2023-11-15 17:26:09,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-15 17:26:09,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-15 17:26:09,976:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-15 17:26:09,976:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 08:49:42,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 08:49:42,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 08:49:42,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 08:49:42,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,491:INFO:PyCaret ClassificationExperiment
2023-11-16 09:09:26,493:INFO:Logging name: clf-default-name
2023-11-16 09:09:26,494:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-16 09:09:26,494:INFO:version 3.2.0
2023-11-16 09:09:26,494:INFO:Initializing setup()
2023-11-16 09:09:26,494:INFO:self.USI: dc25
2023-11-16 09:09:26,494:INFO:self._variable_keys: {'data', 'memory', '_available_plots', 'y', 'gpu_param', 'y_test', 'is_multiclass', 'fold_generator', 'X', 'n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'exp_name_log', 'fold_shuffle_param', 'idx', 'X_train', 'USI', 'logging_param', 'html_param', 'exp_id', 'log_plots_param', 'target_param', 'pipeline', 'fix_imbalance', 'X_test', 'gpu_n_jobs_param', 'y_train'}
2023-11-16 09:09:26,494:INFO:Checking environment
2023-11-16 09:09:26,495:INFO:python_version: 3.8.18
2023-11-16 09:09:26,495:INFO:python_build: ('default', 'Nov  1 2023 11:08:38')
2023-11-16 09:09:26,495:INFO:machine: aarch64
2023-11-16 09:09:26,497:INFO:platform: Linux-5.15.49-linuxkit-pr-aarch64-with-glibc2.34
2023-11-16 09:09:26,499:INFO:Memory: svmem(total=8232710144, available=7026745344, percent=14.6, used=682098688, free=4883681280, active=458027008, inactive=2449285120, buffers=102506496, cached=2564423680, shared=316284928, slab=292446208)
2023-11-16 09:09:26,501:INFO:Physical Core: 6
2023-11-16 09:09:26,501:INFO:Logical Core: 6
2023-11-16 09:09:26,501:INFO:Checking libraries
2023-11-16 09:09:26,502:INFO:System:
2023-11-16 09:09:26,502:INFO:    python: 3.8.18 (default, Nov  1 2023, 11:08:38)  [GCC 12.2.0]
2023-11-16 09:09:26,502:INFO:executable: /usr/local/bin/python
2023-11-16 09:09:26,502:INFO:   machine: Linux-5.15.49-linuxkit-pr-aarch64-with-glibc2.34
2023-11-16 09:09:26,502:INFO:PyCaret required dependencies:
2023-11-16 09:09:26,555:INFO:                 pip: 23.3.1
2023-11-16 09:09:26,555:INFO:          setuptools: 57.5.0
2023-11-16 09:09:26,555:INFO:             pycaret: 3.2.0
2023-11-16 09:09:26,555:INFO:             IPython: 8.12.3
2023-11-16 09:09:26,555:INFO:          ipywidgets: 8.1.1
2023-11-16 09:09:26,555:INFO:                tqdm: 4.66.1
2023-11-16 09:09:26,556:INFO:               numpy: 1.24.4
2023-11-16 09:09:26,556:INFO:              pandas: 1.5.3
2023-11-16 09:09:26,556:INFO:              jinja2: 3.1.2
2023-11-16 09:09:26,556:INFO:               scipy: 1.10.1
2023-11-16 09:09:26,556:INFO:              joblib: 1.3.2
2023-11-16 09:09:26,556:INFO:             sklearn: 1.2.2
2023-11-16 09:09:26,556:INFO:                pyod: 1.1.1
2023-11-16 09:09:26,556:INFO:            imblearn: 0.11.0
2023-11-16 09:09:26,556:INFO:   category_encoders: 2.6.3
2023-11-16 09:09:26,557:INFO:            lightgbm: 4.1.0
2023-11-16 09:09:26,557:INFO:               numba: 0.58.1
2023-11-16 09:09:26,557:INFO:            requests: 2.31.0
2023-11-16 09:09:26,557:INFO:          matplotlib: 3.6.0
2023-11-16 09:09:26,557:INFO:          scikitplot: 0.3.7
2023-11-16 09:09:26,557:INFO:         yellowbrick: 1.5
2023-11-16 09:09:26,557:INFO:              plotly: 5.18.0
2023-11-16 09:09:26,557:INFO:    plotly-resampler: Not installed
2023-11-16 09:09:26,557:INFO:             kaleido: 0.2.1
2023-11-16 09:09:26,557:INFO:           schemdraw: 0.15
2023-11-16 09:09:26,557:INFO:         statsmodels: 0.14.0
2023-11-16 09:09:26,558:INFO:              sktime: 0.21.1
2023-11-16 09:09:26,558:INFO:               tbats: 1.1.3
2023-11-16 09:09:26,558:INFO:            pmdarima: 2.0.4
2023-11-16 09:09:26,558:INFO:              psutil: 5.9.6
2023-11-16 09:09:26,558:INFO:          markupsafe: 2.1.3
2023-11-16 09:09:26,558:INFO:             pickle5: Not installed
2023-11-16 09:09:26,558:INFO:         cloudpickle: 3.0.0
2023-11-16 09:09:26,558:INFO:         deprecation: 2.1.0
2023-11-16 09:09:26,558:INFO:              xxhash: 3.4.1
2023-11-16 09:09:26,558:INFO:           wurlitzer: 3.0.3
2023-11-16 09:09:26,558:INFO:PyCaret optional dependencies:
2023-11-16 09:09:26,571:INFO:                shap: Not installed
2023-11-16 09:09:26,572:INFO:           interpret: Not installed
2023-11-16 09:09:26,572:INFO:                umap: Not installed
2023-11-16 09:09:26,572:INFO:     ydata_profiling: Not installed
2023-11-16 09:09:26,572:INFO:  explainerdashboard: Not installed
2023-11-16 09:09:26,572:INFO:             autoviz: Not installed
2023-11-16 09:09:26,572:INFO:           fairlearn: Not installed
2023-11-16 09:09:26,572:INFO:          deepchecks: Not installed
2023-11-16 09:09:26,573:INFO:             xgboost: Not installed
2023-11-16 09:09:26,573:INFO:            catboost: Not installed
2023-11-16 09:09:26,573:INFO:              kmodes: Not installed
2023-11-16 09:09:26,573:INFO:             mlxtend: Not installed
2023-11-16 09:09:26,573:INFO:       statsforecast: Not installed
2023-11-16 09:09:26,573:INFO:        tune_sklearn: Not installed
2023-11-16 09:09:26,573:INFO:                 ray: Not installed
2023-11-16 09:09:26,573:INFO:            hyperopt: Not installed
2023-11-16 09:09:26,573:INFO:              optuna: Not installed
2023-11-16 09:09:26,574:INFO:               skopt: Not installed
2023-11-16 09:09:26,574:INFO:              mlflow: Not installed
2023-11-16 09:09:26,574:INFO:              gradio: Not installed
2023-11-16 09:09:26,574:INFO:             fastapi: Not installed
2023-11-16 09:09:26,574:INFO:             uvicorn: Not installed
2023-11-16 09:09:26,574:INFO:              m2cgen: Not installed
2023-11-16 09:09:26,574:INFO:           evidently: Not installed
2023-11-16 09:09:26,574:INFO:               fugue: Not installed
2023-11-16 09:09:26,574:INFO:           streamlit: Not installed
2023-11-16 09:09:26,574:INFO:             prophet: Not installed
2023-11-16 09:09:26,574:INFO:None
2023-11-16 09:09:26,575:INFO:Set up GPU usage.
2023-11-16 09:09:26,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,575:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-16 09:09:26,575:INFO:Set up data.
2023-11-16 09:09:26,591:INFO:Set up folding strategy.
2023-11-16 09:09:26,592:INFO:Set up train/test split.
2023-11-16 09:09:26,598:INFO:Set up index.
2023-11-16 09:09:26,598:INFO:Assigning column types.
2023-11-16 09:09:26,600:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-16 09:09:26,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,619:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-16 09:09:26,619:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,622:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,622:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 09:09:26,623:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,645:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,703:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-16 09:09:26,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,703:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 09:09:26,704:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,713:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,719:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-16 09:09:26,719:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,737:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 09:09:26,738:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,746:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,748:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,749:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,752:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,770:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 09:09:26,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,779:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,781:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,782:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,785:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,785:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-16 09:09:26,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,803:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,803:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,804:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,814:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,814:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,851:INFO:Preparing preprocessing pipeline...
2023-11-16 09:09:26,853:INFO:Set up simple imputation.
2023-11-16 09:09:26,866:INFO:Finished creating preprocessing pipeline.
2023-11-16 09:09:26,869:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-16 09:09:26,869:INFO:Creating final display dataframe.
2023-11-16 09:09:26,893:INFO:Setup _display_container:                     Description             Value
0                    Session id              1438
1                        Target            target
2                   Target type        Multiclass
3           Original data shape         (106, 13)
4        Transformed data shape         (106, 13)
5   Transformed train set shape          (74, 13)
6    Transformed test set shape          (32, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              dc25
2023-11-16 09:09:26,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,913:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,913:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,925:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,927:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,928:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,955:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,959:INFO:setup() successfully completed in 0.49s...............
2023-11-16 09:10:15,375:INFO:PyCaret ClassificationExperiment
2023-11-16 09:10:15,376:INFO:Logging name: clf-default-name
2023-11-16 09:10:15,377:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-16 09:10:15,377:INFO:version 3.2.0
2023-11-16 09:10:15,377:INFO:Initializing setup()
2023-11-16 09:10:15,377:INFO:self.USI: 7761
2023-11-16 09:10:15,378:INFO:self._variable_keys: {'data', 'memory', '_available_plots', 'y', 'gpu_param', 'y_test', 'is_multiclass', 'fold_generator', 'X', 'n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'exp_name_log', 'fold_shuffle_param', 'idx', 'X_train', 'USI', 'logging_param', 'html_param', 'exp_id', 'log_plots_param', 'target_param', 'pipeline', 'fix_imbalance', 'X_test', 'gpu_n_jobs_param', 'y_train'}
2023-11-16 09:10:15,378:INFO:Checking environment
2023-11-16 09:10:15,378:INFO:python_version: 3.8.18
2023-11-16 09:10:15,379:INFO:python_build: ('default', 'Nov  1 2023 11:08:38')
2023-11-16 09:10:15,379:INFO:machine: aarch64
2023-11-16 09:10:15,379:INFO:platform: Linux-5.15.49-linuxkit-pr-aarch64-with-glibc2.34
2023-11-16 09:10:15,381:INFO:Memory: svmem(total=8232710144, available=7021359104, percent=14.7, used=687484928, free=4877234176, active=458076160, inactive=2458976256, buffers=102522880, cached=2565468160, shared=316284928, slab=292409344)
2023-11-16 09:10:15,382:INFO:Physical Core: 6
2023-11-16 09:10:15,383:INFO:Logical Core: 6
2023-11-16 09:10:15,383:INFO:Checking libraries
2023-11-16 09:10:15,383:INFO:System:
2023-11-16 09:10:15,384:INFO:    python: 3.8.18 (default, Nov  1 2023, 11:08:38)  [GCC 12.2.0]
2023-11-16 09:10:15,384:INFO:executable: /usr/local/bin/python
2023-11-16 09:10:15,384:INFO:   machine: Linux-5.15.49-linuxkit-pr-aarch64-with-glibc2.34
2023-11-16 09:10:15,384:INFO:PyCaret required dependencies:
2023-11-16 09:10:15,385:INFO:                 pip: 23.3.1
2023-11-16 09:10:15,385:INFO:          setuptools: 57.5.0
2023-11-16 09:10:15,385:INFO:             pycaret: 3.2.0
2023-11-16 09:10:15,386:INFO:             IPython: 8.12.3
2023-11-16 09:10:15,386:INFO:          ipywidgets: 8.1.1
2023-11-16 09:10:15,386:INFO:                tqdm: 4.66.1
2023-11-16 09:10:15,386:INFO:               numpy: 1.24.4
2023-11-16 09:10:15,386:INFO:              pandas: 1.5.3
2023-11-16 09:10:15,386:INFO:              jinja2: 3.1.2
2023-11-16 09:10:15,386:INFO:               scipy: 1.10.1
2023-11-16 09:10:15,387:INFO:              joblib: 1.3.2
2023-11-16 09:10:15,387:INFO:             sklearn: 1.2.2
2023-11-16 09:10:15,387:INFO:                pyod: 1.1.1
2023-11-16 09:10:15,387:INFO:            imblearn: 0.11.0
2023-11-16 09:10:15,387:INFO:   category_encoders: 2.6.3
2023-11-16 09:10:15,387:INFO:            lightgbm: 4.1.0
2023-11-16 09:10:15,387:INFO:               numba: 0.58.1
2023-11-16 09:10:15,388:INFO:            requests: 2.31.0
2023-11-16 09:10:15,388:INFO:          matplotlib: 3.6.0
2023-11-16 09:10:15,388:INFO:          scikitplot: 0.3.7
2023-11-16 09:10:15,388:INFO:         yellowbrick: 1.5
2023-11-16 09:10:15,388:INFO:              plotly: 5.18.0
2023-11-16 09:10:15,388:INFO:    plotly-resampler: Not installed
2023-11-16 09:10:15,388:INFO:             kaleido: 0.2.1
2023-11-16 09:10:15,389:INFO:           schemdraw: 0.15
2023-11-16 09:10:15,389:INFO:         statsmodels: 0.14.0
2023-11-16 09:10:15,389:INFO:              sktime: 0.21.1
2023-11-16 09:10:15,389:INFO:               tbats: 1.1.3
2023-11-16 09:10:15,389:INFO:            pmdarima: 2.0.4
2023-11-16 09:10:15,389:INFO:              psutil: 5.9.6
2023-11-16 09:10:15,389:INFO:          markupsafe: 2.1.3
2023-11-16 09:10:15,389:INFO:             pickle5: Not installed
2023-11-16 09:10:15,390:INFO:         cloudpickle: 3.0.0
2023-11-16 09:10:15,390:INFO:         deprecation: 2.1.0
2023-11-16 09:10:15,390:INFO:              xxhash: 3.4.1
2023-11-16 09:10:15,390:INFO:           wurlitzer: 3.0.3
2023-11-16 09:10:15,390:INFO:PyCaret optional dependencies:
2023-11-16 09:10:15,390:INFO:                shap: Not installed
2023-11-16 09:10:15,390:INFO:           interpret: Not installed
2023-11-16 09:10:15,391:INFO:                umap: Not installed
2023-11-16 09:10:15,391:INFO:     ydata_profiling: Not installed
2023-11-16 09:10:15,391:INFO:  explainerdashboard: Not installed
2023-11-16 09:10:15,391:INFO:             autoviz: Not installed
2023-11-16 09:10:15,391:INFO:           fairlearn: Not installed
2023-11-16 09:10:15,391:INFO:          deepchecks: Not installed
2023-11-16 09:10:15,391:INFO:             xgboost: Not installed
2023-11-16 09:10:15,391:INFO:            catboost: Not installed
2023-11-16 09:10:15,392:INFO:              kmodes: Not installed
2023-11-16 09:10:15,392:INFO:             mlxtend: Not installed
2023-11-16 09:10:15,392:INFO:       statsforecast: Not installed
2023-11-16 09:10:15,392:INFO:        tune_sklearn: Not installed
2023-11-16 09:10:15,392:INFO:                 ray: Not installed
2023-11-16 09:10:15,392:INFO:            hyperopt: Not installed
2023-11-16 09:10:15,392:INFO:              optuna: Not installed
2023-11-16 09:10:15,392:INFO:               skopt: Not installed
2023-11-16 09:10:15,393:INFO:              mlflow: Not installed
2023-11-16 09:10:15,393:INFO:              gradio: Not installed
2023-11-16 09:10:15,393:INFO:             fastapi: Not installed
2023-11-16 09:10:15,393:INFO:             uvicorn: Not installed
2023-11-16 09:10:15,393:INFO:              m2cgen: Not installed
2023-11-16 09:10:15,393:INFO:           evidently: Not installed
2023-11-16 09:10:15,393:INFO:               fugue: Not installed
2023-11-16 09:10:15,394:INFO:           streamlit: Not installed
2023-11-16 09:10:15,394:INFO:             prophet: Not installed
2023-11-16 09:10:15,394:INFO:None
2023-11-16 09:10:15,394:INFO:Set up data.
2023-11-16 09:10:15,407:INFO:Set up folding strategy.
2023-11-16 09:10:15,407:INFO:Set up train/test split.
2023-11-16 09:10:15,411:INFO:Set up index.
2023-11-16 09:10:15,411:INFO:Assigning column types.
2023-11-16 09:10:15,414:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-16 09:10:15,437:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-16 09:10:15,438:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 09:10:15,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,471:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-16 09:10:15,472:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 09:10:15,482:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,483:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-16 09:10:15,501:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 09:10:15,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,532:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 09:10:15,543:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,543:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-16 09:10:15,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,600:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,602:INFO:Preparing preprocessing pipeline...
2023-11-16 09:10:15,602:INFO:Set up simple imputation.
2023-11-16 09:10:15,610:INFO:Finished creating preprocessing pipeline.
2023-11-16 09:10:15,612:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-16 09:10:15,612:INFO:Creating final display dataframe.
2023-11-16 09:10:15,635:INFO:Setup _display_container:                     Description             Value
0                    Session id              6954
1                        Target            target
2                   Target type        Multiclass
3           Original data shape         (106, 13)
4        Transformed data shape         (106, 13)
5   Transformed train set shape          (74, 13)
6    Transformed test set shape          (32, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              7761
2023-11-16 09:10:15,664:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,693:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,694:INFO:setup() successfully completed in 0.33s...............
2023-11-16 09:11:13,803:INFO:Initializing compare_models()
2023-11-16 09:11:13,807:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-16 09:11:13,807:INFO:Checking exceptions
2023-11-16 09:11:13,827:INFO:Preparing display monitor
2023-11-16 09:11:13,841:INFO:Initializing Logistic Regression
2023-11-16 09:11:13,842:INFO:Total runtime is 3.9656956990559895e-06 minutes
2023-11-16 09:11:13,842:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:13,843:INFO:Initializing create_model()
2023-11-16 09:11:13,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:13,844:INFO:Checking exceptions
2023-11-16 09:11:13,844:INFO:Importing libraries
2023-11-16 09:11:13,844:INFO:Copying training dataset
2023-11-16 09:11:13,846:INFO:Defining folds
2023-11-16 09:11:13,846:INFO:Declaring metric variables
2023-11-16 09:11:13,847:INFO:Importing untrained model
2023-11-16 09:11:13,848:INFO:Logistic Regression Imported successfully
2023-11-16 09:11:13,848:INFO:Starting cross validation
2023-11-16 09:11:13,851:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:14,850:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 09:11:14,851:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2023-11-16 09:11:14,852:INFO:Initializing create_model()
2023-11-16 09:11:14,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:14,852:INFO:Checking exceptions
2023-11-16 09:11:14,852:INFO:Importing libraries
2023-11-16 09:11:14,852:INFO:Copying training dataset
2023-11-16 09:11:14,854:INFO:Defining folds
2023-11-16 09:11:14,855:INFO:Declaring metric variables
2023-11-16 09:11:14,855:INFO:Importing untrained model
2023-11-16 09:11:14,855:INFO:Logistic Regression Imported successfully
2023-11-16 09:11:14,855:INFO:Starting cross validation
2023-11-16 09:11:14,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:14,871:ERROR:create_model() for lr raised an exception or returned all 0.0:
2023-11-16 09:11:14,872:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2023-11-16 09:11:14,872:INFO:Initializing K Neighbors Classifier
2023-11-16 09:11:14,872:INFO:Total runtime is 0.017175217469533283 minutes
2023-11-16 09:11:14,872:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:14,872:INFO:Initializing create_model()
2023-11-16 09:11:14,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:14,873:INFO:Checking exceptions
2023-11-16 09:11:14,873:INFO:Importing libraries
2023-11-16 09:11:14,873:INFO:Copying training dataset
2023-11-16 09:11:14,874:INFO:Defining folds
2023-11-16 09:11:14,874:INFO:Declaring metric variables
2023-11-16 09:11:14,875:INFO:Importing untrained model
2023-11-16 09:11:14,875:INFO:K Neighbors Classifier Imported successfully
2023-11-16 09:11:14,875:INFO:Starting cross validation
2023-11-16 09:11:14,876:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:14,916:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,916:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,917:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,917:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,918:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,918:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,920:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,920:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,920:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,920:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,920:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,921:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,921:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,921:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,921:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,921:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,921:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,922:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,922:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,922:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,922:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,922:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,952:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,952:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,952:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,952:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,953:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,953:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,953:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,954:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,954:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,954:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,954:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,955:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,955:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,955:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,955:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,955:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,955:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,956:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,956:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,956:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,962:INFO:Calculating mean and std
2023-11-16 09:11:14,963:INFO:Creating metrics dataframe
2023-11-16 09:11:14,966:INFO:Uploading results into container
2023-11-16 09:11:14,967:INFO:Uploading model into container now
2023-11-16 09:11:14,968:INFO:_master_model_container: 1
2023-11-16 09:11:14,968:INFO:_display_container: 2
2023-11-16 09:11:14,969:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 09:11:14,969:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,084:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,084:INFO:Creating metrics dataframe
2023-11-16 09:11:15,086:INFO:Initializing Naive Bayes
2023-11-16 09:11:15,086:INFO:Total runtime is 0.020749119917551677 minutes
2023-11-16 09:11:15,087:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,087:INFO:Initializing create_model()
2023-11-16 09:11:15,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,087:INFO:Checking exceptions
2023-11-16 09:11:15,087:INFO:Importing libraries
2023-11-16 09:11:15,087:INFO:Copying training dataset
2023-11-16 09:11:15,088:INFO:Defining folds
2023-11-16 09:11:15,089:INFO:Declaring metric variables
2023-11-16 09:11:15,089:INFO:Importing untrained model
2023-11-16 09:11:15,089:INFO:Naive Bayes Imported successfully
2023-11-16 09:11:15,089:INFO:Starting cross validation
2023-11-16 09:11:15,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,101:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,101:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,101:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,102:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,102:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,102:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,102:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,103:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,103:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,103:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,103:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,103:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,104:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,104:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,104:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,104:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,104:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,104:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,104:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,105:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,105:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,105:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,106:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,106:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,106:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,108:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,108:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,109:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,110:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,110:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,110:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,110:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,111:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,111:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,111:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,112:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,112:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,112:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,112:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,112:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,113:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,113:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,113:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,113:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,114:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,114:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,114:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,114:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,115:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,115:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,125:INFO:Calculating mean and std
2023-11-16 09:11:15,126:INFO:Creating metrics dataframe
2023-11-16 09:11:15,127:INFO:Uploading results into container
2023-11-16 09:11:15,128:INFO:Uploading model into container now
2023-11-16 09:11:15,128:INFO:_master_model_container: 2
2023-11-16 09:11:15,128:INFO:_display_container: 2
2023-11-16 09:11:15,128:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-16 09:11:15,128:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,157:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,158:INFO:Creating metrics dataframe
2023-11-16 09:11:15,160:INFO:Initializing Decision Tree Classifier
2023-11-16 09:11:15,160:INFO:Total runtime is 0.021973665555318198 minutes
2023-11-16 09:11:15,160:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,160:INFO:Initializing create_model()
2023-11-16 09:11:15,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,160:INFO:Checking exceptions
2023-11-16 09:11:15,161:INFO:Importing libraries
2023-11-16 09:11:15,161:INFO:Copying training dataset
2023-11-16 09:11:15,162:INFO:Defining folds
2023-11-16 09:11:15,162:INFO:Declaring metric variables
2023-11-16 09:11:15,162:INFO:Importing untrained model
2023-11-16 09:11:15,162:INFO:Decision Tree Classifier Imported successfully
2023-11-16 09:11:15,163:INFO:Starting cross validation
2023-11-16 09:11:15,163:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,175:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,175:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,175:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,175:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,175:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,176:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,176:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,176:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,176:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,176:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,176:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,177:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,177:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,177:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,177:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,177:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,177:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,179:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,179:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,179:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,179:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,184:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,184:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,184:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,184:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,185:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,185:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,185:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,185:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,186:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,186:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,186:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,186:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,187:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,187:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,187:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,187:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,187:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,187:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,188:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,188:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,199:INFO:Calculating mean and std
2023-11-16 09:11:15,200:INFO:Creating metrics dataframe
2023-11-16 09:11:15,202:INFO:Uploading results into container
2023-11-16 09:11:15,202:INFO:Uploading model into container now
2023-11-16 09:11:15,202:INFO:_master_model_container: 3
2023-11-16 09:11:15,202:INFO:_display_container: 2
2023-11-16 09:11:15,203:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6954, splitter='best')
2023-11-16 09:11:15,203:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,231:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,231:INFO:Creating metrics dataframe
2023-11-16 09:11:15,235:INFO:Initializing SVM - Linear Kernel
2023-11-16 09:11:15,235:INFO:Total runtime is 0.023223686218261718 minutes
2023-11-16 09:11:15,235:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,235:INFO:Initializing create_model()
2023-11-16 09:11:15,235:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,236:INFO:Checking exceptions
2023-11-16 09:11:15,236:INFO:Importing libraries
2023-11-16 09:11:15,236:INFO:Copying training dataset
2023-11-16 09:11:15,237:INFO:Defining folds
2023-11-16 09:11:15,237:INFO:Declaring metric variables
2023-11-16 09:11:15,237:INFO:Importing untrained model
2023-11-16 09:11:15,238:INFO:SVM - Linear Kernel Imported successfully
2023-11-16 09:11:15,238:INFO:Starting cross validation
2023-11-16 09:11:15,238:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,253:WARNING:create_model() for svm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 09:11:15,253:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 09:11:15,253:INFO:Initializing create_model()
2023-11-16 09:11:15,253:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,254:INFO:Checking exceptions
2023-11-16 09:11:15,254:INFO:Importing libraries
2023-11-16 09:11:15,254:INFO:Copying training dataset
2023-11-16 09:11:15,255:INFO:Defining folds
2023-11-16 09:11:15,255:INFO:Declaring metric variables
2023-11-16 09:11:15,255:INFO:Importing untrained model
2023-11-16 09:11:15,256:INFO:SVM - Linear Kernel Imported successfully
2023-11-16 09:11:15,256:INFO:Starting cross validation
2023-11-16 09:11:15,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,271:ERROR:create_model() for svm raised an exception or returned all 0.0:
2023-11-16 09:11:15,272:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 09:11:15,272:INFO:Initializing Ridge Classifier
2023-11-16 09:11:15,272:INFO:Total runtime is 0.023841190338134765 minutes
2023-11-16 09:11:15,272:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,272:INFO:Initializing create_model()
2023-11-16 09:11:15,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,273:INFO:Checking exceptions
2023-11-16 09:11:15,273:INFO:Importing libraries
2023-11-16 09:11:15,273:INFO:Copying training dataset
2023-11-16 09:11:15,274:INFO:Defining folds
2023-11-16 09:11:15,274:INFO:Declaring metric variables
2023-11-16 09:11:15,275:INFO:Importing untrained model
2023-11-16 09:11:15,275:INFO:Ridge Classifier Imported successfully
2023-11-16 09:11:15,275:INFO:Starting cross validation
2023-11-16 09:11:15,275:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,292:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,292:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,292:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,292:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,292:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,292:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,293:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,293:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,293:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,293:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,293:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,294:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,294:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,294:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,294:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,294:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,294:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,294:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,295:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,295:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,295:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,295:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,295:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,295:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,295:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,295:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,296:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,296:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,296:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,296:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,301:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,302:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,302:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,302:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,302:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,303:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,303:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,303:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,304:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,304:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,304:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,304:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,310:INFO:Calculating mean and std
2023-11-16 09:11:15,311:INFO:Creating metrics dataframe
2023-11-16 09:11:15,313:INFO:Uploading results into container
2023-11-16 09:11:15,313:INFO:Uploading model into container now
2023-11-16 09:11:15,313:INFO:_master_model_container: 4
2023-11-16 09:11:15,313:INFO:_display_container: 2
2023-11-16 09:11:15,314:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6954, solver='auto',
                tol=0.0001)
2023-11-16 09:11:15,314:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,346:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,346:INFO:Creating metrics dataframe
2023-11-16 09:11:15,348:INFO:Initializing Quadratic Discriminant Analysis
2023-11-16 09:11:15,349:INFO:Total runtime is 0.025118029117584227 minutes
2023-11-16 09:11:15,349:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,349:INFO:Initializing create_model()
2023-11-16 09:11:15,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,349:INFO:Checking exceptions
2023-11-16 09:11:15,349:INFO:Importing libraries
2023-11-16 09:11:15,349:INFO:Copying training dataset
2023-11-16 09:11:15,351:INFO:Defining folds
2023-11-16 09:11:15,351:INFO:Declaring metric variables
2023-11-16 09:11:15,352:INFO:Importing untrained model
2023-11-16 09:11:15,352:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-16 09:11:15,352:INFO:Starting cross validation
2023-11-16 09:11:15,353:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,367:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 09:11:15,367:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 09:11:15,367:INFO:Initializing create_model()
2023-11-16 09:11:15,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,367:INFO:Checking exceptions
2023-11-16 09:11:15,368:INFO:Importing libraries
2023-11-16 09:11:15,368:INFO:Copying training dataset
2023-11-16 09:11:15,369:INFO:Defining folds
2023-11-16 09:11:15,369:INFO:Declaring metric variables
2023-11-16 09:11:15,369:INFO:Importing untrained model
2023-11-16 09:11:15,370:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-16 09:11:15,370:INFO:Starting cross validation
2023-11-16 09:11:15,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,385:ERROR:create_model() for qda raised an exception or returned all 0.0:
2023-11-16 09:11:15,385:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 09:11:15,385:INFO:Initializing Ada Boost Classifier
2023-11-16 09:11:15,385:INFO:Total runtime is 0.02572911183039347 minutes
2023-11-16 09:11:15,385:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,386:INFO:Initializing create_model()
2023-11-16 09:11:15,386:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,386:INFO:Checking exceptions
2023-11-16 09:11:15,386:INFO:Importing libraries
2023-11-16 09:11:15,386:INFO:Copying training dataset
2023-11-16 09:11:15,387:INFO:Defining folds
2023-11-16 09:11:15,387:INFO:Declaring metric variables
2023-11-16 09:11:15,388:INFO:Importing untrained model
2023-11-16 09:11:15,388:INFO:Ada Boost Classifier Imported successfully
2023-11-16 09:11:15,388:INFO:Starting cross validation
2023-11-16 09:11:15,388:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,398:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,398:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,399:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,399:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,399:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,399:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,400:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,400:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,400:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,400:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,401:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,401:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,401:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,401:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,401:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,401:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,402:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,402:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,402:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,402:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,402:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,402:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,402:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,403:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,403:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,403:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,403:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,403:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,404:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,404:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,408:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,409:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,409:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,409:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,409:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,410:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,410:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,410:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,410:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,410:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,411:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,411:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,411:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,411:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,412:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,412:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,412:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,412:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,412:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,413:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,423:INFO:Calculating mean and std
2023-11-16 09:11:15,423:INFO:Creating metrics dataframe
2023-11-16 09:11:15,425:INFO:Uploading results into container
2023-11-16 09:11:15,425:INFO:Uploading model into container now
2023-11-16 09:11:15,426:INFO:_master_model_container: 5
2023-11-16 09:11:15,426:INFO:_display_container: 2
2023-11-16 09:11:15,426:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6954)
2023-11-16 09:11:15,426:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,455:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,455:INFO:Creating metrics dataframe
2023-11-16 09:11:15,457:INFO:Initializing Linear Discriminant Analysis
2023-11-16 09:11:15,458:INFO:Total runtime is 0.026935525735219318 minutes
2023-11-16 09:11:15,458:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,458:INFO:Initializing create_model()
2023-11-16 09:11:15,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,458:INFO:Checking exceptions
2023-11-16 09:11:15,458:INFO:Importing libraries
2023-11-16 09:11:15,459:INFO:Copying training dataset
2023-11-16 09:11:15,460:INFO:Defining folds
2023-11-16 09:11:15,460:INFO:Declaring metric variables
2023-11-16 09:11:15,460:INFO:Importing untrained model
2023-11-16 09:11:15,460:INFO:Linear Discriminant Analysis Imported successfully
2023-11-16 09:11:15,461:INFO:Starting cross validation
2023-11-16 09:11:15,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,475:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,475:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,475:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,475:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,475:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,475:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,476:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,476:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,476:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,476:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,476:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,477:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,477:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,477:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,477:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,477:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,477:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,479:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,479:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,479:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,479:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,484:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,484:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,485:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,485:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,485:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,485:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,486:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,486:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,486:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,486:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,486:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,487:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,487:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,487:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,487:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,487:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,487:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,488:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,488:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,488:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,496:INFO:Calculating mean and std
2023-11-16 09:11:15,497:INFO:Creating metrics dataframe
2023-11-16 09:11:15,498:INFO:Uploading results into container
2023-11-16 09:11:15,499:INFO:Uploading model into container now
2023-11-16 09:11:15,499:INFO:_master_model_container: 6
2023-11-16 09:11:15,499:INFO:_display_container: 2
2023-11-16 09:11:15,499:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-16 09:11:15,499:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,528:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,528:INFO:Creating metrics dataframe
2023-11-16 09:11:15,530:INFO:Initializing Extra Trees Classifier
2023-11-16 09:11:15,530:INFO:Total runtime is 0.028150820732116697 minutes
2023-11-16 09:11:15,531:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,531:INFO:Initializing create_model()
2023-11-16 09:11:15,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,531:INFO:Checking exceptions
2023-11-16 09:11:15,531:INFO:Importing libraries
2023-11-16 09:11:15,531:INFO:Copying training dataset
2023-11-16 09:11:15,532:INFO:Defining folds
2023-11-16 09:11:15,533:INFO:Declaring metric variables
2023-11-16 09:11:15,533:INFO:Importing untrained model
2023-11-16 09:11:15,533:INFO:Extra Trees Classifier Imported successfully
2023-11-16 09:11:15,533:INFO:Starting cross validation
2023-11-16 09:11:15,534:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,627:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,628:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,629:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,630:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,630:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,631:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,631:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,632:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,633:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,634:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,634:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,635:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,637:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,637:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,637:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,638:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,639:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,641:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,642:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,642:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,659:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,660:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,661:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,662:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,663:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,671:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,672:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,673:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,674:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,675:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,723:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,724:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,725:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,726:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,726:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,730:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,731:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,732:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,733:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,733:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,736:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,737:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,738:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,739:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,739:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,739:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,740:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,741:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,741:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,742:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,752:INFO:Calculating mean and std
2023-11-16 09:11:15,752:INFO:Creating metrics dataframe
2023-11-16 09:11:15,754:INFO:Uploading results into container
2023-11-16 09:11:15,755:INFO:Uploading model into container now
2023-11-16 09:11:15,755:INFO:_master_model_container: 7
2023-11-16 09:11:15,755:INFO:_display_container: 2
2023-11-16 09:11:15,755:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6954, verbose=0, warm_start=False)
2023-11-16 09:11:15,755:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,785:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,785:INFO:Creating metrics dataframe
2023-11-16 09:11:15,787:INFO:Initializing Light Gradient Boosting Machine
2023-11-16 09:11:15,787:INFO:Total runtime is 0.03243365287780761 minutes
2023-11-16 09:11:15,788:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,788:INFO:Initializing create_model()
2023-11-16 09:11:15,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,788:INFO:Checking exceptions
2023-11-16 09:11:15,788:INFO:Importing libraries
2023-11-16 09:11:15,788:INFO:Copying training dataset
2023-11-16 09:11:15,790:INFO:Defining folds
2023-11-16 09:11:15,790:INFO:Declaring metric variables
2023-11-16 09:11:15,790:INFO:Importing untrained model
2023-11-16 09:11:15,790:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-16 09:11:15,790:INFO:Starting cross validation
2023-11-16 09:11:15,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,816:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,817:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,818:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,820:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,820:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,824:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,825:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,826:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,826:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,827:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,828:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,828:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,830:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,830:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,830:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,831:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,832:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,832:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,832:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,833:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,834:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,835:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,834:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,839:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,839:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,840:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,840:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,841:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,843:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,844:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,845:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,846:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,846:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,846:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,848:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,853:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,854:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,854:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,855:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,855:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,856:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,856:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,856:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,857:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,858:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,858:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,858:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,859:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,860:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,860:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,866:INFO:Calculating mean and std
2023-11-16 09:11:15,866:INFO:Creating metrics dataframe
2023-11-16 09:11:15,868:INFO:Uploading results into container
2023-11-16 09:11:15,868:INFO:Uploading model into container now
2023-11-16 09:11:15,869:INFO:_master_model_container: 8
2023-11-16 09:11:15,869:INFO:_display_container: 2
2023-11-16 09:11:15,869:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6954, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-16 09:11:15,869:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,899:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,900:INFO:Creating metrics dataframe
2023-11-16 09:11:15,902:INFO:Initializing Dummy Classifier
2023-11-16 09:11:15,902:INFO:Total runtime is 0.034343930085500074 minutes
2023-11-16 09:11:15,902:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,902:INFO:Initializing create_model()
2023-11-16 09:11:15,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,903:INFO:Checking exceptions
2023-11-16 09:11:15,903:INFO:Importing libraries
2023-11-16 09:11:15,903:INFO:Copying training dataset
2023-11-16 09:11:15,904:INFO:Defining folds
2023-11-16 09:11:15,904:INFO:Declaring metric variables
2023-11-16 09:11:15,905:INFO:Importing untrained model
2023-11-16 09:11:15,905:INFO:Dummy Classifier Imported successfully
2023-11-16 09:11:15,905:INFO:Starting cross validation
2023-11-16 09:11:15,905:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,914:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,914:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,915:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,915:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,915:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,915:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,916:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,916:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,916:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,916:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,916:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,917:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,916:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,917:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,917:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,917:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,917:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,917:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,920:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,920:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,923:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,923:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,923:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,923:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,924:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,924:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,924:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,924:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,925:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,925:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,925:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,925:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,925:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,926:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,926:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,926:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,926:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,926:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,927:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,927:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,930:INFO:Calculating mean and std
2023-11-16 09:11:15,930:INFO:Creating metrics dataframe
2023-11-16 09:11:15,932:INFO:Uploading results into container
2023-11-16 09:11:15,932:INFO:Uploading model into container now
2023-11-16 09:11:15,932:INFO:_master_model_container: 9
2023-11-16 09:11:15,932:INFO:_display_container: 2
2023-11-16 09:11:15,933:INFO:DummyClassifier(constant=None, random_state=6954, strategy='prior')
2023-11-16 09:11:15,933:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,961:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,961:INFO:Creating metrics dataframe
2023-11-16 09:11:15,964:INFO:Initializing create_model()
2023-11-16 09:11:15,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,965:INFO:Checking exceptions
2023-11-16 09:11:15,965:INFO:Importing libraries
2023-11-16 09:11:15,965:INFO:Copying training dataset
2023-11-16 09:11:15,967:INFO:Defining folds
2023-11-16 09:11:15,967:INFO:Declaring metric variables
2023-11-16 09:11:15,967:INFO:Importing untrained model
2023-11-16 09:11:15,967:INFO:Declaring custom model
2023-11-16 09:11:15,967:INFO:K Neighbors Classifier Imported successfully
2023-11-16 09:11:15,968:INFO:Cross validation set to False
2023-11-16 09:11:15,968:INFO:Fitting Model
2023-11-16 09:11:15,972:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 09:11:15,972:INFO:create_model() successfully completed......................................
2023-11-16 09:11:16,003:INFO:_master_model_container: 9
2023-11-16 09:11:16,003:INFO:_display_container: 2
2023-11-16 09:11:16,003:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 09:11:16,003:INFO:compare_models() successfully completed......................................
2023-11-16 09:12:38,281:INFO:Initializing create_model()
2023-11-16 09:12:38,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=rbfsvm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:12:38,285:INFO:Checking exceptions
2023-11-16 09:12:38,303:INFO:Importing libraries
2023-11-16 09:12:38,303:INFO:Copying training dataset
2023-11-16 09:12:38,308:INFO:Defining folds
2023-11-16 09:12:38,308:INFO:Declaring metric variables
2023-11-16 09:12:38,309:INFO:Importing untrained model
2023-11-16 09:12:38,310:INFO:SVM - Radial Kernel Imported successfully
2023-11-16 09:12:38,311:INFO:Starting cross validation
2023-11-16 09:12:38,313:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 10:02:49,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:02:49,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:02:49,654:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:02:49,654:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:09,939:INFO:PyCaret ClassificationExperiment
2023-11-16 10:07:09,941:INFO:Logging name: clf-default-name
2023-11-16 10:07:09,941:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-16 10:07:09,941:INFO:version 3.2.0
2023-11-16 10:07:09,942:INFO:Initializing setup()
2023-11-16 10:07:09,942:INFO:self.USI: 1ae3
2023-11-16 10:07:09,942:INFO:self._variable_keys: {'y_train', 'memory', 'target_param', 'fix_imbalance', 'html_param', 'gpu_param', 'fold_groups_param', 'is_multiclass', 'X_test', 'n_jobs_param', 'y', 'gpu_n_jobs_param', 'fold_shuffle_param', 'pipeline', '_ml_usecase', 'log_plots_param', '_available_plots', 'seed', 'fold_generator', 'USI', 'idx', 'exp_id', 'logging_param', 'y_test', 'data', 'exp_name_log', 'X', 'X_train'}
2023-11-16 10:07:09,942:INFO:Checking environment
2023-11-16 10:07:09,943:INFO:python_version: 3.8.18
2023-11-16 10:07:09,943:INFO:python_build: ('default', 'Nov  1 2023 11:08:38')
2023-11-16 10:07:09,943:INFO:machine: aarch64
2023-11-16 10:07:09,945:INFO:platform: Linux-5.15.49-linuxkit-pr-aarch64-with-glibc2.34
2023-11-16 10:07:09,945:INFO:Memory: svmem(total=8232710144, available=7023550464, percent=14.7, used=685236224, free=4238479360, active=911339520, inactive=2613202944, buffers=114892800, cached=3194101760, shared=316342272, slab=327696384)
2023-11-16 10:07:09,947:INFO:Physical Core: 6
2023-11-16 10:07:09,947:INFO:Logical Core: 6
2023-11-16 10:07:09,947:INFO:Checking libraries
2023-11-16 10:07:09,947:INFO:System:
2023-11-16 10:07:09,947:INFO:    python: 3.8.18 (default, Nov  1 2023, 11:08:38)  [GCC 12.2.0]
2023-11-16 10:07:09,947:INFO:executable: /usr/local/bin/python
2023-11-16 10:07:09,948:INFO:   machine: Linux-5.15.49-linuxkit-pr-aarch64-with-glibc2.34
2023-11-16 10:07:09,948:INFO:PyCaret required dependencies:
2023-11-16 10:07:09,993:INFO:                 pip: 23.3.1
2023-11-16 10:07:09,993:INFO:          setuptools: 57.5.0
2023-11-16 10:07:09,993:INFO:             pycaret: 3.2.0
2023-11-16 10:07:09,993:INFO:             IPython: 8.12.3
2023-11-16 10:07:09,993:INFO:          ipywidgets: 8.1.1
2023-11-16 10:07:09,993:INFO:                tqdm: 4.66.1
2023-11-16 10:07:09,994:INFO:               numpy: 1.24.4
2023-11-16 10:07:09,994:INFO:              pandas: 1.5.3
2023-11-16 10:07:09,994:INFO:              jinja2: 3.1.2
2023-11-16 10:07:09,994:INFO:               scipy: 1.10.1
2023-11-16 10:07:09,994:INFO:              joblib: 1.3.2
2023-11-16 10:07:09,994:INFO:             sklearn: 1.2.2
2023-11-16 10:07:09,994:INFO:                pyod: 1.1.1
2023-11-16 10:07:09,995:INFO:            imblearn: 0.11.0
2023-11-16 10:07:09,995:INFO:   category_encoders: 2.6.3
2023-11-16 10:07:09,995:INFO:            lightgbm: 4.1.0
2023-11-16 10:07:09,995:INFO:               numba: 0.58.1
2023-11-16 10:07:09,995:INFO:            requests: 2.31.0
2023-11-16 10:07:09,995:INFO:          matplotlib: 3.6.0
2023-11-16 10:07:09,995:INFO:          scikitplot: 0.3.7
2023-11-16 10:07:09,995:INFO:         yellowbrick: 1.5
2023-11-16 10:07:09,996:INFO:              plotly: 5.18.0
2023-11-16 10:07:09,996:INFO:    plotly-resampler: Not installed
2023-11-16 10:07:09,996:INFO:             kaleido: 0.2.1
2023-11-16 10:07:09,996:INFO:           schemdraw: 0.15
2023-11-16 10:07:09,996:INFO:         statsmodels: 0.14.0
2023-11-16 10:07:09,996:INFO:              sktime: 0.21.1
2023-11-16 10:07:09,996:INFO:               tbats: 1.1.3
2023-11-16 10:07:09,996:INFO:            pmdarima: 2.0.4
2023-11-16 10:07:09,997:INFO:              psutil: 5.9.6
2023-11-16 10:07:09,997:INFO:          markupsafe: 2.1.3
2023-11-16 10:07:09,997:INFO:             pickle5: Not installed
2023-11-16 10:07:09,997:INFO:         cloudpickle: 3.0.0
2023-11-16 10:07:09,997:INFO:         deprecation: 2.1.0
2023-11-16 10:07:09,997:INFO:              xxhash: 3.4.1
2023-11-16 10:07:09,997:INFO:           wurlitzer: 3.0.3
2023-11-16 10:07:09,997:INFO:PyCaret optional dependencies:
2023-11-16 10:07:10,009:INFO:                shap: Not installed
2023-11-16 10:07:10,009:INFO:           interpret: Not installed
2023-11-16 10:07:10,009:INFO:                umap: Not installed
2023-11-16 10:07:10,009:INFO:     ydata_profiling: Not installed
2023-11-16 10:07:10,009:INFO:  explainerdashboard: Not installed
2023-11-16 10:07:10,009:INFO:             autoviz: Not installed
2023-11-16 10:07:10,009:INFO:           fairlearn: Not installed
2023-11-16 10:07:10,010:INFO:          deepchecks: Not installed
2023-11-16 10:07:10,010:INFO:             xgboost: Not installed
2023-11-16 10:07:10,010:INFO:            catboost: Not installed
2023-11-16 10:07:10,010:INFO:              kmodes: Not installed
2023-11-16 10:07:10,010:INFO:             mlxtend: Not installed
2023-11-16 10:07:10,010:INFO:       statsforecast: Not installed
2023-11-16 10:07:10,010:INFO:        tune_sklearn: Not installed
2023-11-16 10:07:10,010:INFO:                 ray: Not installed
2023-11-16 10:07:10,010:INFO:            hyperopt: Not installed
2023-11-16 10:07:10,010:INFO:              optuna: Not installed
2023-11-16 10:07:10,010:INFO:               skopt: Not installed
2023-11-16 10:07:10,010:INFO:              mlflow: Not installed
2023-11-16 10:07:10,010:INFO:              gradio: Not installed
2023-11-16 10:07:10,010:INFO:             fastapi: Not installed
2023-11-16 10:07:10,011:INFO:             uvicorn: Not installed
2023-11-16 10:07:10,011:INFO:              m2cgen: Not installed
2023-11-16 10:07:10,011:INFO:           evidently: Not installed
2023-11-16 10:07:10,011:INFO:               fugue: Not installed
2023-11-16 10:07:10,011:INFO:           streamlit: Not installed
2023-11-16 10:07:10,011:INFO:             prophet: Not installed
2023-11-16 10:07:10,011:INFO:None
2023-11-16 10:07:10,011:INFO:Set up GPU usage.
2023-11-16 10:07:10,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,011:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-16 10:07:10,012:INFO:Set up data.
2023-11-16 10:07:10,030:INFO:Set up folding strategy.
2023-11-16 10:07:10,031:INFO:Set up train/test split.
2023-11-16 10:07:10,035:INFO:Set up index.
2023-11-16 10:07:10,035:INFO:Assigning column types.
2023-11-16 10:07:10,037:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-16 10:07:10,037:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,056:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-16 10:07:10,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,058:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 10:07:10,059:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,070:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,072:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,074:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,111:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,130:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-16 10:07:10,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,131:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 10:07:10,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,145:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-16 10:07:10,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,164:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 10:07:10,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,172:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,182:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,201:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 10:07:10,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,212:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,213:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,216:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-16 10:07:10,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,234:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,234:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,235:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,244:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,248:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,268:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,281:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,283:INFO:Preparing preprocessing pipeline...
2023-11-16 10:07:10,285:INFO:Set up simple imputation.
2023-11-16 10:07:10,297:INFO:Finished creating preprocessing pipeline.
2023-11-16 10:07:10,300:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-16 10:07:10,300:INFO:Creating final display dataframe.
2023-11-16 10:07:10,324:INFO:Setup _display_container:                     Description             Value
0                    Session id              6235
1                        Target            target
2                   Target type        Multiclass
3           Original data shape         (106, 13)
4        Transformed data shape         (106, 13)
5   Transformed train set shape          (74, 13)
6    Transformed test set shape          (32, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              1ae3
2023-11-16 10:07:10,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,359:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,378:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,378:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,378:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,387:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,389:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,393:INFO:setup() successfully completed in 0.47s...............
2023-11-16 10:07:38,284:INFO:Initializing compare_models()
2023-11-16 10:07:38,286:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-16 10:07:38,286:INFO:Checking exceptions
2023-11-16 10:07:38,294:INFO:Preparing display monitor
2023-11-16 10:07:38,303:INFO:Initializing Logistic Regression
2023-11-16 10:07:38,303:INFO:Total runtime is 6.564458211263021e-06 minutes
2023-11-16 10:07:38,304:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:38,304:INFO:Initializing create_model()
2023-11-16 10:07:38,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,305:INFO:Checking exceptions
2023-11-16 10:07:38,305:INFO:Importing libraries
2023-11-16 10:07:38,305:INFO:Copying training dataset
2023-11-16 10:07:38,309:INFO:Defining folds
2023-11-16 10:07:38,309:INFO:Declaring metric variables
2023-11-16 10:07:38,310:INFO:Importing untrained model
2023-11-16 10:07:38,310:INFO:Logistic Regression Imported successfully
2023-11-16 10:07:38,311:INFO:Starting cross validation
2023-11-16 10:07:38,311:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,334:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 10:07:38,336:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2023-11-16 10:07:38,336:INFO:Initializing create_model()
2023-11-16 10:07:38,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,337:INFO:Checking exceptions
2023-11-16 10:07:38,337:INFO:Importing libraries
2023-11-16 10:07:38,337:INFO:Copying training dataset
2023-11-16 10:07:38,339:INFO:Defining folds
2023-11-16 10:07:38,339:INFO:Declaring metric variables
2023-11-16 10:07:38,339:INFO:Importing untrained model
2023-11-16 10:07:38,339:INFO:Logistic Regression Imported successfully
2023-11-16 10:07:38,340:INFO:Starting cross validation
2023-11-16 10:07:38,340:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,358:ERROR:create_model() for lr raised an exception or returned all 0.0:
2023-11-16 10:07:38,358:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2023-11-16 10:07:38,359:INFO:Initializing K Neighbors Classifier
2023-11-16 10:07:38,359:INFO:Total runtime is 0.0009341319402058919 minutes
2023-11-16 10:07:38,359:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:38,359:INFO:Initializing create_model()
2023-11-16 10:07:38,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,360:INFO:Checking exceptions
2023-11-16 10:07:38,360:INFO:Importing libraries
2023-11-16 10:07:38,360:INFO:Copying training dataset
2023-11-16 10:07:38,361:INFO:Defining folds
2023-11-16 10:07:38,362:INFO:Declaring metric variables
2023-11-16 10:07:38,362:INFO:Importing untrained model
2023-11-16 10:07:38,362:INFO:K Neighbors Classifier Imported successfully
2023-11-16 10:07:38,362:INFO:Starting cross validation
2023-11-16 10:07:38,363:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,399:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,401:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,402:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,403:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,404:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,435:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,436:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,437:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,438:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,439:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,469:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,470:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,471:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,472:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,473:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,505:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,507:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,508:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,509:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,510:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,540:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,541:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,542:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,543:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,544:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,545:INFO:Calculating mean and std
2023-11-16 10:07:38,545:INFO:Creating metrics dataframe
2023-11-16 10:07:38,547:INFO:Uploading results into container
2023-11-16 10:07:38,548:INFO:Uploading model into container now
2023-11-16 10:07:38,548:INFO:_master_model_container: 1
2023-11-16 10:07:38,548:INFO:_display_container: 2
2023-11-16 10:07:38,549:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 10:07:38,549:INFO:create_model() successfully completed......................................
2023-11-16 10:07:38,699:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:38,699:INFO:Creating metrics dataframe
2023-11-16 10:07:38,701:INFO:Initializing Naive Bayes
2023-11-16 10:07:38,701:INFO:Total runtime is 0.006643561522165934 minutes
2023-11-16 10:07:38,702:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:38,702:INFO:Initializing create_model()
2023-11-16 10:07:38,702:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,702:INFO:Checking exceptions
2023-11-16 10:07:38,702:INFO:Importing libraries
2023-11-16 10:07:38,702:INFO:Copying training dataset
2023-11-16 10:07:38,704:INFO:Defining folds
2023-11-16 10:07:38,704:INFO:Declaring metric variables
2023-11-16 10:07:38,704:INFO:Importing untrained model
2023-11-16 10:07:38,704:INFO:Naive Bayes Imported successfully
2023-11-16 10:07:38,704:INFO:Starting cross validation
2023-11-16 10:07:38,705:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,710:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,711:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,712:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,713:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,713:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,718:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,719:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,720:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,721:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,721:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,726:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,727:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,728:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,729:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,729:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,734:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,735:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,735:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,736:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,736:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,741:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,742:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,743:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,744:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,744:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,745:INFO:Calculating mean and std
2023-11-16 10:07:38,745:INFO:Creating metrics dataframe
2023-11-16 10:07:38,747:INFO:Uploading results into container
2023-11-16 10:07:38,747:INFO:Uploading model into container now
2023-11-16 10:07:38,747:INFO:_master_model_container: 2
2023-11-16 10:07:38,747:INFO:_display_container: 2
2023-11-16 10:07:38,748:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-16 10:07:38,748:INFO:create_model() successfully completed......................................
2023-11-16 10:07:38,775:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:38,776:INFO:Creating metrics dataframe
2023-11-16 10:07:38,778:INFO:Initializing Decision Tree Classifier
2023-11-16 10:07:38,778:INFO:Total runtime is 0.007922617594401042 minutes
2023-11-16 10:07:38,778:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:38,779:INFO:Initializing create_model()
2023-11-16 10:07:38,779:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,779:INFO:Checking exceptions
2023-11-16 10:07:38,779:INFO:Importing libraries
2023-11-16 10:07:38,779:INFO:Copying training dataset
2023-11-16 10:07:38,780:INFO:Defining folds
2023-11-16 10:07:38,780:INFO:Declaring metric variables
2023-11-16 10:07:38,781:INFO:Importing untrained model
2023-11-16 10:07:38,781:INFO:Decision Tree Classifier Imported successfully
2023-11-16 10:07:38,781:INFO:Starting cross validation
2023-11-16 10:07:38,781:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,788:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,789:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,790:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,791:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,791:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,796:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,797:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,797:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,798:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,799:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,804:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,804:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,805:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,806:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,806:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,811:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,812:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,813:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,814:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,814:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,819:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,820:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,821:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,821:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,822:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,823:INFO:Calculating mean and std
2023-11-16 10:07:38,823:INFO:Creating metrics dataframe
2023-11-16 10:07:38,824:INFO:Uploading results into container
2023-11-16 10:07:38,824:INFO:Uploading model into container now
2023-11-16 10:07:38,825:INFO:_master_model_container: 3
2023-11-16 10:07:38,825:INFO:_display_container: 2
2023-11-16 10:07:38,825:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6235, splitter='best')
2023-11-16 10:07:38,825:INFO:create_model() successfully completed......................................
2023-11-16 10:07:38,852:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:38,853:INFO:Creating metrics dataframe
2023-11-16 10:07:38,855:INFO:Initializing SVM - Linear Kernel
2023-11-16 10:07:38,855:INFO:Total runtime is 0.009201121330261231 minutes
2023-11-16 10:07:38,855:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:38,855:INFO:Initializing create_model()
2023-11-16 10:07:38,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,856:INFO:Checking exceptions
2023-11-16 10:07:38,856:INFO:Importing libraries
2023-11-16 10:07:38,856:INFO:Copying training dataset
2023-11-16 10:07:38,857:INFO:Defining folds
2023-11-16 10:07:38,857:INFO:Declaring metric variables
2023-11-16 10:07:38,857:INFO:Importing untrained model
2023-11-16 10:07:38,858:INFO:SVM - Linear Kernel Imported successfully
2023-11-16 10:07:38,858:INFO:Starting cross validation
2023-11-16 10:07:38,858:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,874:WARNING:create_model() for svm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 10:07:38,874:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 10:07:38,874:INFO:Initializing create_model()
2023-11-16 10:07:38,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,874:INFO:Checking exceptions
2023-11-16 10:07:38,874:INFO:Importing libraries
2023-11-16 10:07:38,875:INFO:Copying training dataset
2023-11-16 10:07:38,876:INFO:Defining folds
2023-11-16 10:07:38,876:INFO:Declaring metric variables
2023-11-16 10:07:38,876:INFO:Importing untrained model
2023-11-16 10:07:38,876:INFO:SVM - Linear Kernel Imported successfully
2023-11-16 10:07:38,877:INFO:Starting cross validation
2023-11-16 10:07:38,877:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,891:ERROR:create_model() for svm raised an exception or returned all 0.0:
2023-11-16 10:07:38,892:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 10:07:38,892:INFO:Initializing Ridge Classifier
2023-11-16 10:07:38,892:INFO:Total runtime is 0.009817826747894288 minutes
2023-11-16 10:07:38,892:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:38,892:INFO:Initializing create_model()
2023-11-16 10:07:38,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,892:INFO:Checking exceptions
2023-11-16 10:07:38,893:INFO:Importing libraries
2023-11-16 10:07:38,893:INFO:Copying training dataset
2023-11-16 10:07:38,894:INFO:Defining folds
2023-11-16 10:07:38,894:INFO:Declaring metric variables
2023-11-16 10:07:38,894:INFO:Importing untrained model
2023-11-16 10:07:38,894:INFO:Ridge Classifier Imported successfully
2023-11-16 10:07:38,895:INFO:Starting cross validation
2023-11-16 10:07:38,895:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,902:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:07:38,903:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,903:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,904:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,905:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,909:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:07:38,910:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,911:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,912:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,912:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,917:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:07:38,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,920:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,925:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:07:38,925:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,926:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,927:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,927:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,932:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:07:38,933:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,934:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,935:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,935:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,936:INFO:Calculating mean and std
2023-11-16 10:07:38,936:INFO:Creating metrics dataframe
2023-11-16 10:07:38,937:INFO:Uploading results into container
2023-11-16 10:07:38,937:INFO:Uploading model into container now
2023-11-16 10:07:38,938:INFO:_master_model_container: 4
2023-11-16 10:07:38,938:INFO:_display_container: 2
2023-11-16 10:07:38,938:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6235, solver='auto',
                tol=0.0001)
2023-11-16 10:07:38,938:INFO:create_model() successfully completed......................................
2023-11-16 10:07:38,966:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:38,966:INFO:Creating metrics dataframe
2023-11-16 10:07:38,968:INFO:Initializing Quadratic Discriminant Analysis
2023-11-16 10:07:38,968:INFO:Total runtime is 0.011089416344960532 minutes
2023-11-16 10:07:38,968:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:38,969:INFO:Initializing create_model()
2023-11-16 10:07:38,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,969:INFO:Checking exceptions
2023-11-16 10:07:38,969:INFO:Importing libraries
2023-11-16 10:07:38,969:INFO:Copying training dataset
2023-11-16 10:07:38,970:INFO:Defining folds
2023-11-16 10:07:38,970:INFO:Declaring metric variables
2023-11-16 10:07:38,971:INFO:Importing untrained model
2023-11-16 10:07:38,971:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-16 10:07:38,971:INFO:Starting cross validation
2023-11-16 10:07:38,972:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,986:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 10:07:38,986:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 10:07:38,987:INFO:Initializing create_model()
2023-11-16 10:07:38,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,987:INFO:Checking exceptions
2023-11-16 10:07:38,987:INFO:Importing libraries
2023-11-16 10:07:38,987:INFO:Copying training dataset
2023-11-16 10:07:38,988:INFO:Defining folds
2023-11-16 10:07:38,989:INFO:Declaring metric variables
2023-11-16 10:07:38,989:INFO:Importing untrained model
2023-11-16 10:07:38,989:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-16 10:07:38,989:INFO:Starting cross validation
2023-11-16 10:07:38,990:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:39,003:ERROR:create_model() for qda raised an exception or returned all 0.0:
2023-11-16 10:07:39,003:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 10:07:39,003:INFO:Initializing Ada Boost Classifier
2023-11-16 10:07:39,004:INFO:Total runtime is 0.01167870362599691 minutes
2023-11-16 10:07:39,004:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:39,004:INFO:Initializing create_model()
2023-11-16 10:07:39,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:39,004:INFO:Checking exceptions
2023-11-16 10:07:39,004:INFO:Importing libraries
2023-11-16 10:07:39,004:INFO:Copying training dataset
2023-11-16 10:07:39,005:INFO:Defining folds
2023-11-16 10:07:39,005:INFO:Declaring metric variables
2023-11-16 10:07:39,006:INFO:Importing untrained model
2023-11-16 10:07:39,006:INFO:Ada Boost Classifier Imported successfully
2023-11-16 10:07:39,006:INFO:Starting cross validation
2023-11-16 10:07:39,006:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:39,012:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,013:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,014:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,014:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,015:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,020:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,021:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,022:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,022:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,023:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,028:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,028:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,029:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,030:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,030:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,035:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,036:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,037:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,038:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,038:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,043:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,044:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,044:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,045:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,046:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,046:INFO:Calculating mean and std
2023-11-16 10:07:39,047:INFO:Creating metrics dataframe
2023-11-16 10:07:39,048:INFO:Uploading results into container
2023-11-16 10:07:39,048:INFO:Uploading model into container now
2023-11-16 10:07:39,048:INFO:_master_model_container: 5
2023-11-16 10:07:39,049:INFO:_display_container: 2
2023-11-16 10:07:39,049:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6235)
2023-11-16 10:07:39,049:INFO:create_model() successfully completed......................................
2023-11-16 10:07:39,077:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:39,077:INFO:Creating metrics dataframe
2023-11-16 10:07:39,079:INFO:Initializing Linear Discriminant Analysis
2023-11-16 10:07:39,079:INFO:Total runtime is 0.01294372081756592 minutes
2023-11-16 10:07:39,080:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:39,080:INFO:Initializing create_model()
2023-11-16 10:07:39,080:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:39,080:INFO:Checking exceptions
2023-11-16 10:07:39,080:INFO:Importing libraries
2023-11-16 10:07:39,080:INFO:Copying training dataset
2023-11-16 10:07:39,082:INFO:Defining folds
2023-11-16 10:07:39,082:INFO:Declaring metric variables
2023-11-16 10:07:39,082:INFO:Importing untrained model
2023-11-16 10:07:39,082:INFO:Linear Discriminant Analysis Imported successfully
2023-11-16 10:07:39,082:INFO:Starting cross validation
2023-11-16 10:07:39,083:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:39,090:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:07:39,091:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,092:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,092:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,093:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,098:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:07:39,099:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,100:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,100:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,101:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,106:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:07:39,107:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,107:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,108:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,109:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,114:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:07:39,114:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,115:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,116:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,116:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,122:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:07:39,123:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,124:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,124:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,125:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,126:INFO:Calculating mean and std
2023-11-16 10:07:39,126:INFO:Creating metrics dataframe
2023-11-16 10:07:39,127:INFO:Uploading results into container
2023-11-16 10:07:39,128:INFO:Uploading model into container now
2023-11-16 10:07:39,128:INFO:_master_model_container: 6
2023-11-16 10:07:39,128:INFO:_display_container: 2
2023-11-16 10:07:39,128:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-16 10:07:39,129:INFO:create_model() successfully completed......................................
2023-11-16 10:07:39,158:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:39,158:INFO:Creating metrics dataframe
2023-11-16 10:07:39,160:INFO:Initializing Extra Trees Classifier
2023-11-16 10:07:39,160:INFO:Total runtime is 0.014289323488871259 minutes
2023-11-16 10:07:39,160:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:39,161:INFO:Initializing create_model()
2023-11-16 10:07:39,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:39,161:INFO:Checking exceptions
2023-11-16 10:07:39,161:INFO:Importing libraries
2023-11-16 10:07:39,161:INFO:Copying training dataset
2023-11-16 10:07:39,162:INFO:Defining folds
2023-11-16 10:07:39,162:INFO:Declaring metric variables
2023-11-16 10:07:39,162:INFO:Importing untrained model
2023-11-16 10:07:39,163:INFO:Extra Trees Classifier Imported successfully
2023-11-16 10:07:39,163:INFO:Starting cross validation
2023-11-16 10:07:39,163:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:39,260:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,261:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,262:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,263:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,263:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,361:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,362:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,363:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,364:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,364:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,462:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,463:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,464:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,465:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,465:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,570:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,571:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,572:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,573:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,573:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,673:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,674:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,675:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,676:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,676:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,677:INFO:Calculating mean and std
2023-11-16 10:07:39,677:INFO:Creating metrics dataframe
2023-11-16 10:07:39,679:INFO:Uploading results into container
2023-11-16 10:07:39,679:INFO:Uploading model into container now
2023-11-16 10:07:39,679:INFO:_master_model_container: 7
2023-11-16 10:07:39,680:INFO:_display_container: 2
2023-11-16 10:07:39,680:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6235, verbose=0, warm_start=False)
2023-11-16 10:07:39,680:INFO:create_model() successfully completed......................................
2023-11-16 10:07:39,710:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:39,710:INFO:Creating metrics dataframe
2023-11-16 10:07:39,712:INFO:Initializing Light Gradient Boosting Machine
2023-11-16 10:07:39,712:INFO:Total runtime is 0.023488962650299074 minutes
2023-11-16 10:07:39,712:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:39,713:INFO:Initializing create_model()
2023-11-16 10:07:39,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:39,713:INFO:Checking exceptions
2023-11-16 10:07:39,713:INFO:Importing libraries
2023-11-16 10:07:39,713:INFO:Copying training dataset
2023-11-16 10:07:39,714:INFO:Defining folds
2023-11-16 10:07:39,714:INFO:Declaring metric variables
2023-11-16 10:07:39,715:INFO:Importing untrained model
2023-11-16 10:07:39,715:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-16 10:07:39,715:INFO:Starting cross validation
2023-11-16 10:07:39,716:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:39,720:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:07:39,721:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 59
2023-11-16 10:07:39,721:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000058 seconds.
2023-11-16 10:07:39,721:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:07:39,721:INFO:[LightGBM] [Info] Total Bins 254
2023-11-16 10:07:39,721:INFO:[LightGBM] [Info] Number of data points in the train set: 59, number of used features: 12
2023-11-16 10:07:39,722:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:07:39,722:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:07:39,722:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,722:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,722:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,722:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,732:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,732:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,732:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,740:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:07:39,741:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,742:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,743:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,744:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,748:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:07:39,748:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 59
2023-11-16 10:07:39,748:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000026 seconds.
2023-11-16 10:07:39,749:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:07:39,749:INFO:[LightGBM] [Info] Total Bins 255
2023-11-16 10:07:39,749:INFO:[LightGBM] [Info] Number of data points in the train set: 59, number of used features: 12
2023-11-16 10:07:39,749:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:07:39,749:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:07:39,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,763:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:07:39,764:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,764:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,765:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,766:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,769:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:07:39,769:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 59
2023-11-16 10:07:39,770:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000023 seconds.
2023-11-16 10:07:39,770:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:07:39,770:INFO:[LightGBM] [Info] Total Bins 256
2023-11-16 10:07:39,770:INFO:[LightGBM] [Info] Number of data points in the train set: 59, number of used features: 12
2023-11-16 10:07:39,770:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:07:39,770:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:07:39,770:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,784:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:07:39,785:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,785:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,786:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,787:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,790:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:07:39,790:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 59
2023-11-16 10:07:39,791:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000022 seconds.
2023-11-16 10:07:39,791:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:07:39,791:INFO:[LightGBM] [Info] Total Bins 254
2023-11-16 10:07:39,791:INFO:[LightGBM] [Info] Number of data points in the train set: 59, number of used features: 12
2023-11-16 10:07:39,791:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:07:39,791:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,803:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,805:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:07:39,806:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,807:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,807:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,808:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,813:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:07:39,813:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 60
2023-11-16 10:07:39,813:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000023 seconds.
2023-11-16 10:07:39,813:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:07:39,813:INFO:[LightGBM] [Info] Total Bins 257
2023-11-16 10:07:39,813:INFO:[LightGBM] [Info] Number of data points in the train set: 60, number of used features: 12
2023-11-16 10:07:39,814:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:07:39,814:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:07:39,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,828:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:07:39,829:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,829:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,830:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,831:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,831:INFO:Calculating mean and std
2023-11-16 10:07:39,832:INFO:Creating metrics dataframe
2023-11-16 10:07:39,833:INFO:Uploading results into container
2023-11-16 10:07:39,834:INFO:Uploading model into container now
2023-11-16 10:07:39,834:INFO:_master_model_container: 8
2023-11-16 10:07:39,834:INFO:_display_container: 2
2023-11-16 10:07:39,834:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6235, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-16 10:07:39,834:INFO:create_model() successfully completed......................................
2023-11-16 10:07:39,864:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:39,864:INFO:Creating metrics dataframe
2023-11-16 10:07:39,866:INFO:Initializing Dummy Classifier
2023-11-16 10:07:39,866:INFO:Total runtime is 0.026060946782430015 minutes
2023-11-16 10:07:39,867:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:39,867:INFO:Initializing create_model()
2023-11-16 10:07:39,867:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:39,867:INFO:Checking exceptions
2023-11-16 10:07:39,867:INFO:Importing libraries
2023-11-16 10:07:39,867:INFO:Copying training dataset
2023-11-16 10:07:39,868:INFO:Defining folds
2023-11-16 10:07:39,869:INFO:Declaring metric variables
2023-11-16 10:07:39,869:INFO:Importing untrained model
2023-11-16 10:07:39,869:INFO:Dummy Classifier Imported successfully
2023-11-16 10:07:39,869:INFO:Starting cross validation
2023-11-16 10:07:39,870:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:39,874:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,875:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,876:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,877:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,877:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,881:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,882:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,883:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,883:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,884:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,888:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,888:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,889:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,890:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,890:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,894:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,895:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,896:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,896:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,897:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,901:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,901:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,902:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,903:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,903:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,904:INFO:Calculating mean and std
2023-11-16 10:07:39,904:INFO:Creating metrics dataframe
2023-11-16 10:07:39,905:INFO:Uploading results into container
2023-11-16 10:07:39,906:INFO:Uploading model into container now
2023-11-16 10:07:39,906:INFO:_master_model_container: 9
2023-11-16 10:07:39,906:INFO:_display_container: 2
2023-11-16 10:07:39,906:INFO:DummyClassifier(constant=None, random_state=6235, strategy='prior')
2023-11-16 10:07:39,906:INFO:create_model() successfully completed......................................
2023-11-16 10:07:39,932:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:39,932:INFO:Creating metrics dataframe
2023-11-16 10:07:39,935:INFO:Initializing create_model()
2023-11-16 10:07:39,935:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:39,935:INFO:Checking exceptions
2023-11-16 10:07:39,936:INFO:Importing libraries
2023-11-16 10:07:39,936:INFO:Copying training dataset
2023-11-16 10:07:39,937:INFO:Defining folds
2023-11-16 10:07:39,937:INFO:Declaring metric variables
2023-11-16 10:07:39,937:INFO:Importing untrained model
2023-11-16 10:07:39,938:INFO:Declaring custom model
2023-11-16 10:07:39,938:INFO:K Neighbors Classifier Imported successfully
2023-11-16 10:07:39,938:INFO:Cross validation set to False
2023-11-16 10:07:39,938:INFO:Fitting Model
2023-11-16 10:07:39,942:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 10:07:39,942:INFO:create_model() successfully completed......................................
2023-11-16 10:07:39,973:INFO:_master_model_container: 9
2023-11-16 10:07:39,973:INFO:_display_container: 2
2023-11-16 10:07:39,973:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 10:07:39,973:INFO:compare_models() successfully completed......................................
2023-11-16 10:40:38,459:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:40:38,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:40:38,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:40:38,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:30,256:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:30,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:30,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:30,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,695:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,937:INFO:PyCaret ClassificationExperiment
2023-11-16 10:43:48,937:INFO:Logging name: clf-default-name
2023-11-16 10:43:48,937:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-16 10:43:48,938:INFO:version 3.2.0
2023-11-16 10:43:48,938:INFO:Initializing setup()
2023-11-16 10:43:48,938:INFO:self.USI: e4c3
2023-11-16 10:43:48,938:INFO:self._variable_keys: {'USI', 'y', 'fold_shuffle_param', 'memory', 'exp_name_log', 'gpu_param', 'X_test', 'target_param', 'fold_generator', 'exp_id', 'fold_groups_param', 'idx', '_ml_usecase', '_available_plots', 'seed', 'data', 'y_test', 'fix_imbalance', 'y_train', 'X_train', 'is_multiclass', 'X', 'log_plots_param', 'html_param', 'pipeline', 'n_jobs_param', 'gpu_n_jobs_param', 'logging_param'}
2023-11-16 10:43:48,938:INFO:Checking environment
2023-11-16 10:43:48,938:INFO:python_version: 3.8.18
2023-11-16 10:43:48,938:INFO:python_build: ('default', 'Nov  1 2023 11:08:38')
2023-11-16 10:43:48,939:INFO:machine: aarch64
2023-11-16 10:43:48,939:INFO:platform: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-16 10:43:48,940:INFO:Memory: svmem(total=8225300480, available=7157551104, percent=13.0, used=858771456, free=3675680768, active=1983275008, inactive=2022416384, buffers=106815488, cached=3584032768, shared=1400832, slab=367796224)
2023-11-16 10:43:48,941:INFO:Physical Core: 12
2023-11-16 10:43:48,941:INFO:Logical Core: 12
2023-11-16 10:43:48,942:INFO:Checking libraries
2023-11-16 10:43:48,942:INFO:System:
2023-11-16 10:43:48,942:INFO:    python: 3.8.18 (default, Nov  1 2023, 11:08:38)  [GCC 12.2.0]
2023-11-16 10:43:48,942:INFO:executable: /usr/local/bin/python
2023-11-16 10:43:48,942:INFO:   machine: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-16 10:43:48,942:INFO:PyCaret required dependencies:
2023-11-16 10:43:48,952:INFO:                 pip: 23.3.1
2023-11-16 10:43:48,952:INFO:          setuptools: 57.5.0
2023-11-16 10:43:48,952:INFO:             pycaret: 3.2.0
2023-11-16 10:43:48,952:INFO:             IPython: 8.12.3
2023-11-16 10:43:48,952:INFO:          ipywidgets: 8.1.1
2023-11-16 10:43:48,953:INFO:                tqdm: 4.66.1
2023-11-16 10:43:48,953:INFO:               numpy: 1.24.4
2023-11-16 10:43:48,953:INFO:              pandas: 1.5.3
2023-11-16 10:43:48,953:INFO:              jinja2: 3.1.2
2023-11-16 10:43:48,953:INFO:               scipy: 1.10.1
2023-11-16 10:43:48,953:INFO:              joblib: 1.3.2
2023-11-16 10:43:48,953:INFO:             sklearn: 1.2.2
2023-11-16 10:43:48,953:INFO:                pyod: 1.1.1
2023-11-16 10:43:48,953:INFO:            imblearn: 0.11.0
2023-11-16 10:43:48,953:INFO:   category_encoders: 2.6.3
2023-11-16 10:43:48,954:INFO:            lightgbm: 4.1.0
2023-11-16 10:43:48,954:INFO:               numba: 0.58.1
2023-11-16 10:43:48,954:INFO:            requests: 2.31.0
2023-11-16 10:43:48,954:INFO:          matplotlib: 3.6.0
2023-11-16 10:43:48,954:INFO:          scikitplot: 0.3.7
2023-11-16 10:43:48,954:INFO:         yellowbrick: 1.5
2023-11-16 10:43:48,954:INFO:              plotly: 5.18.0
2023-11-16 10:43:48,954:INFO:    plotly-resampler: Not installed
2023-11-16 10:43:48,954:INFO:             kaleido: 0.2.1
2023-11-16 10:43:48,955:INFO:           schemdraw: 0.15
2023-11-16 10:43:48,955:INFO:         statsmodels: 0.14.0
2023-11-16 10:43:48,955:INFO:              sktime: 0.21.1
2023-11-16 10:43:48,955:INFO:               tbats: 1.1.3
2023-11-16 10:43:48,955:INFO:            pmdarima: 2.0.4
2023-11-16 10:43:48,955:INFO:              psutil: 5.9.6
2023-11-16 10:43:48,955:INFO:          markupsafe: 2.1.3
2023-11-16 10:43:48,955:INFO:             pickle5: Not installed
2023-11-16 10:43:48,955:INFO:         cloudpickle: 3.0.0
2023-11-16 10:43:48,955:INFO:         deprecation: 2.1.0
2023-11-16 10:43:48,956:INFO:              xxhash: 3.4.1
2023-11-16 10:43:48,956:INFO:           wurlitzer: 3.0.3
2023-11-16 10:43:48,956:INFO:PyCaret optional dependencies:
2023-11-16 10:43:48,966:INFO:                shap: Not installed
2023-11-16 10:43:48,966:INFO:           interpret: Not installed
2023-11-16 10:43:48,966:INFO:                umap: Not installed
2023-11-16 10:43:48,966:INFO:     ydata_profiling: Not installed
2023-11-16 10:43:48,966:INFO:  explainerdashboard: Not installed
2023-11-16 10:43:48,966:INFO:             autoviz: Not installed
2023-11-16 10:43:48,966:INFO:           fairlearn: Not installed
2023-11-16 10:43:48,966:INFO:          deepchecks: Not installed
2023-11-16 10:43:48,966:INFO:             xgboost: Not installed
2023-11-16 10:43:48,967:INFO:            catboost: Not installed
2023-11-16 10:43:48,967:INFO:              kmodes: Not installed
2023-11-16 10:43:48,967:INFO:             mlxtend: Not installed
2023-11-16 10:43:48,967:INFO:       statsforecast: Not installed
2023-11-16 10:43:48,967:INFO:        tune_sklearn: Not installed
2023-11-16 10:43:48,967:INFO:                 ray: Not installed
2023-11-16 10:43:48,967:INFO:            hyperopt: Not installed
2023-11-16 10:43:48,967:INFO:              optuna: Not installed
2023-11-16 10:43:48,967:INFO:               skopt: Not installed
2023-11-16 10:43:48,967:INFO:              mlflow: Not installed
2023-11-16 10:43:48,968:INFO:              gradio: Not installed
2023-11-16 10:43:48,968:INFO:             fastapi: Not installed
2023-11-16 10:43:48,968:INFO:             uvicorn: Not installed
2023-11-16 10:43:48,968:INFO:              m2cgen: Not installed
2023-11-16 10:43:48,968:INFO:           evidently: Not installed
2023-11-16 10:43:48,968:INFO:               fugue: Not installed
2023-11-16 10:43:48,968:INFO:           streamlit: Not installed
2023-11-16 10:43:48,968:INFO:             prophet: Not installed
2023-11-16 10:43:48,968:INFO:None
2023-11-16 10:43:48,968:INFO:Set up GPU usage.
2023-11-16 10:43:48,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,969:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-16 10:43:48,969:INFO:Set up data.
2023-11-16 10:43:48,972:INFO:Set up folding strategy.
2023-11-16 10:43:48,972:INFO:Set up train/test split.
2023-11-16 10:43:48,974:INFO:Set up index.
2023-11-16 10:43:48,974:INFO:Assigning column types.
2023-11-16 10:43:48,975:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-16 10:43:48,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-16 10:43:48,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,993:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 10:43:48,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-16 10:43:49,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,045:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 10:43:49,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,056:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,061:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-16 10:43:49,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,080:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 10:43:49,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,089:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,113:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,113:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,114:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 10:43:49,114:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,122:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,124:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,130:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-16 10:43:49,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,157:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,159:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,164:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,182:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,182:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,182:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,193:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,193:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,199:INFO:Preparing preprocessing pipeline...
2023-11-16 10:43:49,200:INFO:Set up simple imputation.
2023-11-16 10:43:49,209:INFO:Finished creating preprocessing pipeline.
2023-11-16 10:43:49,211:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-16 10:43:49,211:INFO:Creating final display dataframe.
2023-11-16 10:43:49,234:INFO:Setup _display_container:                     Description             Value
0                    Session id               492
1                        Target            target
2                   Target type        Multiclass
3           Original data shape         (106, 13)
4        Transformed data shape         (106, 13)
5   Transformed train set shape          (74, 13)
6    Transformed test set shape          (32, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              e4c3
2023-11-16 10:43:49,236:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,255:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,265:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,300:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,300:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,304:INFO:setup() successfully completed in 0.37s...............
2023-11-16 10:43:49,304:INFO:Initializing compare_models()
2023-11-16 10:43:49,304:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-16 10:43:49,305:INFO:Checking exceptions
2023-11-16 10:43:49,306:INFO:Preparing display monitor
2023-11-16 10:43:49,308:INFO:Initializing Logistic Regression
2023-11-16 10:43:49,308:INFO:Total runtime is 2.745787302652995e-06 minutes
2023-11-16 10:43:49,308:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,308:INFO:Initializing create_model()
2023-11-16 10:43:49,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,309:INFO:Checking exceptions
2023-11-16 10:43:49,309:INFO:Importing libraries
2023-11-16 10:43:49,309:INFO:Copying training dataset
2023-11-16 10:43:49,310:INFO:Defining folds
2023-11-16 10:43:49,310:INFO:Declaring metric variables
2023-11-16 10:43:49,310:INFO:Importing untrained model
2023-11-16 10:43:49,311:INFO:Logistic Regression Imported successfully
2023-11-16 10:43:49,311:INFO:Starting cross validation
2023-11-16 10:43:49,311:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,327:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 10:43:49,327:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2023-11-16 10:43:49,327:INFO:Initializing create_model()
2023-11-16 10:43:49,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,328:INFO:Checking exceptions
2023-11-16 10:43:49,328:INFO:Importing libraries
2023-11-16 10:43:49,328:INFO:Copying training dataset
2023-11-16 10:43:49,329:INFO:Defining folds
2023-11-16 10:43:49,329:INFO:Declaring metric variables
2023-11-16 10:43:49,329:INFO:Importing untrained model
2023-11-16 10:43:49,329:INFO:Logistic Regression Imported successfully
2023-11-16 10:43:49,330:INFO:Starting cross validation
2023-11-16 10:43:49,330:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,344:ERROR:create_model() for lr raised an exception or returned all 0.0:
2023-11-16 10:43:49,345:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2023-11-16 10:43:49,345:INFO:Initializing K Neighbors Classifier
2023-11-16 10:43:49,345:INFO:Total runtime is 0.0006144245465596517 minutes
2023-11-16 10:43:49,345:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,345:INFO:Initializing create_model()
2023-11-16 10:43:49,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,345:INFO:Checking exceptions
2023-11-16 10:43:49,345:INFO:Importing libraries
2023-11-16 10:43:49,346:INFO:Copying training dataset
2023-11-16 10:43:49,347:INFO:Defining folds
2023-11-16 10:43:49,347:INFO:Declaring metric variables
2023-11-16 10:43:49,347:INFO:Importing untrained model
2023-11-16 10:43:49,347:INFO:K Neighbors Classifier Imported successfully
2023-11-16 10:43:49,347:INFO:Starting cross validation
2023-11-16 10:43:49,348:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,384:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,385:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,386:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,387:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,388:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,420:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,421:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,422:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,423:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,423:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,457:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,458:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,459:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,460:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,460:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,493:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,494:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,495:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,496:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,496:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,528:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,529:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,530:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,531:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,531:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,532:INFO:Calculating mean and std
2023-11-16 10:43:49,533:INFO:Creating metrics dataframe
2023-11-16 10:43:49,534:INFO:Uploading results into container
2023-11-16 10:43:49,535:INFO:Uploading model into container now
2023-11-16 10:43:49,535:INFO:_master_model_container: 1
2023-11-16 10:43:49,535:INFO:_display_container: 2
2023-11-16 10:43:49,535:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 10:43:49,536:INFO:create_model() successfully completed......................................
2023-11-16 10:43:49,581:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:49,581:INFO:Creating metrics dataframe
2023-11-16 10:43:49,583:INFO:Initializing Naive Bayes
2023-11-16 10:43:49,584:INFO:Total runtime is 0.004594496885935466 minutes
2023-11-16 10:43:49,584:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,584:INFO:Initializing create_model()
2023-11-16 10:43:49,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,585:INFO:Checking exceptions
2023-11-16 10:43:49,585:INFO:Importing libraries
2023-11-16 10:43:49,585:INFO:Copying training dataset
2023-11-16 10:43:49,586:INFO:Defining folds
2023-11-16 10:43:49,586:INFO:Declaring metric variables
2023-11-16 10:43:49,587:INFO:Importing untrained model
2023-11-16 10:43:49,587:INFO:Naive Bayes Imported successfully
2023-11-16 10:43:49,587:INFO:Starting cross validation
2023-11-16 10:43:49,587:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,594:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,594:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,595:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,596:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,596:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,601:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,602:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,603:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,603:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,604:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,609:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,609:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,610:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,611:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,611:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,616:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,617:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,617:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,618:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,618:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,623:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,624:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,625:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,625:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,626:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,627:INFO:Calculating mean and std
2023-11-16 10:43:49,627:INFO:Creating metrics dataframe
2023-11-16 10:43:49,628:INFO:Uploading results into container
2023-11-16 10:43:49,628:INFO:Uploading model into container now
2023-11-16 10:43:49,629:INFO:_master_model_container: 2
2023-11-16 10:43:49,629:INFO:_display_container: 2
2023-11-16 10:43:49,629:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-16 10:43:49,629:INFO:create_model() successfully completed......................................
2023-11-16 10:43:49,659:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:49,659:INFO:Creating metrics dataframe
2023-11-16 10:43:49,661:INFO:Initializing Decision Tree Classifier
2023-11-16 10:43:49,661:INFO:Total runtime is 0.005887170632680258 minutes
2023-11-16 10:43:49,661:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,662:INFO:Initializing create_model()
2023-11-16 10:43:49,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,662:INFO:Checking exceptions
2023-11-16 10:43:49,662:INFO:Importing libraries
2023-11-16 10:43:49,662:INFO:Copying training dataset
2023-11-16 10:43:49,663:INFO:Defining folds
2023-11-16 10:43:49,664:INFO:Declaring metric variables
2023-11-16 10:43:49,664:INFO:Importing untrained model
2023-11-16 10:43:49,664:INFO:Decision Tree Classifier Imported successfully
2023-11-16 10:43:49,664:INFO:Starting cross validation
2023-11-16 10:43:49,665:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,671:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,672:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,672:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,673:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,674:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,679:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,679:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,680:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,681:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,681:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,686:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,687:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,688:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,688:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,689:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,694:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,694:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,695:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,696:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,696:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,701:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,702:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,702:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,703:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,704:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,704:INFO:Calculating mean and std
2023-11-16 10:43:49,705:INFO:Creating metrics dataframe
2023-11-16 10:43:49,706:INFO:Uploading results into container
2023-11-16 10:43:49,706:INFO:Uploading model into container now
2023-11-16 10:43:49,706:INFO:_master_model_container: 3
2023-11-16 10:43:49,706:INFO:_display_container: 2
2023-11-16 10:43:49,707:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=492, splitter='best')
2023-11-16 10:43:49,707:INFO:create_model() successfully completed......................................
2023-11-16 10:43:49,735:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:49,735:INFO:Creating metrics dataframe
2023-11-16 10:43:49,737:INFO:Initializing SVM - Linear Kernel
2023-11-16 10:43:49,737:INFO:Total runtime is 0.007153471310933432 minutes
2023-11-16 10:43:49,737:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,738:INFO:Initializing create_model()
2023-11-16 10:43:49,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,738:INFO:Checking exceptions
2023-11-16 10:43:49,738:INFO:Importing libraries
2023-11-16 10:43:49,738:INFO:Copying training dataset
2023-11-16 10:43:49,739:INFO:Defining folds
2023-11-16 10:43:49,739:INFO:Declaring metric variables
2023-11-16 10:43:49,739:INFO:Importing untrained model
2023-11-16 10:43:49,740:INFO:SVM - Linear Kernel Imported successfully
2023-11-16 10:43:49,740:INFO:Starting cross validation
2023-11-16 10:43:49,740:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,754:WARNING:create_model() for svm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 10:43:49,755:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 10:43:49,755:INFO:Initializing create_model()
2023-11-16 10:43:49,755:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,755:INFO:Checking exceptions
2023-11-16 10:43:49,755:INFO:Importing libraries
2023-11-16 10:43:49,755:INFO:Copying training dataset
2023-11-16 10:43:49,756:INFO:Defining folds
2023-11-16 10:43:49,756:INFO:Declaring metric variables
2023-11-16 10:43:49,757:INFO:Importing untrained model
2023-11-16 10:43:49,757:INFO:SVM - Linear Kernel Imported successfully
2023-11-16 10:43:49,757:INFO:Starting cross validation
2023-11-16 10:43:49,757:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,772:ERROR:create_model() for svm raised an exception or returned all 0.0:
2023-11-16 10:43:49,772:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 10:43:49,772:INFO:Initializing Ridge Classifier
2023-11-16 10:43:49,772:INFO:Total runtime is 0.007738610108693441 minutes
2023-11-16 10:43:49,772:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,773:INFO:Initializing create_model()
2023-11-16 10:43:49,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,773:INFO:Checking exceptions
2023-11-16 10:43:49,773:INFO:Importing libraries
2023-11-16 10:43:49,773:INFO:Copying training dataset
2023-11-16 10:43:49,774:INFO:Defining folds
2023-11-16 10:43:49,774:INFO:Declaring metric variables
2023-11-16 10:43:49,775:INFO:Importing untrained model
2023-11-16 10:43:49,775:INFO:Ridge Classifier Imported successfully
2023-11-16 10:43:49,775:INFO:Starting cross validation
2023-11-16 10:43:49,775:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,782:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:43:49,783:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,784:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,785:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,785:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,790:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:43:49,791:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,792:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,792:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,793:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,798:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:43:49,798:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,799:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,800:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,800:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,805:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:43:49,806:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,807:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,807:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,808:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,812:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:43:49,813:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,814:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,815:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,815:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,816:INFO:Calculating mean and std
2023-11-16 10:43:49,816:INFO:Creating metrics dataframe
2023-11-16 10:43:49,817:INFO:Uploading results into container
2023-11-16 10:43:49,818:INFO:Uploading model into container now
2023-11-16 10:43:49,818:INFO:_master_model_container: 4
2023-11-16 10:43:49,818:INFO:_display_container: 2
2023-11-16 10:43:49,818:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=492, solver='auto',
                tol=0.0001)
2023-11-16 10:43:49,818:INFO:create_model() successfully completed......................................
2023-11-16 10:43:49,846:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:49,846:INFO:Creating metrics dataframe
2023-11-16 10:43:49,848:INFO:Initializing Quadratic Discriminant Analysis
2023-11-16 10:43:49,848:INFO:Total runtime is 0.009008022149403891 minutes
2023-11-16 10:43:49,849:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,849:INFO:Initializing create_model()
2023-11-16 10:43:49,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,849:INFO:Checking exceptions
2023-11-16 10:43:49,849:INFO:Importing libraries
2023-11-16 10:43:49,849:INFO:Copying training dataset
2023-11-16 10:43:49,850:INFO:Defining folds
2023-11-16 10:43:49,850:INFO:Declaring metric variables
2023-11-16 10:43:49,851:INFO:Importing untrained model
2023-11-16 10:43:49,851:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-16 10:43:49,851:INFO:Starting cross validation
2023-11-16 10:43:49,851:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,864:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 10:43:49,865:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 10:43:49,865:INFO:Initializing create_model()
2023-11-16 10:43:49,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,865:INFO:Checking exceptions
2023-11-16 10:43:49,865:INFO:Importing libraries
2023-11-16 10:43:49,865:INFO:Copying training dataset
2023-11-16 10:43:49,866:INFO:Defining folds
2023-11-16 10:43:49,866:INFO:Declaring metric variables
2023-11-16 10:43:49,866:INFO:Importing untrained model
2023-11-16 10:43:49,867:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-16 10:43:49,867:INFO:Starting cross validation
2023-11-16 10:43:49,867:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,880:ERROR:create_model() for qda raised an exception or returned all 0.0:
2023-11-16 10:43:49,880:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 10:43:49,880:INFO:Initializing Ada Boost Classifier
2023-11-16 10:43:49,880:INFO:Total runtime is 0.009540192286173504 minutes
2023-11-16 10:43:49,881:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,881:INFO:Initializing create_model()
2023-11-16 10:43:49,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,881:INFO:Checking exceptions
2023-11-16 10:43:49,881:INFO:Importing libraries
2023-11-16 10:43:49,881:INFO:Copying training dataset
2023-11-16 10:43:49,882:INFO:Defining folds
2023-11-16 10:43:49,882:INFO:Declaring metric variables
2023-11-16 10:43:49,883:INFO:Importing untrained model
2023-11-16 10:43:49,883:INFO:Ada Boost Classifier Imported successfully
2023-11-16 10:43:49,883:INFO:Starting cross validation
2023-11-16 10:43:49,883:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,889:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,890:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,890:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,891:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,892:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,897:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,898:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,898:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,899:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,900:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,905:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,906:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,906:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,907:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,908:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,913:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,913:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,914:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,915:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,915:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,920:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,921:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,922:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,922:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,923:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,923:INFO:Calculating mean and std
2023-11-16 10:43:49,924:INFO:Creating metrics dataframe
2023-11-16 10:43:49,925:INFO:Uploading results into container
2023-11-16 10:43:49,925:INFO:Uploading model into container now
2023-11-16 10:43:49,925:INFO:_master_model_container: 5
2023-11-16 10:43:49,926:INFO:_display_container: 2
2023-11-16 10:43:49,926:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=492)
2023-11-16 10:43:49,926:INFO:create_model() successfully completed......................................
2023-11-16 10:43:49,954:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:49,954:INFO:Creating metrics dataframe
2023-11-16 10:43:49,956:INFO:Initializing Linear Discriminant Analysis
2023-11-16 10:43:49,956:INFO:Total runtime is 0.010806103547414146 minutes
2023-11-16 10:43:49,956:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,957:INFO:Initializing create_model()
2023-11-16 10:43:49,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,957:INFO:Checking exceptions
2023-11-16 10:43:49,957:INFO:Importing libraries
2023-11-16 10:43:49,957:INFO:Copying training dataset
2023-11-16 10:43:49,958:INFO:Defining folds
2023-11-16 10:43:49,958:INFO:Declaring metric variables
2023-11-16 10:43:49,958:INFO:Importing untrained model
2023-11-16 10:43:49,959:INFO:Linear Discriminant Analysis Imported successfully
2023-11-16 10:43:49,959:INFO:Starting cross validation
2023-11-16 10:43:49,959:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,966:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:43:49,967:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,967:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,968:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,968:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,973:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:43:49,974:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,975:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,976:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,976:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,981:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:43:49,982:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,982:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,983:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,983:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,988:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:43:49,989:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,990:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,991:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,991:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,996:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:43:49,996:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,997:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,998:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,998:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,999:INFO:Calculating mean and std
2023-11-16 10:43:49,999:INFO:Creating metrics dataframe
2023-11-16 10:43:50,001:INFO:Uploading results into container
2023-11-16 10:43:50,001:INFO:Uploading model into container now
2023-11-16 10:43:50,001:INFO:_master_model_container: 6
2023-11-16 10:43:50,001:INFO:_display_container: 2
2023-11-16 10:43:50,001:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-16 10:43:50,002:INFO:create_model() successfully completed......................................
2023-11-16 10:43:50,029:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:50,030:INFO:Creating metrics dataframe
2023-11-16 10:43:50,032:INFO:Initializing Extra Trees Classifier
2023-11-16 10:43:50,032:INFO:Total runtime is 0.012063606580098472 minutes
2023-11-16 10:43:50,032:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:50,032:INFO:Initializing create_model()
2023-11-16 10:43:50,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:50,032:INFO:Checking exceptions
2023-11-16 10:43:50,033:INFO:Importing libraries
2023-11-16 10:43:50,033:INFO:Copying training dataset
2023-11-16 10:43:50,034:INFO:Defining folds
2023-11-16 10:43:50,034:INFO:Declaring metric variables
2023-11-16 10:43:50,034:INFO:Importing untrained model
2023-11-16 10:43:50,034:INFO:Extra Trees Classifier Imported successfully
2023-11-16 10:43:50,035:INFO:Starting cross validation
2023-11-16 10:43:50,035:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:50,137:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,138:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,138:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,139:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,140:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,239:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,240:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,241:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,242:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,242:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,345:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,346:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,347:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,347:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,348:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,448:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,449:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,450:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,451:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,451:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,540:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,541:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,542:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,543:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,544:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,544:INFO:Calculating mean and std
2023-11-16 10:43:50,545:INFO:Creating metrics dataframe
2023-11-16 10:43:50,546:INFO:Uploading results into container
2023-11-16 10:43:50,547:INFO:Uploading model into container now
2023-11-16 10:43:50,547:INFO:_master_model_container: 7
2023-11-16 10:43:50,547:INFO:_display_container: 2
2023-11-16 10:43:50,547:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=492, verbose=0, warm_start=False)
2023-11-16 10:43:50,547:INFO:create_model() successfully completed......................................
2023-11-16 10:43:50,577:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:50,577:INFO:Creating metrics dataframe
2023-11-16 10:43:50,580:INFO:Initializing Light Gradient Boosting Machine
2023-11-16 10:43:50,580:INFO:Total runtime is 0.021197013060251874 minutes
2023-11-16 10:43:50,580:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:50,580:INFO:Initializing create_model()
2023-11-16 10:43:50,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:50,580:INFO:Checking exceptions
2023-11-16 10:43:50,581:INFO:Importing libraries
2023-11-16 10:43:50,581:INFO:Copying training dataset
2023-11-16 10:43:50,582:INFO:Defining folds
2023-11-16 10:43:50,582:INFO:Declaring metric variables
2023-11-16 10:43:50,582:INFO:Importing untrained model
2023-11-16 10:43:50,582:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-16 10:43:50,583:INFO:Starting cross validation
2023-11-16 10:43:50,583:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:50,588:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:43:50,588:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 59
2023-11-16 10:43:50,589:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000077 seconds.
2023-11-16 10:43:50,589:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:43:50,589:INFO:[LightGBM] [Info] Total Bins 255
2023-11-16 10:43:50,590:INFO:[LightGBM] [Info] Number of data points in the train set: 59, number of used features: 12
2023-11-16 10:43:50,590:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:43:50,590:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:43:50,590:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,590:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,601:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,601:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,601:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,601:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,601:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,605:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:43:50,606:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,606:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,607:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,608:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,611:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:43:50,611:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 59
2023-11-16 10:43:50,612:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000032 seconds.
2023-11-16 10:43:50,612:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:43:50,612:INFO:[LightGBM] [Info] Total Bins 254
2023-11-16 10:43:50,612:INFO:[LightGBM] [Info] Number of data points in the train set: 59, number of used features: 12
2023-11-16 10:43:50,612:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:43:50,613:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:43:50,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,627:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:43:50,628:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,628:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,629:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,630:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,634:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:43:50,634:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 59
2023-11-16 10:43:50,637:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002065 seconds.
2023-11-16 10:43:50,637:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:43:50,637:INFO:[LightGBM] [Info] Total Bins 256
2023-11-16 10:43:50,638:INFO:[LightGBM] [Info] Number of data points in the train set: 59, number of used features: 12
2023-11-16 10:43:50,638:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:43:50,638:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:43:50,638:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,638:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,649:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,649:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,652:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:43:50,653:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,654:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,654:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,655:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,659:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:43:50,659:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 59
2023-11-16 10:43:50,662:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001661 seconds.
2023-11-16 10:43:50,662:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:43:50,662:INFO:[LightGBM] [Info] Total Bins 254
2023-11-16 10:43:50,662:INFO:[LightGBM] [Info] Number of data points in the train set: 59, number of used features: 12
2023-11-16 10:43:50,663:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:43:50,663:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:43:50,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,674:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,678:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:43:50,678:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,679:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,680:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,680:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,685:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:43:50,685:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 60
2023-11-16 10:43:50,685:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000031 seconds.
2023-11-16 10:43:50,685:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:43:50,685:INFO:[LightGBM] [Info] Total Bins 259
2023-11-16 10:43:50,686:INFO:[LightGBM] [Info] Number of data points in the train set: 60, number of used features: 12
2023-11-16 10:43:50,686:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:43:50,686:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:43:50,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,700:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:43:50,701:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,702:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,703:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,703:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,704:INFO:Calculating mean and std
2023-11-16 10:43:50,704:INFO:Creating metrics dataframe
2023-11-16 10:43:50,706:INFO:Uploading results into container
2023-11-16 10:43:50,706:INFO:Uploading model into container now
2023-11-16 10:43:50,706:INFO:_master_model_container: 8
2023-11-16 10:43:50,706:INFO:_display_container: 2
2023-11-16 10:43:50,707:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=492, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-16 10:43:50,707:INFO:create_model() successfully completed......................................
2023-11-16 10:43:50,736:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:50,736:INFO:Creating metrics dataframe
2023-11-16 10:43:50,738:INFO:Initializing Dummy Classifier
2023-11-16 10:43:50,738:INFO:Total runtime is 0.02384070952733358 minutes
2023-11-16 10:43:50,739:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:50,739:INFO:Initializing create_model()
2023-11-16 10:43:50,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:50,739:INFO:Checking exceptions
2023-11-16 10:43:50,739:INFO:Importing libraries
2023-11-16 10:43:50,739:INFO:Copying training dataset
2023-11-16 10:43:50,741:INFO:Defining folds
2023-11-16 10:43:50,741:INFO:Declaring metric variables
2023-11-16 10:43:50,741:INFO:Importing untrained model
2023-11-16 10:43:50,741:INFO:Dummy Classifier Imported successfully
2023-11-16 10:43:50,741:INFO:Starting cross validation
2023-11-16 10:43:50,742:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:50,746:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,747:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,748:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,749:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,749:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,753:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,754:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,755:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,756:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,756:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,760:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,761:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,762:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,762:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,763:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,767:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,767:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,768:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,769:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,769:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,773:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,774:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,775:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,776:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,776:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,777:INFO:Calculating mean and std
2023-11-16 10:43:50,777:INFO:Creating metrics dataframe
2023-11-16 10:43:50,778:INFO:Uploading results into container
2023-11-16 10:43:50,779:INFO:Uploading model into container now
2023-11-16 10:43:50,779:INFO:_master_model_container: 9
2023-11-16 10:43:50,779:INFO:_display_container: 2
2023-11-16 10:43:50,779:INFO:DummyClassifier(constant=None, random_state=492, strategy='prior')
2023-11-16 10:43:50,779:INFO:create_model() successfully completed......................................
2023-11-16 10:43:50,807:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:50,807:INFO:Creating metrics dataframe
2023-11-16 10:43:50,810:INFO:Initializing create_model()
2023-11-16 10:43:50,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:50,810:INFO:Checking exceptions
2023-11-16 10:43:50,811:INFO:Importing libraries
2023-11-16 10:43:50,811:INFO:Copying training dataset
2023-11-16 10:43:50,812:INFO:Defining folds
2023-11-16 10:43:50,812:INFO:Declaring metric variables
2023-11-16 10:43:50,812:INFO:Importing untrained model
2023-11-16 10:43:50,812:INFO:Declaring custom model
2023-11-16 10:43:50,812:INFO:K Neighbors Classifier Imported successfully
2023-11-16 10:43:50,813:INFO:Cross validation set to False
2023-11-16 10:43:50,813:INFO:Fitting Model
2023-11-16 10:43:50,816:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 10:43:50,816:INFO:create_model() successfully completed......................................
2023-11-16 10:43:50,845:INFO:_master_model_container: 9
2023-11-16 10:43:50,845:INFO:_display_container: 2
2023-11-16 10:43:50,846:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 10:43:50,846:INFO:compare_models() successfully completed......................................
2023-11-20 10:03:20,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,478:INFO:PyCaret ClassificationExperiment
2023-11-20 10:03:20,479:INFO:Logging name: clf-default-name
2023-11-20 10:03:20,480:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-20 10:03:20,480:INFO:version 3.2.0
2023-11-20 10:03:20,480:INFO:Initializing setup()
2023-11-20 10:03:20,481:INFO:self.USI: 3b33
2023-11-20 10:03:20,481:INFO:self._variable_keys: {'exp_id', 'exp_name_log', 'log_plots_param', 'y_train', 'y_test', 'y', 'target_param', 'data', 'X_test', 'USI', 'gpu_param', 'seed', 'memory', 'fold_generator', 'fix_imbalance', 'pipeline', 'is_multiclass', 'idx', 'X_train', 'html_param', 'fold_groups_param', '_available_plots', 'X', 'gpu_n_jobs_param', 'logging_param', 'fold_shuffle_param', '_ml_usecase', 'n_jobs_param'}
2023-11-20 10:03:20,481:INFO:Checking environment
2023-11-20 10:03:20,481:INFO:python_version: 3.8.18
2023-11-20 10:03:20,482:INFO:python_build: ('default', 'Nov  1 2023 14:38:12')
2023-11-20 10:03:20,482:INFO:machine: x86_64
2023-11-20 10:03:20,483:INFO:platform: Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.34
2023-11-20 10:03:20,484:INFO:Memory: svmem(total=8139022336, available=6680449024, percent=17.9, used=1145720832, free=1944166400, active=2636378112, inactive=2688188416, buffers=210386944, cached=4838748160, shared=5611520, slab=563097600)
2023-11-20 10:03:20,486:INFO:Physical Core: 4
2023-11-20 10:03:20,486:INFO:Logical Core: 8
2023-11-20 10:03:20,487:INFO:Checking libraries
2023-11-20 10:03:20,487:INFO:System:
2023-11-20 10:03:20,487:INFO:    python: 3.8.18 (default, Nov  1 2023, 14:38:12)  [GCC 12.2.0]
2023-11-20 10:03:20,488:INFO:executable: /usr/local/bin/python
2023-11-20 10:03:20,488:INFO:   machine: Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.34
2023-11-20 10:03:20,488:INFO:PyCaret required dependencies:
2023-11-20 10:03:20,506:INFO:                 pip: 23.0.1
2023-11-20 10:03:20,507:INFO:          setuptools: 57.5.0
2023-11-20 10:03:20,507:INFO:             pycaret: 3.2.0
2023-11-20 10:03:20,508:INFO:             IPython: 8.12.3
2023-11-20 10:03:20,508:INFO:          ipywidgets: 8.1.1
2023-11-20 10:03:20,509:INFO:                tqdm: 4.66.1
2023-11-20 10:03:20,509:INFO:               numpy: 1.24.4
2023-11-20 10:03:20,509:INFO:              pandas: 1.5.3
2023-11-20 10:03:20,510:INFO:              jinja2: 3.1.2
2023-11-20 10:03:20,510:INFO:               scipy: 1.10.1
2023-11-20 10:03:20,510:INFO:              joblib: 1.3.2
2023-11-20 10:03:20,511:INFO:             sklearn: 1.2.2
2023-11-20 10:03:20,511:INFO:                pyod: 1.1.2
2023-11-20 10:03:20,511:INFO:            imblearn: 0.11.0
2023-11-20 10:03:20,511:INFO:   category_encoders: 2.6.3
2023-11-20 10:03:20,511:INFO:            lightgbm: 4.1.0
2023-11-20 10:03:20,512:INFO:               numba: 0.58.1
2023-11-20 10:03:20,512:INFO:            requests: 2.31.0
2023-11-20 10:03:20,512:INFO:          matplotlib: 3.6.0
2023-11-20 10:03:20,512:INFO:          scikitplot: 0.3.7
2023-11-20 10:03:20,512:INFO:         yellowbrick: 1.5
2023-11-20 10:03:20,513:INFO:              plotly: 5.18.0
2023-11-20 10:03:20,513:INFO:    plotly-resampler: Not installed
2023-11-20 10:03:20,513:INFO:             kaleido: 0.2.1
2023-11-20 10:03:20,513:INFO:           schemdraw: 0.15
2023-11-20 10:03:20,513:INFO:         statsmodels: 0.14.0
2023-11-20 10:03:20,514:INFO:              sktime: 0.21.1
2023-11-20 10:03:20,514:INFO:               tbats: 1.1.3
2023-11-20 10:03:20,514:INFO:            pmdarima: 2.0.4
2023-11-20 10:03:20,514:INFO:              psutil: 5.9.6
2023-11-20 10:03:20,514:INFO:          markupsafe: 2.1.3
2023-11-20 10:03:20,514:INFO:             pickle5: Not installed
2023-11-20 10:03:20,515:INFO:         cloudpickle: 3.0.0
2023-11-20 10:03:20,515:INFO:         deprecation: 2.1.0
2023-11-20 10:03:20,515:INFO:              xxhash: 3.4.1
2023-11-20 10:03:20,515:INFO:           wurlitzer: 3.0.3
2023-11-20 10:03:20,515:INFO:PyCaret optional dependencies:
2023-11-20 10:03:20,539:INFO:                shap: Not installed
2023-11-20 10:03:20,539:INFO:           interpret: Not installed
2023-11-20 10:03:20,539:INFO:                umap: Not installed
2023-11-20 10:03:20,540:INFO:     ydata_profiling: Not installed
2023-11-20 10:03:20,540:INFO:  explainerdashboard: Not installed
2023-11-20 10:03:20,540:INFO:             autoviz: Not installed
2023-11-20 10:03:20,541:INFO:           fairlearn: Not installed
2023-11-20 10:03:20,541:INFO:          deepchecks: Not installed
2023-11-20 10:03:20,541:INFO:             xgboost: Not installed
2023-11-20 10:03:20,541:INFO:            catboost: Not installed
2023-11-20 10:03:20,542:INFO:              kmodes: Not installed
2023-11-20 10:03:20,542:INFO:             mlxtend: Not installed
2023-11-20 10:03:20,542:INFO:       statsforecast: Not installed
2023-11-20 10:03:20,542:INFO:        tune_sklearn: Not installed
2023-11-20 10:03:20,543:INFO:                 ray: Not installed
2023-11-20 10:03:20,543:INFO:            hyperopt: Not installed
2023-11-20 10:03:20,543:INFO:              optuna: Not installed
2023-11-20 10:03:20,543:INFO:               skopt: Not installed
2023-11-20 10:03:20,543:INFO:              mlflow: Not installed
2023-11-20 10:03:20,544:INFO:              gradio: Not installed
2023-11-20 10:03:20,544:INFO:             fastapi: Not installed
2023-11-20 10:03:20,544:INFO:             uvicorn: Not installed
2023-11-20 10:03:20,544:INFO:              m2cgen: Not installed
2023-11-20 10:03:20,544:INFO:           evidently: Not installed
2023-11-20 10:03:20,545:INFO:               fugue: Not installed
2023-11-20 10:03:20,545:INFO:           streamlit: Not installed
2023-11-20 10:03:20,545:INFO:             prophet: Not installed
2023-11-20 10:03:20,545:INFO:None
2023-11-20 10:03:20,545:INFO:Set up GPU usage.
2023-11-20 10:03:20,546:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,546:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-20 10:03:20,546:INFO:Set up data.
2023-11-20 10:03:20,552:INFO:Set up folding strategy.
2023-11-20 10:03:20,553:INFO:Set up train/test split.
2023-11-20 10:03:20,556:INFO:Set up index.
2023-11-20 10:03:20,556:INFO:Assigning column types.
2023-11-20 10:03:20,559:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-20 10:03:20,559:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,591:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-20 10:03:20,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,595:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-20 10:03:20,596:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,616:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,670:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-20 10:03:20,671:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,671:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,673:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-20 10:03:20,673:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,695:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,701:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,702:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-20 10:03:20,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,738:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-20 10:03:20,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,755:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,758:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,760:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,766:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,800:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,802:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-20 10:03:20,803:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,823:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,831:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-20 10:03:20,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,862:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,882:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,888:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,939:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,953:INFO:Preparing preprocessing pipeline...
2023-11-20 10:03:20,955:INFO:Set up simple imputation.
2023-11-20 10:03:20,972:INFO:Finished creating preprocessing pipeline.
2023-11-20 10:03:20,977:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-20 10:03:20,982:INFO:Creating final display dataframe.
2023-11-20 10:03:21,030:INFO:Setup _display_container:                     Description             Value
0                    Session id              1549
1                        Target            target
2                   Target type            Binary
3           Original data shape         (210, 13)
4        Transformed data shape         (210, 13)
5   Transformed train set shape         (147, 13)
6    Transformed test set shape          (63, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3b33
2023-11-20 10:03:21,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,065:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,067:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,087:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:21,094:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:21,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,127:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,128:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,153:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:21,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:21,159:INFO:setup() successfully completed in 0.69s...............
2023-11-20 10:03:21,160:INFO:Initializing compare_models()
2023-11-20 10:03:21,160:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-20 10:03:21,160:INFO:Checking exceptions
2023-11-20 10:03:21,163:INFO:Preparing display monitor
2023-11-20 10:03:21,166:INFO:Initializing Logistic Regression
2023-11-20 10:03:21,166:INFO:Total runtime is 4.712740580240885e-06 minutes
2023-11-20 10:03:21,167:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:21,167:INFO:Initializing create_model()
2023-11-20 10:03:21,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:21,168:INFO:Checking exceptions
2023-11-20 10:03:21,169:INFO:Importing libraries
2023-11-20 10:03:21,169:INFO:Copying training dataset
2023-11-20 10:03:21,172:INFO:Defining folds
2023-11-20 10:03:21,173:INFO:Declaring metric variables
2023-11-20 10:03:21,173:INFO:Importing untrained model
2023-11-20 10:03:21,174:INFO:Logistic Regression Imported successfully
2023-11-20 10:03:21,175:INFO:Starting cross validation
2023-11-20 10:03:21,176:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:21,309:INFO:Calculating mean and std
2023-11-20 10:03:21,311:INFO:Creating metrics dataframe
2023-11-20 10:03:21,316:INFO:Uploading results into container
2023-11-20 10:03:21,317:INFO:Uploading model into container now
2023-11-20 10:03:21,318:INFO:_master_model_container: 1
2023-11-20 10:03:21,318:INFO:_display_container: 2
2023-11-20 10:03:21,319:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1549, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-20 10:03:21,319:INFO:create_model() successfully completed......................................
2023-11-20 10:03:21,380:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:21,381:INFO:Creating metrics dataframe
2023-11-20 10:03:21,385:INFO:Initializing K Neighbors Classifier
2023-11-20 10:03:21,386:INFO:Total runtime is 0.0036659797032674154 minutes
2023-11-20 10:03:21,387:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:21,387:INFO:Initializing create_model()
2023-11-20 10:03:21,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:21,388:INFO:Checking exceptions
2023-11-20 10:03:21,389:INFO:Importing libraries
2023-11-20 10:03:21,389:INFO:Copying training dataset
2023-11-20 10:03:21,394:INFO:Defining folds
2023-11-20 10:03:21,395:INFO:Declaring metric variables
2023-11-20 10:03:21,396:INFO:Importing untrained model
2023-11-20 10:03:21,397:INFO:K Neighbors Classifier Imported successfully
2023-11-20 10:03:21,398:INFO:Starting cross validation
2023-11-20 10:03:21,399:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:21,668:INFO:Calculating mean and std
2023-11-20 10:03:21,669:INFO:Creating metrics dataframe
2023-11-20 10:03:21,672:INFO:Uploading results into container
2023-11-20 10:03:21,673:INFO:Uploading model into container now
2023-11-20 10:03:21,674:INFO:_master_model_container: 2
2023-11-20 10:03:21,674:INFO:_display_container: 2
2023-11-20 10:03:21,675:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-20 10:03:21,675:INFO:create_model() successfully completed......................................
2023-11-20 10:03:21,724:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:21,725:INFO:Creating metrics dataframe
2023-11-20 10:03:21,732:INFO:Initializing Naive Bayes
2023-11-20 10:03:21,732:INFO:Total runtime is 0.009437274932861329 minutes
2023-11-20 10:03:21,733:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:21,734:INFO:Initializing create_model()
2023-11-20 10:03:21,735:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:21,735:INFO:Checking exceptions
2023-11-20 10:03:21,736:INFO:Importing libraries
2023-11-20 10:03:21,736:INFO:Copying training dataset
2023-11-20 10:03:21,740:INFO:Defining folds
2023-11-20 10:03:21,741:INFO:Declaring metric variables
2023-11-20 10:03:21,742:INFO:Importing untrained model
2023-11-20 10:03:21,742:INFO:Naive Bayes Imported successfully
2023-11-20 10:03:21,743:INFO:Starting cross validation
2023-11-20 10:03:21,745:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:21,828:INFO:Calculating mean and std
2023-11-20 10:03:21,829:INFO:Creating metrics dataframe
2023-11-20 10:03:21,833:INFO:Uploading results into container
2023-11-20 10:03:21,834:INFO:Uploading model into container now
2023-11-20 10:03:21,834:INFO:_master_model_container: 3
2023-11-20 10:03:21,834:INFO:_display_container: 2
2023-11-20 10:03:21,835:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-20 10:03:21,835:INFO:create_model() successfully completed......................................
2023-11-20 10:03:21,887:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:21,888:INFO:Creating metrics dataframe
2023-11-20 10:03:21,892:INFO:Initializing Decision Tree Classifier
2023-11-20 10:03:21,893:INFO:Total runtime is 0.012118975321451824 minutes
2023-11-20 10:03:21,894:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:21,895:INFO:Initializing create_model()
2023-11-20 10:03:21,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:21,896:INFO:Checking exceptions
2023-11-20 10:03:21,896:INFO:Importing libraries
2023-11-20 10:03:21,897:INFO:Copying training dataset
2023-11-20 10:03:21,899:INFO:Defining folds
2023-11-20 10:03:21,900:INFO:Declaring metric variables
2023-11-20 10:03:21,901:INFO:Importing untrained model
2023-11-20 10:03:21,902:INFO:Decision Tree Classifier Imported successfully
2023-11-20 10:03:21,903:INFO:Starting cross validation
2023-11-20 10:03:21,904:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:21,990:INFO:Calculating mean and std
2023-11-20 10:03:21,991:INFO:Creating metrics dataframe
2023-11-20 10:03:21,995:INFO:Uploading results into container
2023-11-20 10:03:21,996:INFO:Uploading model into container now
2023-11-20 10:03:21,996:INFO:_master_model_container: 4
2023-11-20 10:03:21,996:INFO:_display_container: 2
2023-11-20 10:03:21,997:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1549, splitter='best')
2023-11-20 10:03:21,997:INFO:create_model() successfully completed......................................
2023-11-20 10:03:22,049:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:22,050:INFO:Creating metrics dataframe
2023-11-20 10:03:22,054:INFO:Initializing SVM - Linear Kernel
2023-11-20 10:03:22,055:INFO:Total runtime is 0.014813248316446941 minutes
2023-11-20 10:03:22,055:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:22,056:INFO:Initializing create_model()
2023-11-20 10:03:22,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:22,057:INFO:Checking exceptions
2023-11-20 10:03:22,057:INFO:Importing libraries
2023-11-20 10:03:22,058:INFO:Copying training dataset
2023-11-20 10:03:22,060:INFO:Defining folds
2023-11-20 10:03:22,061:INFO:Declaring metric variables
2023-11-20 10:03:22,061:INFO:Importing untrained model
2023-11-20 10:03:22,062:INFO:SVM - Linear Kernel Imported successfully
2023-11-20 10:03:22,063:INFO:Starting cross validation
2023-11-20 10:03:22,064:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:22,076:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-20 10:03:22,092:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-20 10:03:22,106:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-20 10:03:22,121:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-20 10:03:22,136:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-20 10:03:22,142:INFO:Calculating mean and std
2023-11-20 10:03:22,143:INFO:Creating metrics dataframe
2023-11-20 10:03:22,147:INFO:Uploading results into container
2023-11-20 10:03:22,148:INFO:Uploading model into container now
2023-11-20 10:03:22,149:INFO:_master_model_container: 5
2023-11-20 10:03:22,150:INFO:_display_container: 2
2023-11-20 10:03:22,151:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1549, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-20 10:03:22,151:INFO:create_model() successfully completed......................................
2023-11-20 10:03:22,201:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:22,202:INFO:Creating metrics dataframe
2023-11-20 10:03:22,206:INFO:Initializing Ridge Classifier
2023-11-20 10:03:22,207:INFO:Total runtime is 0.017342448234558105 minutes
2023-11-20 10:03:22,207:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:22,208:INFO:Initializing create_model()
2023-11-20 10:03:22,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:22,208:INFO:Checking exceptions
2023-11-20 10:03:22,209:INFO:Importing libraries
2023-11-20 10:03:22,209:INFO:Copying training dataset
2023-11-20 10:03:22,212:INFO:Defining folds
2023-11-20 10:03:22,213:INFO:Declaring metric variables
2023-11-20 10:03:22,215:INFO:Importing untrained model
2023-11-20 10:03:22,217:INFO:Ridge Classifier Imported successfully
2023-11-20 10:03:22,219:INFO:Starting cross validation
2023-11-20 10:03:22,220:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:22,235:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-20 10:03:22,250:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-20 10:03:22,265:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-20 10:03:22,280:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-20 10:03:22,296:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-20 10:03:22,302:INFO:Calculating mean and std
2023-11-20 10:03:22,303:INFO:Creating metrics dataframe
2023-11-20 10:03:22,307:INFO:Uploading results into container
2023-11-20 10:03:22,308:INFO:Uploading model into container now
2023-11-20 10:03:22,309:INFO:_master_model_container: 6
2023-11-20 10:03:22,309:INFO:_display_container: 2
2023-11-20 10:03:22,310:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1549, solver='auto',
                tol=0.0001)
2023-11-20 10:03:22,310:INFO:create_model() successfully completed......................................
2023-11-20 10:03:22,360:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:22,361:INFO:Creating metrics dataframe
2023-11-20 10:03:22,365:INFO:Initializing Quadratic Discriminant Analysis
2023-11-20 10:03:22,366:INFO:Total runtime is 0.01999267339706421 minutes
2023-11-20 10:03:22,366:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:22,367:INFO:Initializing create_model()
2023-11-20 10:03:22,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:22,367:INFO:Checking exceptions
2023-11-20 10:03:22,368:INFO:Importing libraries
2023-11-20 10:03:22,368:INFO:Copying training dataset
2023-11-20 10:03:22,371:INFO:Defining folds
2023-11-20 10:03:22,372:INFO:Declaring metric variables
2023-11-20 10:03:22,372:INFO:Importing untrained model
2023-11-20 10:03:22,373:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-20 10:03:22,373:INFO:Starting cross validation
2023-11-20 10:03:22,374:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:22,454:INFO:Calculating mean and std
2023-11-20 10:03:22,455:INFO:Creating metrics dataframe
2023-11-20 10:03:22,458:INFO:Uploading results into container
2023-11-20 10:03:22,460:INFO:Uploading model into container now
2023-11-20 10:03:22,460:INFO:_master_model_container: 7
2023-11-20 10:03:22,461:INFO:_display_container: 2
2023-11-20 10:03:22,462:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-20 10:03:22,462:INFO:create_model() successfully completed......................................
2023-11-20 10:03:22,511:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:22,512:INFO:Creating metrics dataframe
2023-11-20 10:03:22,517:INFO:Initializing Ada Boost Classifier
2023-11-20 10:03:22,517:INFO:Total runtime is 0.022520971298217774 minutes
2023-11-20 10:03:22,518:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:22,519:INFO:Initializing create_model()
2023-11-20 10:03:22,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:22,520:INFO:Checking exceptions
2023-11-20 10:03:22,520:INFO:Importing libraries
2023-11-20 10:03:22,521:INFO:Copying training dataset
2023-11-20 10:03:22,523:INFO:Defining folds
2023-11-20 10:03:22,524:INFO:Declaring metric variables
2023-11-20 10:03:22,524:INFO:Importing untrained model
2023-11-20 10:03:22,525:INFO:Ada Boost Classifier Imported successfully
2023-11-20 10:03:22,526:INFO:Starting cross validation
2023-11-20 10:03:22,527:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:22,905:INFO:Calculating mean and std
2023-11-20 10:03:22,906:INFO:Creating metrics dataframe
2023-11-20 10:03:22,910:INFO:Uploading results into container
2023-11-20 10:03:22,911:INFO:Uploading model into container now
2023-11-20 10:03:22,912:INFO:_master_model_container: 8
2023-11-20 10:03:22,912:INFO:_display_container: 2
2023-11-20 10:03:22,913:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1549)
2023-11-20 10:03:22,913:INFO:create_model() successfully completed......................................
2023-11-20 10:03:22,964:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:22,965:INFO:Creating metrics dataframe
2023-11-20 10:03:22,970:INFO:Initializing Linear Discriminant Analysis
2023-11-20 10:03:22,971:INFO:Total runtime is 0.030079849561055503 minutes
2023-11-20 10:03:22,972:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:22,972:INFO:Initializing create_model()
2023-11-20 10:03:22,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:22,973:INFO:Checking exceptions
2023-11-20 10:03:22,974:INFO:Importing libraries
2023-11-20 10:03:22,975:INFO:Copying training dataset
2023-11-20 10:03:22,978:INFO:Defining folds
2023-11-20 10:03:22,979:INFO:Declaring metric variables
2023-11-20 10:03:22,980:INFO:Importing untrained model
2023-11-20 10:03:22,981:INFO:Linear Discriminant Analysis Imported successfully
2023-11-20 10:03:22,981:INFO:Starting cross validation
2023-11-20 10:03:22,982:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:23,064:INFO:Calculating mean and std
2023-11-20 10:03:23,065:INFO:Creating metrics dataframe
2023-11-20 10:03:23,069:INFO:Uploading results into container
2023-11-20 10:03:23,070:INFO:Uploading model into container now
2023-11-20 10:03:23,070:INFO:_master_model_container: 9
2023-11-20 10:03:23,071:INFO:_display_container: 2
2023-11-20 10:03:23,071:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-20 10:03:23,071:INFO:create_model() successfully completed......................................
2023-11-20 10:03:23,122:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:23,123:INFO:Creating metrics dataframe
2023-11-20 10:03:23,127:INFO:Initializing Extra Trees Classifier
2023-11-20 10:03:23,128:INFO:Total runtime is 0.032698190212249754 minutes
2023-11-20 10:03:23,129:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:23,129:INFO:Initializing create_model()
2023-11-20 10:03:23,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:23,130:INFO:Checking exceptions
2023-11-20 10:03:23,131:INFO:Importing libraries
2023-11-20 10:03:23,131:INFO:Copying training dataset
2023-11-20 10:03:23,135:INFO:Defining folds
2023-11-20 10:03:23,135:INFO:Declaring metric variables
2023-11-20 10:03:23,136:INFO:Importing untrained model
2023-11-20 10:03:23,137:INFO:Extra Trees Classifier Imported successfully
2023-11-20 10:03:23,137:INFO:Starting cross validation
2023-11-20 10:03:23,139:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:24,590:INFO:Calculating mean and std
2023-11-20 10:03:24,591:INFO:Creating metrics dataframe
2023-11-20 10:03:24,594:INFO:Uploading results into container
2023-11-20 10:03:24,595:INFO:Uploading model into container now
2023-11-20 10:03:24,595:INFO:_master_model_container: 10
2023-11-20 10:03:24,596:INFO:_display_container: 2
2023-11-20 10:03:24,596:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1549, verbose=0, warm_start=False)
2023-11-20 10:03:24,596:INFO:create_model() successfully completed......................................
2023-11-20 10:03:24,644:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:24,645:INFO:Creating metrics dataframe
2023-11-20 10:03:24,650:INFO:Initializing Light Gradient Boosting Machine
2023-11-20 10:03:24,650:INFO:Total runtime is 0.05807009935379028 minutes
2023-11-20 10:03:24,651:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:24,652:INFO:Initializing create_model()
2023-11-20 10:03:24,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:24,653:INFO:Checking exceptions
2023-11-20 10:03:24,653:INFO:Importing libraries
2023-11-20 10:03:24,654:INFO:Copying training dataset
2023-11-20 10:03:24,657:INFO:Defining folds
2023-11-20 10:03:24,657:INFO:Declaring metric variables
2023-11-20 10:03:24,658:INFO:Importing untrained model
2023-11-20 10:03:24,659:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-20 10:03:24,659:INFO:Starting cross validation
2023-11-20 10:03:24,661:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:24,703:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-20 10:03:24,711:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000062 seconds.
2023-11-20 10:03:24,711:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-20 10:03:24,712:INFO:[LightGBM] [Info] Total Bins 487
2023-11-20 10:03:24,712:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-20 10:03:24,713:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-20 10:03:24,713:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-20 10:03:24,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,773:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-20 10:03:24,774:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000055 seconds.
2023-11-20 10:03:24,774:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-20 10:03:24,774:INFO:[LightGBM] [Info] Total Bins 487
2023-11-20 10:03:24,775:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-20 10:03:24,775:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-20 10:03:24,775:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-20 10:03:24,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,982:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-20 10:03:24,982:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000054 seconds.
2023-11-20 10:03:24,982:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-20 10:03:24,983:INFO:[LightGBM] [Info] Total Bins 492
2023-11-20 10:03:24,983:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-20 10:03:24,983:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-20 10:03:24,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,040:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-20 10:03:25,041:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.
2023-11-20 10:03:25,041:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-20 10:03:25,041:INFO:[LightGBM] [Info] Total Bins 492
2023-11-20 10:03:25,041:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-20 10:03:25,042:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-20 10:03:25,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,098:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 60
2023-11-20 10:03:25,098:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000051 seconds.
2023-11-20 10:03:25,099:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-20 10:03:25,099:INFO:[LightGBM] [Info] Total Bins 492
2023-11-20 10:03:25,099:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-20 10:03:25,100:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491525 -> initscore=-0.033902
2023-11-20 10:03:25,100:INFO:[LightGBM] [Info] Start training from score -0.033902
2023-11-20 10:03:25,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,173:INFO:Calculating mean and std
2023-11-20 10:03:25,174:INFO:Creating metrics dataframe
2023-11-20 10:03:25,180:INFO:Uploading results into container
2023-11-20 10:03:25,181:INFO:Uploading model into container now
2023-11-20 10:03:25,182:INFO:_master_model_container: 11
2023-11-20 10:03:25,182:INFO:_display_container: 2
2023-11-20 10:03:25,183:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1549, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-20 10:03:25,183:INFO:create_model() successfully completed......................................
2023-11-20 10:03:25,241:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:25,241:INFO:Creating metrics dataframe
2023-11-20 10:03:25,246:INFO:Initializing Dummy Classifier
2023-11-20 10:03:25,246:INFO:Total runtime is 0.06800220807393392 minutes
2023-11-20 10:03:25,247:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:25,247:INFO:Initializing create_model()
2023-11-20 10:03:25,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:25,248:INFO:Checking exceptions
2023-11-20 10:03:25,248:INFO:Importing libraries
2023-11-20 10:03:25,248:INFO:Copying training dataset
2023-11-20 10:03:25,251:INFO:Defining folds
2023-11-20 10:03:25,251:INFO:Declaring metric variables
2023-11-20 10:03:25,252:INFO:Importing untrained model
2023-11-20 10:03:25,253:INFO:Dummy Classifier Imported successfully
2023-11-20 10:03:25,253:INFO:Starting cross validation
2023-11-20 10:03:25,254:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:25,271:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-20 10:03:25,288:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-20 10:03:25,303:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-20 10:03:25,318:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-20 10:03:25,335:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-20 10:03:25,341:INFO:Calculating mean and std
2023-11-20 10:03:25,342:INFO:Creating metrics dataframe
2023-11-20 10:03:25,344:INFO:Uploading results into container
2023-11-20 10:03:25,346:INFO:Uploading model into container now
2023-11-20 10:03:25,347:INFO:_master_model_container: 12
2023-11-20 10:03:25,347:INFO:_display_container: 2
2023-11-20 10:03:25,348:INFO:DummyClassifier(constant=None, random_state=1549, strategy='prior')
2023-11-20 10:03:25,348:INFO:create_model() successfully completed......................................
2023-11-20 10:03:25,395:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:25,397:INFO:Creating metrics dataframe
2023-11-20 10:03:25,403:INFO:Initializing create_model()
2023-11-20 10:03:25,403:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1549, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:25,404:INFO:Checking exceptions
2023-11-20 10:03:25,405:INFO:Importing libraries
2023-11-20 10:03:25,406:INFO:Copying training dataset
2023-11-20 10:03:25,408:INFO:Defining folds
2023-11-20 10:03:25,409:INFO:Declaring metric variables
2023-11-20 10:03:25,410:INFO:Importing untrained model
2023-11-20 10:03:25,411:INFO:Declaring custom model
2023-11-20 10:03:25,412:INFO:SVM - Linear Kernel Imported successfully
2023-11-20 10:03:25,413:INFO:Cross validation set to False
2023-11-20 10:03:25,414:INFO:Fitting Model
2023-11-20 10:03:25,422:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1549, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-20 10:03:25,423:INFO:create_model() successfully completed......................................
2023-11-20 10:03:25,480:INFO:_master_model_container: 12
2023-11-20 10:03:25,481:INFO:_display_container: 2
2023-11-20 10:03:25,482:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1549, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-20 10:03:25,482:INFO:compare_models() successfully completed......................................
