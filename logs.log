2023-11-15 17:26:09,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-15 17:26:09,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-15 17:26:09,976:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-15 17:26:09,976:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 08:49:42,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 08:49:42,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 08:49:42,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 08:49:42,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,491:INFO:PyCaret ClassificationExperiment
2023-11-16 09:09:26,493:INFO:Logging name: clf-default-name
2023-11-16 09:09:26,494:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-16 09:09:26,494:INFO:version 3.2.0
2023-11-16 09:09:26,494:INFO:Initializing setup()
2023-11-16 09:09:26,494:INFO:self.USI: dc25
2023-11-16 09:09:26,494:INFO:self._variable_keys: {'data', 'memory', '_available_plots', 'y', 'gpu_param', 'y_test', 'is_multiclass', 'fold_generator', 'X', 'n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'exp_name_log', 'fold_shuffle_param', 'idx', 'X_train', 'USI', 'logging_param', 'html_param', 'exp_id', 'log_plots_param', 'target_param', 'pipeline', 'fix_imbalance', 'X_test', 'gpu_n_jobs_param', 'y_train'}
2023-11-16 09:09:26,494:INFO:Checking environment
2023-11-16 09:09:26,495:INFO:python_version: 3.8.18
2023-11-16 09:09:26,495:INFO:python_build: ('default', 'Nov  1 2023 11:08:38')
2023-11-16 09:09:26,495:INFO:machine: aarch64
2023-11-16 09:09:26,497:INFO:platform: Linux-5.15.49-linuxkit-pr-aarch64-with-glibc2.34
2023-11-16 09:09:26,499:INFO:Memory: svmem(total=8232710144, available=7026745344, percent=14.6, used=682098688, free=4883681280, active=458027008, inactive=2449285120, buffers=102506496, cached=2564423680, shared=316284928, slab=292446208)
2023-11-16 09:09:26,501:INFO:Physical Core: 6
2023-11-16 09:09:26,501:INFO:Logical Core: 6
2023-11-16 09:09:26,501:INFO:Checking libraries
2023-11-16 09:09:26,502:INFO:System:
2023-11-16 09:09:26,502:INFO:    python: 3.8.18 (default, Nov  1 2023, 11:08:38)  [GCC 12.2.0]
2023-11-16 09:09:26,502:INFO:executable: /usr/local/bin/python
2023-11-16 09:09:26,502:INFO:   machine: Linux-5.15.49-linuxkit-pr-aarch64-with-glibc2.34
2023-11-16 09:09:26,502:INFO:PyCaret required dependencies:
2023-11-16 09:09:26,555:INFO:                 pip: 23.3.1
2023-11-16 09:09:26,555:INFO:          setuptools: 57.5.0
2023-11-16 09:09:26,555:INFO:             pycaret: 3.2.0
2023-11-16 09:09:26,555:INFO:             IPython: 8.12.3
2023-11-16 09:09:26,555:INFO:          ipywidgets: 8.1.1
2023-11-16 09:09:26,555:INFO:                tqdm: 4.66.1
2023-11-16 09:09:26,556:INFO:               numpy: 1.24.4
2023-11-16 09:09:26,556:INFO:              pandas: 1.5.3
2023-11-16 09:09:26,556:INFO:              jinja2: 3.1.2
2023-11-16 09:09:26,556:INFO:               scipy: 1.10.1
2023-11-16 09:09:26,556:INFO:              joblib: 1.3.2
2023-11-16 09:09:26,556:INFO:             sklearn: 1.2.2
2023-11-16 09:09:26,556:INFO:                pyod: 1.1.1
2023-11-16 09:09:26,556:INFO:            imblearn: 0.11.0
2023-11-16 09:09:26,556:INFO:   category_encoders: 2.6.3
2023-11-16 09:09:26,557:INFO:            lightgbm: 4.1.0
2023-11-16 09:09:26,557:INFO:               numba: 0.58.1
2023-11-16 09:09:26,557:INFO:            requests: 2.31.0
2023-11-16 09:09:26,557:INFO:          matplotlib: 3.6.0
2023-11-16 09:09:26,557:INFO:          scikitplot: 0.3.7
2023-11-16 09:09:26,557:INFO:         yellowbrick: 1.5
2023-11-16 09:09:26,557:INFO:              plotly: 5.18.0
2023-11-16 09:09:26,557:INFO:    plotly-resampler: Not installed
2023-11-16 09:09:26,557:INFO:             kaleido: 0.2.1
2023-11-16 09:09:26,557:INFO:           schemdraw: 0.15
2023-11-16 09:09:26,557:INFO:         statsmodels: 0.14.0
2023-11-16 09:09:26,558:INFO:              sktime: 0.21.1
2023-11-16 09:09:26,558:INFO:               tbats: 1.1.3
2023-11-16 09:09:26,558:INFO:            pmdarima: 2.0.4
2023-11-16 09:09:26,558:INFO:              psutil: 5.9.6
2023-11-16 09:09:26,558:INFO:          markupsafe: 2.1.3
2023-11-16 09:09:26,558:INFO:             pickle5: Not installed
2023-11-16 09:09:26,558:INFO:         cloudpickle: 3.0.0
2023-11-16 09:09:26,558:INFO:         deprecation: 2.1.0
2023-11-16 09:09:26,558:INFO:              xxhash: 3.4.1
2023-11-16 09:09:26,558:INFO:           wurlitzer: 3.0.3
2023-11-16 09:09:26,558:INFO:PyCaret optional dependencies:
2023-11-16 09:09:26,571:INFO:                shap: Not installed
2023-11-16 09:09:26,572:INFO:           interpret: Not installed
2023-11-16 09:09:26,572:INFO:                umap: Not installed
2023-11-16 09:09:26,572:INFO:     ydata_profiling: Not installed
2023-11-16 09:09:26,572:INFO:  explainerdashboard: Not installed
2023-11-16 09:09:26,572:INFO:             autoviz: Not installed
2023-11-16 09:09:26,572:INFO:           fairlearn: Not installed
2023-11-16 09:09:26,572:INFO:          deepchecks: Not installed
2023-11-16 09:09:26,573:INFO:             xgboost: Not installed
2023-11-16 09:09:26,573:INFO:            catboost: Not installed
2023-11-16 09:09:26,573:INFO:              kmodes: Not installed
2023-11-16 09:09:26,573:INFO:             mlxtend: Not installed
2023-11-16 09:09:26,573:INFO:       statsforecast: Not installed
2023-11-16 09:09:26,573:INFO:        tune_sklearn: Not installed
2023-11-16 09:09:26,573:INFO:                 ray: Not installed
2023-11-16 09:09:26,573:INFO:            hyperopt: Not installed
2023-11-16 09:09:26,573:INFO:              optuna: Not installed
2023-11-16 09:09:26,574:INFO:               skopt: Not installed
2023-11-16 09:09:26,574:INFO:              mlflow: Not installed
2023-11-16 09:09:26,574:INFO:              gradio: Not installed
2023-11-16 09:09:26,574:INFO:             fastapi: Not installed
2023-11-16 09:09:26,574:INFO:             uvicorn: Not installed
2023-11-16 09:09:26,574:INFO:              m2cgen: Not installed
2023-11-16 09:09:26,574:INFO:           evidently: Not installed
2023-11-16 09:09:26,574:INFO:               fugue: Not installed
2023-11-16 09:09:26,574:INFO:           streamlit: Not installed
2023-11-16 09:09:26,574:INFO:             prophet: Not installed
2023-11-16 09:09:26,574:INFO:None
2023-11-16 09:09:26,575:INFO:Set up GPU usage.
2023-11-16 09:09:26,575:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,575:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-16 09:09:26,575:INFO:Set up data.
2023-11-16 09:09:26,591:INFO:Set up folding strategy.
2023-11-16 09:09:26,592:INFO:Set up train/test split.
2023-11-16 09:09:26,598:INFO:Set up index.
2023-11-16 09:09:26,598:INFO:Assigning column types.
2023-11-16 09:09:26,600:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-16 09:09:26,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,619:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-16 09:09:26,619:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,622:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,622:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 09:09:26,623:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,645:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,703:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-16 09:09:26,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,703:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 09:09:26,704:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,713:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,714:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,719:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-16 09:09:26,719:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,737:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 09:09:26,738:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,746:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,748:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,749:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,752:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,770:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 09:09:26,770:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,779:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,781:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,782:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,785:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,785:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-16 09:09:26,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,803:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,803:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,804:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,814:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,814:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,834:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,851:INFO:Preparing preprocessing pipeline...
2023-11-16 09:09:26,853:INFO:Set up simple imputation.
2023-11-16 09:09:26,866:INFO:Finished creating preprocessing pipeline.
2023-11-16 09:09:26,869:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-16 09:09:26,869:INFO:Creating final display dataframe.
2023-11-16 09:09:26,893:INFO:Setup _display_container:                     Description             Value
0                    Session id              1438
1                        Target            target
2                   Target type        Multiclass
3           Original data shape         (106, 13)
4        Transformed data shape         (106, 13)
5   Transformed train set shape          (74, 13)
6    Transformed test set shape          (32, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              dc25
2023-11-16 09:09:26,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,913:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,913:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,925:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,927:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,928:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,955:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 09:09:26,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:09:26,959:INFO:setup() successfully completed in 0.49s...............
2023-11-16 09:10:15,375:INFO:PyCaret ClassificationExperiment
2023-11-16 09:10:15,376:INFO:Logging name: clf-default-name
2023-11-16 09:10:15,377:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-16 09:10:15,377:INFO:version 3.2.0
2023-11-16 09:10:15,377:INFO:Initializing setup()
2023-11-16 09:10:15,377:INFO:self.USI: 7761
2023-11-16 09:10:15,378:INFO:self._variable_keys: {'data', 'memory', '_available_plots', 'y', 'gpu_param', 'y_test', 'is_multiclass', 'fold_generator', 'X', 'n_jobs_param', 'fold_groups_param', '_ml_usecase', 'seed', 'exp_name_log', 'fold_shuffle_param', 'idx', 'X_train', 'USI', 'logging_param', 'html_param', 'exp_id', 'log_plots_param', 'target_param', 'pipeline', 'fix_imbalance', 'X_test', 'gpu_n_jobs_param', 'y_train'}
2023-11-16 09:10:15,378:INFO:Checking environment
2023-11-16 09:10:15,378:INFO:python_version: 3.8.18
2023-11-16 09:10:15,379:INFO:python_build: ('default', 'Nov  1 2023 11:08:38')
2023-11-16 09:10:15,379:INFO:machine: aarch64
2023-11-16 09:10:15,379:INFO:platform: Linux-5.15.49-linuxkit-pr-aarch64-with-glibc2.34
2023-11-16 09:10:15,381:INFO:Memory: svmem(total=8232710144, available=7021359104, percent=14.7, used=687484928, free=4877234176, active=458076160, inactive=2458976256, buffers=102522880, cached=2565468160, shared=316284928, slab=292409344)
2023-11-16 09:10:15,382:INFO:Physical Core: 6
2023-11-16 09:10:15,383:INFO:Logical Core: 6
2023-11-16 09:10:15,383:INFO:Checking libraries
2023-11-16 09:10:15,383:INFO:System:
2023-11-16 09:10:15,384:INFO:    python: 3.8.18 (default, Nov  1 2023, 11:08:38)  [GCC 12.2.0]
2023-11-16 09:10:15,384:INFO:executable: /usr/local/bin/python
2023-11-16 09:10:15,384:INFO:   machine: Linux-5.15.49-linuxkit-pr-aarch64-with-glibc2.34
2023-11-16 09:10:15,384:INFO:PyCaret required dependencies:
2023-11-16 09:10:15,385:INFO:                 pip: 23.3.1
2023-11-16 09:10:15,385:INFO:          setuptools: 57.5.0
2023-11-16 09:10:15,385:INFO:             pycaret: 3.2.0
2023-11-16 09:10:15,386:INFO:             IPython: 8.12.3
2023-11-16 09:10:15,386:INFO:          ipywidgets: 8.1.1
2023-11-16 09:10:15,386:INFO:                tqdm: 4.66.1
2023-11-16 09:10:15,386:INFO:               numpy: 1.24.4
2023-11-16 09:10:15,386:INFO:              pandas: 1.5.3
2023-11-16 09:10:15,386:INFO:              jinja2: 3.1.2
2023-11-16 09:10:15,386:INFO:               scipy: 1.10.1
2023-11-16 09:10:15,387:INFO:              joblib: 1.3.2
2023-11-16 09:10:15,387:INFO:             sklearn: 1.2.2
2023-11-16 09:10:15,387:INFO:                pyod: 1.1.1
2023-11-16 09:10:15,387:INFO:            imblearn: 0.11.0
2023-11-16 09:10:15,387:INFO:   category_encoders: 2.6.3
2023-11-16 09:10:15,387:INFO:            lightgbm: 4.1.0
2023-11-16 09:10:15,387:INFO:               numba: 0.58.1
2023-11-16 09:10:15,388:INFO:            requests: 2.31.0
2023-11-16 09:10:15,388:INFO:          matplotlib: 3.6.0
2023-11-16 09:10:15,388:INFO:          scikitplot: 0.3.7
2023-11-16 09:10:15,388:INFO:         yellowbrick: 1.5
2023-11-16 09:10:15,388:INFO:              plotly: 5.18.0
2023-11-16 09:10:15,388:INFO:    plotly-resampler: Not installed
2023-11-16 09:10:15,388:INFO:             kaleido: 0.2.1
2023-11-16 09:10:15,389:INFO:           schemdraw: 0.15
2023-11-16 09:10:15,389:INFO:         statsmodels: 0.14.0
2023-11-16 09:10:15,389:INFO:              sktime: 0.21.1
2023-11-16 09:10:15,389:INFO:               tbats: 1.1.3
2023-11-16 09:10:15,389:INFO:            pmdarima: 2.0.4
2023-11-16 09:10:15,389:INFO:              psutil: 5.9.6
2023-11-16 09:10:15,389:INFO:          markupsafe: 2.1.3
2023-11-16 09:10:15,389:INFO:             pickle5: Not installed
2023-11-16 09:10:15,390:INFO:         cloudpickle: 3.0.0
2023-11-16 09:10:15,390:INFO:         deprecation: 2.1.0
2023-11-16 09:10:15,390:INFO:              xxhash: 3.4.1
2023-11-16 09:10:15,390:INFO:           wurlitzer: 3.0.3
2023-11-16 09:10:15,390:INFO:PyCaret optional dependencies:
2023-11-16 09:10:15,390:INFO:                shap: Not installed
2023-11-16 09:10:15,390:INFO:           interpret: Not installed
2023-11-16 09:10:15,391:INFO:                umap: Not installed
2023-11-16 09:10:15,391:INFO:     ydata_profiling: Not installed
2023-11-16 09:10:15,391:INFO:  explainerdashboard: Not installed
2023-11-16 09:10:15,391:INFO:             autoviz: Not installed
2023-11-16 09:10:15,391:INFO:           fairlearn: Not installed
2023-11-16 09:10:15,391:INFO:          deepchecks: Not installed
2023-11-16 09:10:15,391:INFO:             xgboost: Not installed
2023-11-16 09:10:15,391:INFO:            catboost: Not installed
2023-11-16 09:10:15,392:INFO:              kmodes: Not installed
2023-11-16 09:10:15,392:INFO:             mlxtend: Not installed
2023-11-16 09:10:15,392:INFO:       statsforecast: Not installed
2023-11-16 09:10:15,392:INFO:        tune_sklearn: Not installed
2023-11-16 09:10:15,392:INFO:                 ray: Not installed
2023-11-16 09:10:15,392:INFO:            hyperopt: Not installed
2023-11-16 09:10:15,392:INFO:              optuna: Not installed
2023-11-16 09:10:15,392:INFO:               skopt: Not installed
2023-11-16 09:10:15,393:INFO:              mlflow: Not installed
2023-11-16 09:10:15,393:INFO:              gradio: Not installed
2023-11-16 09:10:15,393:INFO:             fastapi: Not installed
2023-11-16 09:10:15,393:INFO:             uvicorn: Not installed
2023-11-16 09:10:15,393:INFO:              m2cgen: Not installed
2023-11-16 09:10:15,393:INFO:           evidently: Not installed
2023-11-16 09:10:15,393:INFO:               fugue: Not installed
2023-11-16 09:10:15,394:INFO:           streamlit: Not installed
2023-11-16 09:10:15,394:INFO:             prophet: Not installed
2023-11-16 09:10:15,394:INFO:None
2023-11-16 09:10:15,394:INFO:Set up data.
2023-11-16 09:10:15,407:INFO:Set up folding strategy.
2023-11-16 09:10:15,407:INFO:Set up train/test split.
2023-11-16 09:10:15,411:INFO:Set up index.
2023-11-16 09:10:15,411:INFO:Assigning column types.
2023-11-16 09:10:15,414:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-16 09:10:15,437:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-16 09:10:15,438:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 09:10:15,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,471:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-16 09:10:15,472:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 09:10:15,482:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,483:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-16 09:10:15,501:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 09:10:15,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,532:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 09:10:15,543:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,543:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-16 09:10:15,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,600:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,602:INFO:Preparing preprocessing pipeline...
2023-11-16 09:10:15,602:INFO:Set up simple imputation.
2023-11-16 09:10:15,610:INFO:Finished creating preprocessing pipeline.
2023-11-16 09:10:15,612:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-16 09:10:15,612:INFO:Creating final display dataframe.
2023-11-16 09:10:15,635:INFO:Setup _display_container:                     Description             Value
0                    Session id              6954
1                        Target            target
2                   Target type        Multiclass
3           Original data shape         (106, 13)
4        Transformed data shape         (106, 13)
5   Transformed train set shape          (74, 13)
6    Transformed test set shape          (32, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              7761
2023-11-16 09:10:15,664:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,693:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 09:10:15,694:INFO:setup() successfully completed in 0.33s...............
2023-11-16 09:11:13,803:INFO:Initializing compare_models()
2023-11-16 09:11:13,807:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-16 09:11:13,807:INFO:Checking exceptions
2023-11-16 09:11:13,827:INFO:Preparing display monitor
2023-11-16 09:11:13,841:INFO:Initializing Logistic Regression
2023-11-16 09:11:13,842:INFO:Total runtime is 3.9656956990559895e-06 minutes
2023-11-16 09:11:13,842:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:13,843:INFO:Initializing create_model()
2023-11-16 09:11:13,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:13,844:INFO:Checking exceptions
2023-11-16 09:11:13,844:INFO:Importing libraries
2023-11-16 09:11:13,844:INFO:Copying training dataset
2023-11-16 09:11:13,846:INFO:Defining folds
2023-11-16 09:11:13,846:INFO:Declaring metric variables
2023-11-16 09:11:13,847:INFO:Importing untrained model
2023-11-16 09:11:13,848:INFO:Logistic Regression Imported successfully
2023-11-16 09:11:13,848:INFO:Starting cross validation
2023-11-16 09:11:13,851:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:14,850:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 09:11:14,851:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2023-11-16 09:11:14,852:INFO:Initializing create_model()
2023-11-16 09:11:14,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:14,852:INFO:Checking exceptions
2023-11-16 09:11:14,852:INFO:Importing libraries
2023-11-16 09:11:14,852:INFO:Copying training dataset
2023-11-16 09:11:14,854:INFO:Defining folds
2023-11-16 09:11:14,855:INFO:Declaring metric variables
2023-11-16 09:11:14,855:INFO:Importing untrained model
2023-11-16 09:11:14,855:INFO:Logistic Regression Imported successfully
2023-11-16 09:11:14,855:INFO:Starting cross validation
2023-11-16 09:11:14,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:14,871:ERROR:create_model() for lr raised an exception or returned all 0.0:
2023-11-16 09:11:14,872:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2023-11-16 09:11:14,872:INFO:Initializing K Neighbors Classifier
2023-11-16 09:11:14,872:INFO:Total runtime is 0.017175217469533283 minutes
2023-11-16 09:11:14,872:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:14,872:INFO:Initializing create_model()
2023-11-16 09:11:14,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:14,873:INFO:Checking exceptions
2023-11-16 09:11:14,873:INFO:Importing libraries
2023-11-16 09:11:14,873:INFO:Copying training dataset
2023-11-16 09:11:14,874:INFO:Defining folds
2023-11-16 09:11:14,874:INFO:Declaring metric variables
2023-11-16 09:11:14,875:INFO:Importing untrained model
2023-11-16 09:11:14,875:INFO:K Neighbors Classifier Imported successfully
2023-11-16 09:11:14,875:INFO:Starting cross validation
2023-11-16 09:11:14,876:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:14,916:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,916:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,917:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,917:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,918:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,918:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,920:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,920:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,920:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,920:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,920:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,921:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,921:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,921:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,921:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,921:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,921:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,922:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,922:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,922:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,922:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,922:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,952:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,952:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,952:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,952:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:14,953:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,953:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,953:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,954:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,954:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,954:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,954:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,955:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:14,955:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,955:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,955:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,955:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:14,955:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,956:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,956:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,956:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:14,962:INFO:Calculating mean and std
2023-11-16 09:11:14,963:INFO:Creating metrics dataframe
2023-11-16 09:11:14,966:INFO:Uploading results into container
2023-11-16 09:11:14,967:INFO:Uploading model into container now
2023-11-16 09:11:14,968:INFO:_master_model_container: 1
2023-11-16 09:11:14,968:INFO:_display_container: 2
2023-11-16 09:11:14,969:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 09:11:14,969:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,084:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,084:INFO:Creating metrics dataframe
2023-11-16 09:11:15,086:INFO:Initializing Naive Bayes
2023-11-16 09:11:15,086:INFO:Total runtime is 0.020749119917551677 minutes
2023-11-16 09:11:15,087:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,087:INFO:Initializing create_model()
2023-11-16 09:11:15,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,087:INFO:Checking exceptions
2023-11-16 09:11:15,087:INFO:Importing libraries
2023-11-16 09:11:15,087:INFO:Copying training dataset
2023-11-16 09:11:15,088:INFO:Defining folds
2023-11-16 09:11:15,089:INFO:Declaring metric variables
2023-11-16 09:11:15,089:INFO:Importing untrained model
2023-11-16 09:11:15,089:INFO:Naive Bayes Imported successfully
2023-11-16 09:11:15,089:INFO:Starting cross validation
2023-11-16 09:11:15,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,101:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,101:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,101:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,102:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,102:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,102:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,102:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,103:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,103:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,103:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,103:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,103:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,104:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,104:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,104:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,104:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,104:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,104:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,104:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,105:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,105:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,105:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,106:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,106:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,106:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,108:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,108:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,109:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,110:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,110:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,110:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,110:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,111:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,111:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,111:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,112:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,112:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,112:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,112:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,112:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,113:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,113:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,113:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,113:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,114:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,114:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,114:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,114:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,115:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,115:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,125:INFO:Calculating mean and std
2023-11-16 09:11:15,126:INFO:Creating metrics dataframe
2023-11-16 09:11:15,127:INFO:Uploading results into container
2023-11-16 09:11:15,128:INFO:Uploading model into container now
2023-11-16 09:11:15,128:INFO:_master_model_container: 2
2023-11-16 09:11:15,128:INFO:_display_container: 2
2023-11-16 09:11:15,128:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-16 09:11:15,128:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,157:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,158:INFO:Creating metrics dataframe
2023-11-16 09:11:15,160:INFO:Initializing Decision Tree Classifier
2023-11-16 09:11:15,160:INFO:Total runtime is 0.021973665555318198 minutes
2023-11-16 09:11:15,160:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,160:INFO:Initializing create_model()
2023-11-16 09:11:15,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,160:INFO:Checking exceptions
2023-11-16 09:11:15,161:INFO:Importing libraries
2023-11-16 09:11:15,161:INFO:Copying training dataset
2023-11-16 09:11:15,162:INFO:Defining folds
2023-11-16 09:11:15,162:INFO:Declaring metric variables
2023-11-16 09:11:15,162:INFO:Importing untrained model
2023-11-16 09:11:15,162:INFO:Decision Tree Classifier Imported successfully
2023-11-16 09:11:15,163:INFO:Starting cross validation
2023-11-16 09:11:15,163:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,175:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,175:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,175:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,175:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,175:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,176:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,176:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,176:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,176:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,176:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,176:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,177:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,177:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,177:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,177:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,177:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,177:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,178:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,179:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,179:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,179:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,179:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,184:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,184:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,184:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,184:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,185:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,185:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,185:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,185:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,186:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,186:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,186:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,186:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,187:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,187:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,187:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,187:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,187:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,187:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,188:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,188:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,199:INFO:Calculating mean and std
2023-11-16 09:11:15,200:INFO:Creating metrics dataframe
2023-11-16 09:11:15,202:INFO:Uploading results into container
2023-11-16 09:11:15,202:INFO:Uploading model into container now
2023-11-16 09:11:15,202:INFO:_master_model_container: 3
2023-11-16 09:11:15,202:INFO:_display_container: 2
2023-11-16 09:11:15,203:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6954, splitter='best')
2023-11-16 09:11:15,203:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,231:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,231:INFO:Creating metrics dataframe
2023-11-16 09:11:15,235:INFO:Initializing SVM - Linear Kernel
2023-11-16 09:11:15,235:INFO:Total runtime is 0.023223686218261718 minutes
2023-11-16 09:11:15,235:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,235:INFO:Initializing create_model()
2023-11-16 09:11:15,235:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,236:INFO:Checking exceptions
2023-11-16 09:11:15,236:INFO:Importing libraries
2023-11-16 09:11:15,236:INFO:Copying training dataset
2023-11-16 09:11:15,237:INFO:Defining folds
2023-11-16 09:11:15,237:INFO:Declaring metric variables
2023-11-16 09:11:15,237:INFO:Importing untrained model
2023-11-16 09:11:15,238:INFO:SVM - Linear Kernel Imported successfully
2023-11-16 09:11:15,238:INFO:Starting cross validation
2023-11-16 09:11:15,238:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,253:WARNING:create_model() for svm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 09:11:15,253:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 09:11:15,253:INFO:Initializing create_model()
2023-11-16 09:11:15,253:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,254:INFO:Checking exceptions
2023-11-16 09:11:15,254:INFO:Importing libraries
2023-11-16 09:11:15,254:INFO:Copying training dataset
2023-11-16 09:11:15,255:INFO:Defining folds
2023-11-16 09:11:15,255:INFO:Declaring metric variables
2023-11-16 09:11:15,255:INFO:Importing untrained model
2023-11-16 09:11:15,256:INFO:SVM - Linear Kernel Imported successfully
2023-11-16 09:11:15,256:INFO:Starting cross validation
2023-11-16 09:11:15,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,271:ERROR:create_model() for svm raised an exception or returned all 0.0:
2023-11-16 09:11:15,272:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 09:11:15,272:INFO:Initializing Ridge Classifier
2023-11-16 09:11:15,272:INFO:Total runtime is 0.023841190338134765 minutes
2023-11-16 09:11:15,272:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,272:INFO:Initializing create_model()
2023-11-16 09:11:15,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,273:INFO:Checking exceptions
2023-11-16 09:11:15,273:INFO:Importing libraries
2023-11-16 09:11:15,273:INFO:Copying training dataset
2023-11-16 09:11:15,274:INFO:Defining folds
2023-11-16 09:11:15,274:INFO:Declaring metric variables
2023-11-16 09:11:15,275:INFO:Importing untrained model
2023-11-16 09:11:15,275:INFO:Ridge Classifier Imported successfully
2023-11-16 09:11:15,275:INFO:Starting cross validation
2023-11-16 09:11:15,275:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,292:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,292:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,292:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,292:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,292:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,292:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,293:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,293:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,293:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,293:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,293:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,294:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,294:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,294:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,294:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,294:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,294:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,294:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,295:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,295:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,295:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,295:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,295:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,295:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,295:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,295:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,296:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,296:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,296:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,296:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,301:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,302:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,302:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,302:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 09:11:15,302:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,303:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,303:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,303:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,304:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,304:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,304:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,304:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,310:INFO:Calculating mean and std
2023-11-16 09:11:15,311:INFO:Creating metrics dataframe
2023-11-16 09:11:15,313:INFO:Uploading results into container
2023-11-16 09:11:15,313:INFO:Uploading model into container now
2023-11-16 09:11:15,313:INFO:_master_model_container: 4
2023-11-16 09:11:15,313:INFO:_display_container: 2
2023-11-16 09:11:15,314:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6954, solver='auto',
                tol=0.0001)
2023-11-16 09:11:15,314:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,346:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,346:INFO:Creating metrics dataframe
2023-11-16 09:11:15,348:INFO:Initializing Quadratic Discriminant Analysis
2023-11-16 09:11:15,349:INFO:Total runtime is 0.025118029117584227 minutes
2023-11-16 09:11:15,349:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,349:INFO:Initializing create_model()
2023-11-16 09:11:15,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,349:INFO:Checking exceptions
2023-11-16 09:11:15,349:INFO:Importing libraries
2023-11-16 09:11:15,349:INFO:Copying training dataset
2023-11-16 09:11:15,351:INFO:Defining folds
2023-11-16 09:11:15,351:INFO:Declaring metric variables
2023-11-16 09:11:15,352:INFO:Importing untrained model
2023-11-16 09:11:15,352:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-16 09:11:15,352:INFO:Starting cross validation
2023-11-16 09:11:15,353:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,367:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 09:11:15,367:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 09:11:15,367:INFO:Initializing create_model()
2023-11-16 09:11:15,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,367:INFO:Checking exceptions
2023-11-16 09:11:15,368:INFO:Importing libraries
2023-11-16 09:11:15,368:INFO:Copying training dataset
2023-11-16 09:11:15,369:INFO:Defining folds
2023-11-16 09:11:15,369:INFO:Declaring metric variables
2023-11-16 09:11:15,369:INFO:Importing untrained model
2023-11-16 09:11:15,370:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-16 09:11:15,370:INFO:Starting cross validation
2023-11-16 09:11:15,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,385:ERROR:create_model() for qda raised an exception or returned all 0.0:
2023-11-16 09:11:15,385:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 09:11:15,385:INFO:Initializing Ada Boost Classifier
2023-11-16 09:11:15,385:INFO:Total runtime is 0.02572911183039347 minutes
2023-11-16 09:11:15,385:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,386:INFO:Initializing create_model()
2023-11-16 09:11:15,386:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,386:INFO:Checking exceptions
2023-11-16 09:11:15,386:INFO:Importing libraries
2023-11-16 09:11:15,386:INFO:Copying training dataset
2023-11-16 09:11:15,387:INFO:Defining folds
2023-11-16 09:11:15,387:INFO:Declaring metric variables
2023-11-16 09:11:15,388:INFO:Importing untrained model
2023-11-16 09:11:15,388:INFO:Ada Boost Classifier Imported successfully
2023-11-16 09:11:15,388:INFO:Starting cross validation
2023-11-16 09:11:15,388:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,398:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,398:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,399:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,399:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,399:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,399:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,400:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,400:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,400:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,400:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,401:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,401:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,401:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,401:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,401:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,401:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,402:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,402:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,402:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,402:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,402:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,402:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,402:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,403:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,403:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,403:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,403:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,403:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,404:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,404:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,408:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,409:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,409:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,409:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,409:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,410:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,410:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,410:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,410:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,410:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,411:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,411:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,411:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,411:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,412:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,412:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,412:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,412:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,412:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,413:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,423:INFO:Calculating mean and std
2023-11-16 09:11:15,423:INFO:Creating metrics dataframe
2023-11-16 09:11:15,425:INFO:Uploading results into container
2023-11-16 09:11:15,425:INFO:Uploading model into container now
2023-11-16 09:11:15,426:INFO:_master_model_container: 5
2023-11-16 09:11:15,426:INFO:_display_container: 2
2023-11-16 09:11:15,426:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6954)
2023-11-16 09:11:15,426:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,455:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,455:INFO:Creating metrics dataframe
2023-11-16 09:11:15,457:INFO:Initializing Linear Discriminant Analysis
2023-11-16 09:11:15,458:INFO:Total runtime is 0.026935525735219318 minutes
2023-11-16 09:11:15,458:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,458:INFO:Initializing create_model()
2023-11-16 09:11:15,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,458:INFO:Checking exceptions
2023-11-16 09:11:15,458:INFO:Importing libraries
2023-11-16 09:11:15,459:INFO:Copying training dataset
2023-11-16 09:11:15,460:INFO:Defining folds
2023-11-16 09:11:15,460:INFO:Declaring metric variables
2023-11-16 09:11:15,460:INFO:Importing untrained model
2023-11-16 09:11:15,460:INFO:Linear Discriminant Analysis Imported successfully
2023-11-16 09:11:15,461:INFO:Starting cross validation
2023-11-16 09:11:15,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,475:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,475:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,475:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,475:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,475:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,475:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,476:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,476:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,476:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,476:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,476:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,477:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,477:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,477:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,477:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,477:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,477:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,478:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,479:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,479:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,479:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,479:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,484:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,484:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,485:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,485:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 09:11:15,485:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,485:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,486:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,486:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,486:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,486:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,486:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,487:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,487:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,487:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,487:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,487:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,487:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,488:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,488:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,488:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,496:INFO:Calculating mean and std
2023-11-16 09:11:15,497:INFO:Creating metrics dataframe
2023-11-16 09:11:15,498:INFO:Uploading results into container
2023-11-16 09:11:15,499:INFO:Uploading model into container now
2023-11-16 09:11:15,499:INFO:_master_model_container: 6
2023-11-16 09:11:15,499:INFO:_display_container: 2
2023-11-16 09:11:15,499:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-16 09:11:15,499:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,528:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,528:INFO:Creating metrics dataframe
2023-11-16 09:11:15,530:INFO:Initializing Extra Trees Classifier
2023-11-16 09:11:15,530:INFO:Total runtime is 0.028150820732116697 minutes
2023-11-16 09:11:15,531:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,531:INFO:Initializing create_model()
2023-11-16 09:11:15,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,531:INFO:Checking exceptions
2023-11-16 09:11:15,531:INFO:Importing libraries
2023-11-16 09:11:15,531:INFO:Copying training dataset
2023-11-16 09:11:15,532:INFO:Defining folds
2023-11-16 09:11:15,533:INFO:Declaring metric variables
2023-11-16 09:11:15,533:INFO:Importing untrained model
2023-11-16 09:11:15,533:INFO:Extra Trees Classifier Imported successfully
2023-11-16 09:11:15,533:INFO:Starting cross validation
2023-11-16 09:11:15,534:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,627:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,628:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,629:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,630:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,630:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,631:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,631:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,632:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,633:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,634:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,634:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,635:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,637:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,637:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,637:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,638:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,639:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,641:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,642:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,642:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,659:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,660:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,661:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,662:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,663:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,671:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,672:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,673:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,674:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,675:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,723:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,724:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,725:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,726:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,726:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,730:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,731:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,732:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,733:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,733:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,736:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,737:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,738:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,739:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,739:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,739:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,740:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,741:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,741:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,742:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,752:INFO:Calculating mean and std
2023-11-16 09:11:15,752:INFO:Creating metrics dataframe
2023-11-16 09:11:15,754:INFO:Uploading results into container
2023-11-16 09:11:15,755:INFO:Uploading model into container now
2023-11-16 09:11:15,755:INFO:_master_model_container: 7
2023-11-16 09:11:15,755:INFO:_display_container: 2
2023-11-16 09:11:15,755:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6954, verbose=0, warm_start=False)
2023-11-16 09:11:15,755:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,785:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,785:INFO:Creating metrics dataframe
2023-11-16 09:11:15,787:INFO:Initializing Light Gradient Boosting Machine
2023-11-16 09:11:15,787:INFO:Total runtime is 0.03243365287780761 minutes
2023-11-16 09:11:15,788:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,788:INFO:Initializing create_model()
2023-11-16 09:11:15,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,788:INFO:Checking exceptions
2023-11-16 09:11:15,788:INFO:Importing libraries
2023-11-16 09:11:15,788:INFO:Copying training dataset
2023-11-16 09:11:15,790:INFO:Defining folds
2023-11-16 09:11:15,790:INFO:Declaring metric variables
2023-11-16 09:11:15,790:INFO:Importing untrained model
2023-11-16 09:11:15,790:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-16 09:11:15,790:INFO:Starting cross validation
2023-11-16 09:11:15,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,816:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,817:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,818:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,820:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,820:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,824:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,825:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,826:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,826:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,827:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,828:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,828:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,830:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,830:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,830:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,831:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,832:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,832:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,832:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,833:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,834:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,835:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,834:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,839:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,839:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,840:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,840:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,841:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,843:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,844:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,845:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,846:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,846:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,846:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,848:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,853:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,854:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,854:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,855:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,855:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,856:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,856:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,856:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,857:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,858:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,858:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 09:11:15,858:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,859:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,860:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,860:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,866:INFO:Calculating mean and std
2023-11-16 09:11:15,866:INFO:Creating metrics dataframe
2023-11-16 09:11:15,868:INFO:Uploading results into container
2023-11-16 09:11:15,868:INFO:Uploading model into container now
2023-11-16 09:11:15,869:INFO:_master_model_container: 8
2023-11-16 09:11:15,869:INFO:_display_container: 2
2023-11-16 09:11:15,869:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6954, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-16 09:11:15,869:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,899:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,900:INFO:Creating metrics dataframe
2023-11-16 09:11:15,902:INFO:Initializing Dummy Classifier
2023-11-16 09:11:15,902:INFO:Total runtime is 0.034343930085500074 minutes
2023-11-16 09:11:15,902:INFO:SubProcess create_model() called ==================================
2023-11-16 09:11:15,902:INFO:Initializing create_model()
2023-11-16 09:11:15,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff93397f70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,903:INFO:Checking exceptions
2023-11-16 09:11:15,903:INFO:Importing libraries
2023-11-16 09:11:15,903:INFO:Copying training dataset
2023-11-16 09:11:15,904:INFO:Defining folds
2023-11-16 09:11:15,904:INFO:Declaring metric variables
2023-11-16 09:11:15,905:INFO:Importing untrained model
2023-11-16 09:11:15,905:INFO:Dummy Classifier Imported successfully
2023-11-16 09:11:15,905:INFO:Starting cross validation
2023-11-16 09:11:15,905:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 09:11:15,914:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,914:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,915:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,915:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (8, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,915:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,915:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,916:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,916:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,916:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,916:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,916:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,917:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,916:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,917:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,917:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,917:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,917:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,917:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,920:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,920:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,923:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,923:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,923:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,923:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,924:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (7, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 09:11:15,924:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,924:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,924:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,925:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,925:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,925:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,925:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,925:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,926:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 09:11:15,926:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,926:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,926:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,926:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,927:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 09:11:15,927:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 09:11:15,930:INFO:Calculating mean and std
2023-11-16 09:11:15,930:INFO:Creating metrics dataframe
2023-11-16 09:11:15,932:INFO:Uploading results into container
2023-11-16 09:11:15,932:INFO:Uploading model into container now
2023-11-16 09:11:15,932:INFO:_master_model_container: 9
2023-11-16 09:11:15,932:INFO:_display_container: 2
2023-11-16 09:11:15,933:INFO:DummyClassifier(constant=None, random_state=6954, strategy='prior')
2023-11-16 09:11:15,933:INFO:create_model() successfully completed......................................
2023-11-16 09:11:15,961:INFO:SubProcess create_model() end ==================================
2023-11-16 09:11:15,961:INFO:Creating metrics dataframe
2023-11-16 09:11:15,964:INFO:Initializing create_model()
2023-11-16 09:11:15,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:11:15,965:INFO:Checking exceptions
2023-11-16 09:11:15,965:INFO:Importing libraries
2023-11-16 09:11:15,965:INFO:Copying training dataset
2023-11-16 09:11:15,967:INFO:Defining folds
2023-11-16 09:11:15,967:INFO:Declaring metric variables
2023-11-16 09:11:15,967:INFO:Importing untrained model
2023-11-16 09:11:15,967:INFO:Declaring custom model
2023-11-16 09:11:15,967:INFO:K Neighbors Classifier Imported successfully
2023-11-16 09:11:15,968:INFO:Cross validation set to False
2023-11-16 09:11:15,968:INFO:Fitting Model
2023-11-16 09:11:15,972:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 09:11:15,972:INFO:create_model() successfully completed......................................
2023-11-16 09:11:16,003:INFO:_master_model_container: 9
2023-11-16 09:11:16,003:INFO:_display_container: 2
2023-11-16 09:11:16,003:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 09:11:16,003:INFO:compare_models() successfully completed......................................
2023-11-16 09:12:38,281:INFO:Initializing create_model()
2023-11-16 09:12:38,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb0a69100>, estimator=rbfsvm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 09:12:38,285:INFO:Checking exceptions
2023-11-16 09:12:38,303:INFO:Importing libraries
2023-11-16 09:12:38,303:INFO:Copying training dataset
2023-11-16 09:12:38,308:INFO:Defining folds
2023-11-16 09:12:38,308:INFO:Declaring metric variables
2023-11-16 09:12:38,309:INFO:Importing untrained model
2023-11-16 09:12:38,310:INFO:SVM - Radial Kernel Imported successfully
2023-11-16 09:12:38,311:INFO:Starting cross validation
2023-11-16 09:12:38,313:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-16 10:02:49,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:02:49,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:02:49,654:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:02:49,654:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:09,939:INFO:PyCaret ClassificationExperiment
2023-11-16 10:07:09,941:INFO:Logging name: clf-default-name
2023-11-16 10:07:09,941:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-16 10:07:09,941:INFO:version 3.2.0
2023-11-16 10:07:09,942:INFO:Initializing setup()
2023-11-16 10:07:09,942:INFO:self.USI: 1ae3
2023-11-16 10:07:09,942:INFO:self._variable_keys: {'y_train', 'memory', 'target_param', 'fix_imbalance', 'html_param', 'gpu_param', 'fold_groups_param', 'is_multiclass', 'X_test', 'n_jobs_param', 'y', 'gpu_n_jobs_param', 'fold_shuffle_param', 'pipeline', '_ml_usecase', 'log_plots_param', '_available_plots', 'seed', 'fold_generator', 'USI', 'idx', 'exp_id', 'logging_param', 'y_test', 'data', 'exp_name_log', 'X', 'X_train'}
2023-11-16 10:07:09,942:INFO:Checking environment
2023-11-16 10:07:09,943:INFO:python_version: 3.8.18
2023-11-16 10:07:09,943:INFO:python_build: ('default', 'Nov  1 2023 11:08:38')
2023-11-16 10:07:09,943:INFO:machine: aarch64
2023-11-16 10:07:09,945:INFO:platform: Linux-5.15.49-linuxkit-pr-aarch64-with-glibc2.34
2023-11-16 10:07:09,945:INFO:Memory: svmem(total=8232710144, available=7023550464, percent=14.7, used=685236224, free=4238479360, active=911339520, inactive=2613202944, buffers=114892800, cached=3194101760, shared=316342272, slab=327696384)
2023-11-16 10:07:09,947:INFO:Physical Core: 6
2023-11-16 10:07:09,947:INFO:Logical Core: 6
2023-11-16 10:07:09,947:INFO:Checking libraries
2023-11-16 10:07:09,947:INFO:System:
2023-11-16 10:07:09,947:INFO:    python: 3.8.18 (default, Nov  1 2023, 11:08:38)  [GCC 12.2.0]
2023-11-16 10:07:09,947:INFO:executable: /usr/local/bin/python
2023-11-16 10:07:09,948:INFO:   machine: Linux-5.15.49-linuxkit-pr-aarch64-with-glibc2.34
2023-11-16 10:07:09,948:INFO:PyCaret required dependencies:
2023-11-16 10:07:09,993:INFO:                 pip: 23.3.1
2023-11-16 10:07:09,993:INFO:          setuptools: 57.5.0
2023-11-16 10:07:09,993:INFO:             pycaret: 3.2.0
2023-11-16 10:07:09,993:INFO:             IPython: 8.12.3
2023-11-16 10:07:09,993:INFO:          ipywidgets: 8.1.1
2023-11-16 10:07:09,993:INFO:                tqdm: 4.66.1
2023-11-16 10:07:09,994:INFO:               numpy: 1.24.4
2023-11-16 10:07:09,994:INFO:              pandas: 1.5.3
2023-11-16 10:07:09,994:INFO:              jinja2: 3.1.2
2023-11-16 10:07:09,994:INFO:               scipy: 1.10.1
2023-11-16 10:07:09,994:INFO:              joblib: 1.3.2
2023-11-16 10:07:09,994:INFO:             sklearn: 1.2.2
2023-11-16 10:07:09,994:INFO:                pyod: 1.1.1
2023-11-16 10:07:09,995:INFO:            imblearn: 0.11.0
2023-11-16 10:07:09,995:INFO:   category_encoders: 2.6.3
2023-11-16 10:07:09,995:INFO:            lightgbm: 4.1.0
2023-11-16 10:07:09,995:INFO:               numba: 0.58.1
2023-11-16 10:07:09,995:INFO:            requests: 2.31.0
2023-11-16 10:07:09,995:INFO:          matplotlib: 3.6.0
2023-11-16 10:07:09,995:INFO:          scikitplot: 0.3.7
2023-11-16 10:07:09,995:INFO:         yellowbrick: 1.5
2023-11-16 10:07:09,996:INFO:              plotly: 5.18.0
2023-11-16 10:07:09,996:INFO:    plotly-resampler: Not installed
2023-11-16 10:07:09,996:INFO:             kaleido: 0.2.1
2023-11-16 10:07:09,996:INFO:           schemdraw: 0.15
2023-11-16 10:07:09,996:INFO:         statsmodels: 0.14.0
2023-11-16 10:07:09,996:INFO:              sktime: 0.21.1
2023-11-16 10:07:09,996:INFO:               tbats: 1.1.3
2023-11-16 10:07:09,996:INFO:            pmdarima: 2.0.4
2023-11-16 10:07:09,997:INFO:              psutil: 5.9.6
2023-11-16 10:07:09,997:INFO:          markupsafe: 2.1.3
2023-11-16 10:07:09,997:INFO:             pickle5: Not installed
2023-11-16 10:07:09,997:INFO:         cloudpickle: 3.0.0
2023-11-16 10:07:09,997:INFO:         deprecation: 2.1.0
2023-11-16 10:07:09,997:INFO:              xxhash: 3.4.1
2023-11-16 10:07:09,997:INFO:           wurlitzer: 3.0.3
2023-11-16 10:07:09,997:INFO:PyCaret optional dependencies:
2023-11-16 10:07:10,009:INFO:                shap: Not installed
2023-11-16 10:07:10,009:INFO:           interpret: Not installed
2023-11-16 10:07:10,009:INFO:                umap: Not installed
2023-11-16 10:07:10,009:INFO:     ydata_profiling: Not installed
2023-11-16 10:07:10,009:INFO:  explainerdashboard: Not installed
2023-11-16 10:07:10,009:INFO:             autoviz: Not installed
2023-11-16 10:07:10,009:INFO:           fairlearn: Not installed
2023-11-16 10:07:10,010:INFO:          deepchecks: Not installed
2023-11-16 10:07:10,010:INFO:             xgboost: Not installed
2023-11-16 10:07:10,010:INFO:            catboost: Not installed
2023-11-16 10:07:10,010:INFO:              kmodes: Not installed
2023-11-16 10:07:10,010:INFO:             mlxtend: Not installed
2023-11-16 10:07:10,010:INFO:       statsforecast: Not installed
2023-11-16 10:07:10,010:INFO:        tune_sklearn: Not installed
2023-11-16 10:07:10,010:INFO:                 ray: Not installed
2023-11-16 10:07:10,010:INFO:            hyperopt: Not installed
2023-11-16 10:07:10,010:INFO:              optuna: Not installed
2023-11-16 10:07:10,010:INFO:               skopt: Not installed
2023-11-16 10:07:10,010:INFO:              mlflow: Not installed
2023-11-16 10:07:10,010:INFO:              gradio: Not installed
2023-11-16 10:07:10,010:INFO:             fastapi: Not installed
2023-11-16 10:07:10,011:INFO:             uvicorn: Not installed
2023-11-16 10:07:10,011:INFO:              m2cgen: Not installed
2023-11-16 10:07:10,011:INFO:           evidently: Not installed
2023-11-16 10:07:10,011:INFO:               fugue: Not installed
2023-11-16 10:07:10,011:INFO:           streamlit: Not installed
2023-11-16 10:07:10,011:INFO:             prophet: Not installed
2023-11-16 10:07:10,011:INFO:None
2023-11-16 10:07:10,011:INFO:Set up GPU usage.
2023-11-16 10:07:10,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,011:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-16 10:07:10,012:INFO:Set up data.
2023-11-16 10:07:10,030:INFO:Set up folding strategy.
2023-11-16 10:07:10,031:INFO:Set up train/test split.
2023-11-16 10:07:10,035:INFO:Set up index.
2023-11-16 10:07:10,035:INFO:Assigning column types.
2023-11-16 10:07:10,037:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-16 10:07:10,037:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,056:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-16 10:07:10,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,058:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 10:07:10,059:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,070:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,072:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,074:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,111:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,130:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-16 10:07:10,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,131:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 10:07:10,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,145:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-16 10:07:10,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,163:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,164:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 10:07:10,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,172:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,182:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,201:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 10:07:10,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,212:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,213:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,216:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-16 10:07:10,216:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,234:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,234:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,235:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,244:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,248:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,268:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,276:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,281:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,283:INFO:Preparing preprocessing pipeline...
2023-11-16 10:07:10,285:INFO:Set up simple imputation.
2023-11-16 10:07:10,297:INFO:Finished creating preprocessing pipeline.
2023-11-16 10:07:10,300:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-16 10:07:10,300:INFO:Creating final display dataframe.
2023-11-16 10:07:10,324:INFO:Setup _display_container:                     Description             Value
0                    Session id              6235
1                        Target            target
2                   Target type        Multiclass
3           Original data shape         (106, 13)
4        Transformed data shape         (106, 13)
5   Transformed train set shape          (74, 13)
6    Transformed test set shape          (32, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              1ae3
2023-11-16 10:07:10,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,359:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,378:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,378:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,378:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,387:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,389:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:07:10,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:07:10,393:INFO:setup() successfully completed in 0.47s...............
2023-11-16 10:07:38,284:INFO:Initializing compare_models()
2023-11-16 10:07:38,286:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-16 10:07:38,286:INFO:Checking exceptions
2023-11-16 10:07:38,294:INFO:Preparing display monitor
2023-11-16 10:07:38,303:INFO:Initializing Logistic Regression
2023-11-16 10:07:38,303:INFO:Total runtime is 6.564458211263021e-06 minutes
2023-11-16 10:07:38,304:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:38,304:INFO:Initializing create_model()
2023-11-16 10:07:38,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,305:INFO:Checking exceptions
2023-11-16 10:07:38,305:INFO:Importing libraries
2023-11-16 10:07:38,305:INFO:Copying training dataset
2023-11-16 10:07:38,309:INFO:Defining folds
2023-11-16 10:07:38,309:INFO:Declaring metric variables
2023-11-16 10:07:38,310:INFO:Importing untrained model
2023-11-16 10:07:38,310:INFO:Logistic Regression Imported successfully
2023-11-16 10:07:38,311:INFO:Starting cross validation
2023-11-16 10:07:38,311:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,334:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 10:07:38,336:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2023-11-16 10:07:38,336:INFO:Initializing create_model()
2023-11-16 10:07:38,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,337:INFO:Checking exceptions
2023-11-16 10:07:38,337:INFO:Importing libraries
2023-11-16 10:07:38,337:INFO:Copying training dataset
2023-11-16 10:07:38,339:INFO:Defining folds
2023-11-16 10:07:38,339:INFO:Declaring metric variables
2023-11-16 10:07:38,339:INFO:Importing untrained model
2023-11-16 10:07:38,339:INFO:Logistic Regression Imported successfully
2023-11-16 10:07:38,340:INFO:Starting cross validation
2023-11-16 10:07:38,340:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,358:ERROR:create_model() for lr raised an exception or returned all 0.0:
2023-11-16 10:07:38,358:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2023-11-16 10:07:38,359:INFO:Initializing K Neighbors Classifier
2023-11-16 10:07:38,359:INFO:Total runtime is 0.0009341319402058919 minutes
2023-11-16 10:07:38,359:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:38,359:INFO:Initializing create_model()
2023-11-16 10:07:38,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,360:INFO:Checking exceptions
2023-11-16 10:07:38,360:INFO:Importing libraries
2023-11-16 10:07:38,360:INFO:Copying training dataset
2023-11-16 10:07:38,361:INFO:Defining folds
2023-11-16 10:07:38,362:INFO:Declaring metric variables
2023-11-16 10:07:38,362:INFO:Importing untrained model
2023-11-16 10:07:38,362:INFO:K Neighbors Classifier Imported successfully
2023-11-16 10:07:38,362:INFO:Starting cross validation
2023-11-16 10:07:38,363:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,399:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,401:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,402:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,403:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,404:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,435:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,436:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,437:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,438:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,439:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,469:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,470:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,471:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,472:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,473:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,505:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,507:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,508:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,509:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,510:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,540:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,541:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,542:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,543:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,544:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,545:INFO:Calculating mean and std
2023-11-16 10:07:38,545:INFO:Creating metrics dataframe
2023-11-16 10:07:38,547:INFO:Uploading results into container
2023-11-16 10:07:38,548:INFO:Uploading model into container now
2023-11-16 10:07:38,548:INFO:_master_model_container: 1
2023-11-16 10:07:38,548:INFO:_display_container: 2
2023-11-16 10:07:38,549:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 10:07:38,549:INFO:create_model() successfully completed......................................
2023-11-16 10:07:38,699:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:38,699:INFO:Creating metrics dataframe
2023-11-16 10:07:38,701:INFO:Initializing Naive Bayes
2023-11-16 10:07:38,701:INFO:Total runtime is 0.006643561522165934 minutes
2023-11-16 10:07:38,702:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:38,702:INFO:Initializing create_model()
2023-11-16 10:07:38,702:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,702:INFO:Checking exceptions
2023-11-16 10:07:38,702:INFO:Importing libraries
2023-11-16 10:07:38,702:INFO:Copying training dataset
2023-11-16 10:07:38,704:INFO:Defining folds
2023-11-16 10:07:38,704:INFO:Declaring metric variables
2023-11-16 10:07:38,704:INFO:Importing untrained model
2023-11-16 10:07:38,704:INFO:Naive Bayes Imported successfully
2023-11-16 10:07:38,704:INFO:Starting cross validation
2023-11-16 10:07:38,705:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,710:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,711:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,712:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,713:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,713:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,718:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,719:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,720:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,721:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,721:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,726:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,727:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,728:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,729:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,729:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,734:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,735:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,735:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,736:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,736:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,741:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,742:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,743:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,744:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,744:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,745:INFO:Calculating mean and std
2023-11-16 10:07:38,745:INFO:Creating metrics dataframe
2023-11-16 10:07:38,747:INFO:Uploading results into container
2023-11-16 10:07:38,747:INFO:Uploading model into container now
2023-11-16 10:07:38,747:INFO:_master_model_container: 2
2023-11-16 10:07:38,747:INFO:_display_container: 2
2023-11-16 10:07:38,748:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-16 10:07:38,748:INFO:create_model() successfully completed......................................
2023-11-16 10:07:38,775:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:38,776:INFO:Creating metrics dataframe
2023-11-16 10:07:38,778:INFO:Initializing Decision Tree Classifier
2023-11-16 10:07:38,778:INFO:Total runtime is 0.007922617594401042 minutes
2023-11-16 10:07:38,778:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:38,779:INFO:Initializing create_model()
2023-11-16 10:07:38,779:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,779:INFO:Checking exceptions
2023-11-16 10:07:38,779:INFO:Importing libraries
2023-11-16 10:07:38,779:INFO:Copying training dataset
2023-11-16 10:07:38,780:INFO:Defining folds
2023-11-16 10:07:38,780:INFO:Declaring metric variables
2023-11-16 10:07:38,781:INFO:Importing untrained model
2023-11-16 10:07:38,781:INFO:Decision Tree Classifier Imported successfully
2023-11-16 10:07:38,781:INFO:Starting cross validation
2023-11-16 10:07:38,781:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,788:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,789:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,790:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,791:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,791:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,796:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,797:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,797:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,798:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,799:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,804:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,804:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,805:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,806:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,806:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,811:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,812:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,813:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,814:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,814:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,819:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:38,820:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,821:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,821:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,822:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,823:INFO:Calculating mean and std
2023-11-16 10:07:38,823:INFO:Creating metrics dataframe
2023-11-16 10:07:38,824:INFO:Uploading results into container
2023-11-16 10:07:38,824:INFO:Uploading model into container now
2023-11-16 10:07:38,825:INFO:_master_model_container: 3
2023-11-16 10:07:38,825:INFO:_display_container: 2
2023-11-16 10:07:38,825:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6235, splitter='best')
2023-11-16 10:07:38,825:INFO:create_model() successfully completed......................................
2023-11-16 10:07:38,852:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:38,853:INFO:Creating metrics dataframe
2023-11-16 10:07:38,855:INFO:Initializing SVM - Linear Kernel
2023-11-16 10:07:38,855:INFO:Total runtime is 0.009201121330261231 minutes
2023-11-16 10:07:38,855:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:38,855:INFO:Initializing create_model()
2023-11-16 10:07:38,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,856:INFO:Checking exceptions
2023-11-16 10:07:38,856:INFO:Importing libraries
2023-11-16 10:07:38,856:INFO:Copying training dataset
2023-11-16 10:07:38,857:INFO:Defining folds
2023-11-16 10:07:38,857:INFO:Declaring metric variables
2023-11-16 10:07:38,857:INFO:Importing untrained model
2023-11-16 10:07:38,858:INFO:SVM - Linear Kernel Imported successfully
2023-11-16 10:07:38,858:INFO:Starting cross validation
2023-11-16 10:07:38,858:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,874:WARNING:create_model() for svm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 10:07:38,874:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 10:07:38,874:INFO:Initializing create_model()
2023-11-16 10:07:38,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,874:INFO:Checking exceptions
2023-11-16 10:07:38,874:INFO:Importing libraries
2023-11-16 10:07:38,875:INFO:Copying training dataset
2023-11-16 10:07:38,876:INFO:Defining folds
2023-11-16 10:07:38,876:INFO:Declaring metric variables
2023-11-16 10:07:38,876:INFO:Importing untrained model
2023-11-16 10:07:38,876:INFO:SVM - Linear Kernel Imported successfully
2023-11-16 10:07:38,877:INFO:Starting cross validation
2023-11-16 10:07:38,877:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,891:ERROR:create_model() for svm raised an exception or returned all 0.0:
2023-11-16 10:07:38,892:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 10:07:38,892:INFO:Initializing Ridge Classifier
2023-11-16 10:07:38,892:INFO:Total runtime is 0.009817826747894288 minutes
2023-11-16 10:07:38,892:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:38,892:INFO:Initializing create_model()
2023-11-16 10:07:38,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,892:INFO:Checking exceptions
2023-11-16 10:07:38,893:INFO:Importing libraries
2023-11-16 10:07:38,893:INFO:Copying training dataset
2023-11-16 10:07:38,894:INFO:Defining folds
2023-11-16 10:07:38,894:INFO:Declaring metric variables
2023-11-16 10:07:38,894:INFO:Importing untrained model
2023-11-16 10:07:38,894:INFO:Ridge Classifier Imported successfully
2023-11-16 10:07:38,895:INFO:Starting cross validation
2023-11-16 10:07:38,895:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,902:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:07:38,903:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,903:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,904:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,905:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,909:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:07:38,910:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,911:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,912:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,912:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,917:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:07:38,918:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,919:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,920:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,925:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:07:38,925:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,926:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,927:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,927:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,932:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:07:38,933:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,934:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:38,935:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:38,935:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:38,936:INFO:Calculating mean and std
2023-11-16 10:07:38,936:INFO:Creating metrics dataframe
2023-11-16 10:07:38,937:INFO:Uploading results into container
2023-11-16 10:07:38,937:INFO:Uploading model into container now
2023-11-16 10:07:38,938:INFO:_master_model_container: 4
2023-11-16 10:07:38,938:INFO:_display_container: 2
2023-11-16 10:07:38,938:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6235, solver='auto',
                tol=0.0001)
2023-11-16 10:07:38,938:INFO:create_model() successfully completed......................................
2023-11-16 10:07:38,966:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:38,966:INFO:Creating metrics dataframe
2023-11-16 10:07:38,968:INFO:Initializing Quadratic Discriminant Analysis
2023-11-16 10:07:38,968:INFO:Total runtime is 0.011089416344960532 minutes
2023-11-16 10:07:38,968:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:38,969:INFO:Initializing create_model()
2023-11-16 10:07:38,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,969:INFO:Checking exceptions
2023-11-16 10:07:38,969:INFO:Importing libraries
2023-11-16 10:07:38,969:INFO:Copying training dataset
2023-11-16 10:07:38,970:INFO:Defining folds
2023-11-16 10:07:38,970:INFO:Declaring metric variables
2023-11-16 10:07:38,971:INFO:Importing untrained model
2023-11-16 10:07:38,971:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-16 10:07:38,971:INFO:Starting cross validation
2023-11-16 10:07:38,972:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:38,986:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 10:07:38,986:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 10:07:38,987:INFO:Initializing create_model()
2023-11-16 10:07:38,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:38,987:INFO:Checking exceptions
2023-11-16 10:07:38,987:INFO:Importing libraries
2023-11-16 10:07:38,987:INFO:Copying training dataset
2023-11-16 10:07:38,988:INFO:Defining folds
2023-11-16 10:07:38,989:INFO:Declaring metric variables
2023-11-16 10:07:38,989:INFO:Importing untrained model
2023-11-16 10:07:38,989:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-16 10:07:38,989:INFO:Starting cross validation
2023-11-16 10:07:38,990:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:39,003:ERROR:create_model() for qda raised an exception or returned all 0.0:
2023-11-16 10:07:39,003:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 10:07:39,003:INFO:Initializing Ada Boost Classifier
2023-11-16 10:07:39,004:INFO:Total runtime is 0.01167870362599691 minutes
2023-11-16 10:07:39,004:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:39,004:INFO:Initializing create_model()
2023-11-16 10:07:39,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:39,004:INFO:Checking exceptions
2023-11-16 10:07:39,004:INFO:Importing libraries
2023-11-16 10:07:39,004:INFO:Copying training dataset
2023-11-16 10:07:39,005:INFO:Defining folds
2023-11-16 10:07:39,005:INFO:Declaring metric variables
2023-11-16 10:07:39,006:INFO:Importing untrained model
2023-11-16 10:07:39,006:INFO:Ada Boost Classifier Imported successfully
2023-11-16 10:07:39,006:INFO:Starting cross validation
2023-11-16 10:07:39,006:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:39,012:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,013:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,014:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,014:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,015:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,020:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,021:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,022:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,022:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,023:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,028:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,028:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,029:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,030:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,030:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,035:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,036:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,037:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,038:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,038:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,043:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,044:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,044:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,045:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,046:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,046:INFO:Calculating mean and std
2023-11-16 10:07:39,047:INFO:Creating metrics dataframe
2023-11-16 10:07:39,048:INFO:Uploading results into container
2023-11-16 10:07:39,048:INFO:Uploading model into container now
2023-11-16 10:07:39,048:INFO:_master_model_container: 5
2023-11-16 10:07:39,049:INFO:_display_container: 2
2023-11-16 10:07:39,049:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6235)
2023-11-16 10:07:39,049:INFO:create_model() successfully completed......................................
2023-11-16 10:07:39,077:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:39,077:INFO:Creating metrics dataframe
2023-11-16 10:07:39,079:INFO:Initializing Linear Discriminant Analysis
2023-11-16 10:07:39,079:INFO:Total runtime is 0.01294372081756592 minutes
2023-11-16 10:07:39,080:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:39,080:INFO:Initializing create_model()
2023-11-16 10:07:39,080:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:39,080:INFO:Checking exceptions
2023-11-16 10:07:39,080:INFO:Importing libraries
2023-11-16 10:07:39,080:INFO:Copying training dataset
2023-11-16 10:07:39,082:INFO:Defining folds
2023-11-16 10:07:39,082:INFO:Declaring metric variables
2023-11-16 10:07:39,082:INFO:Importing untrained model
2023-11-16 10:07:39,082:INFO:Linear Discriminant Analysis Imported successfully
2023-11-16 10:07:39,082:INFO:Starting cross validation
2023-11-16 10:07:39,083:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:39,090:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:07:39,091:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,092:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,092:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,093:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,098:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:07:39,099:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,100:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,100:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,101:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,106:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:07:39,107:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,107:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,108:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,109:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,114:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:07:39,114:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,115:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,116:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,116:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,122:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:07:39,123:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,124:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,124:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,125:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,126:INFO:Calculating mean and std
2023-11-16 10:07:39,126:INFO:Creating metrics dataframe
2023-11-16 10:07:39,127:INFO:Uploading results into container
2023-11-16 10:07:39,128:INFO:Uploading model into container now
2023-11-16 10:07:39,128:INFO:_master_model_container: 6
2023-11-16 10:07:39,128:INFO:_display_container: 2
2023-11-16 10:07:39,128:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-16 10:07:39,129:INFO:create_model() successfully completed......................................
2023-11-16 10:07:39,158:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:39,158:INFO:Creating metrics dataframe
2023-11-16 10:07:39,160:INFO:Initializing Extra Trees Classifier
2023-11-16 10:07:39,160:INFO:Total runtime is 0.014289323488871259 minutes
2023-11-16 10:07:39,160:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:39,161:INFO:Initializing create_model()
2023-11-16 10:07:39,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:39,161:INFO:Checking exceptions
2023-11-16 10:07:39,161:INFO:Importing libraries
2023-11-16 10:07:39,161:INFO:Copying training dataset
2023-11-16 10:07:39,162:INFO:Defining folds
2023-11-16 10:07:39,162:INFO:Declaring metric variables
2023-11-16 10:07:39,162:INFO:Importing untrained model
2023-11-16 10:07:39,163:INFO:Extra Trees Classifier Imported successfully
2023-11-16 10:07:39,163:INFO:Starting cross validation
2023-11-16 10:07:39,163:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:39,260:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,261:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,262:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,263:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,263:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,361:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,362:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,363:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,364:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,364:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,462:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,463:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,464:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,465:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,465:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,570:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,571:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,572:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,573:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,573:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,673:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,674:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,675:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,676:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,676:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,677:INFO:Calculating mean and std
2023-11-16 10:07:39,677:INFO:Creating metrics dataframe
2023-11-16 10:07:39,679:INFO:Uploading results into container
2023-11-16 10:07:39,679:INFO:Uploading model into container now
2023-11-16 10:07:39,679:INFO:_master_model_container: 7
2023-11-16 10:07:39,680:INFO:_display_container: 2
2023-11-16 10:07:39,680:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6235, verbose=0, warm_start=False)
2023-11-16 10:07:39,680:INFO:create_model() successfully completed......................................
2023-11-16 10:07:39,710:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:39,710:INFO:Creating metrics dataframe
2023-11-16 10:07:39,712:INFO:Initializing Light Gradient Boosting Machine
2023-11-16 10:07:39,712:INFO:Total runtime is 0.023488962650299074 minutes
2023-11-16 10:07:39,712:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:39,713:INFO:Initializing create_model()
2023-11-16 10:07:39,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:39,713:INFO:Checking exceptions
2023-11-16 10:07:39,713:INFO:Importing libraries
2023-11-16 10:07:39,713:INFO:Copying training dataset
2023-11-16 10:07:39,714:INFO:Defining folds
2023-11-16 10:07:39,714:INFO:Declaring metric variables
2023-11-16 10:07:39,715:INFO:Importing untrained model
2023-11-16 10:07:39,715:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-16 10:07:39,715:INFO:Starting cross validation
2023-11-16 10:07:39,716:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:39,720:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:07:39,721:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 59
2023-11-16 10:07:39,721:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000058 seconds.
2023-11-16 10:07:39,721:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:07:39,721:INFO:[LightGBM] [Info] Total Bins 254
2023-11-16 10:07:39,721:INFO:[LightGBM] [Info] Number of data points in the train set: 59, number of used features: 12
2023-11-16 10:07:39,722:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:07:39,722:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:07:39,722:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,722:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,722:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,722:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,723:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,724:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,725:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,726:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,727:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,728:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,729:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,730:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,731:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,732:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,732:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,732:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,734:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,735:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,740:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:07:39,741:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,742:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,743:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,744:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,748:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:07:39,748:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 59
2023-11-16 10:07:39,748:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000026 seconds.
2023-11-16 10:07:39,749:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:07:39,749:INFO:[LightGBM] [Info] Total Bins 255
2023-11-16 10:07:39,749:INFO:[LightGBM] [Info] Number of data points in the train set: 59, number of used features: 12
2023-11-16 10:07:39,749:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:07:39,749:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:07:39,749:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,750:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,751:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,752:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,753:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,755:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,757:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,758:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,759:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,760:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,763:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:07:39,764:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,764:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,765:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,766:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,769:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:07:39,769:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 59
2023-11-16 10:07:39,770:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000023 seconds.
2023-11-16 10:07:39,770:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:07:39,770:INFO:[LightGBM] [Info] Total Bins 256
2023-11-16 10:07:39,770:INFO:[LightGBM] [Info] Number of data points in the train set: 59, number of used features: 12
2023-11-16 10:07:39,770:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:07:39,770:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:07:39,770:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,771:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,772:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,773:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,774:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,775:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,776:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,778:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,779:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,780:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,781:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,784:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:07:39,785:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,785:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,786:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,787:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,790:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:07:39,790:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 59
2023-11-16 10:07:39,791:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000022 seconds.
2023-11-16 10:07:39,791:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:07:39,791:INFO:[LightGBM] [Info] Total Bins 254
2023-11-16 10:07:39,791:INFO:[LightGBM] [Info] Number of data points in the train set: 59, number of used features: 12
2023-11-16 10:07:39,791:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:07:39,791:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,792:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,793:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,794:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,795:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,796:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,797:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,799:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,800:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,801:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,802:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,803:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,805:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:07:39,806:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,807:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,807:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,808:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,813:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:07:39,813:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 60
2023-11-16 10:07:39,813:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000023 seconds.
2023-11-16 10:07:39,813:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:07:39,813:INFO:[LightGBM] [Info] Total Bins 257
2023-11-16 10:07:39,813:INFO:[LightGBM] [Info] Number of data points in the train set: 60, number of used features: 12
2023-11-16 10:07:39,814:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:07:39,814:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:07:39,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,817:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,818:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,819:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,820:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,821:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,822:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,823:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,824:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,825:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:07:39,828:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:07:39,829:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,829:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,830:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,831:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,831:INFO:Calculating mean and std
2023-11-16 10:07:39,832:INFO:Creating metrics dataframe
2023-11-16 10:07:39,833:INFO:Uploading results into container
2023-11-16 10:07:39,834:INFO:Uploading model into container now
2023-11-16 10:07:39,834:INFO:_master_model_container: 8
2023-11-16 10:07:39,834:INFO:_display_container: 2
2023-11-16 10:07:39,834:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6235, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-16 10:07:39,834:INFO:create_model() successfully completed......................................
2023-11-16 10:07:39,864:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:39,864:INFO:Creating metrics dataframe
2023-11-16 10:07:39,866:INFO:Initializing Dummy Classifier
2023-11-16 10:07:39,866:INFO:Total runtime is 0.026060946782430015 minutes
2023-11-16 10:07:39,867:INFO:SubProcess create_model() called ==================================
2023-11-16 10:07:39,867:INFO:Initializing create_model()
2023-11-16 10:07:39,867:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5e945e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:39,867:INFO:Checking exceptions
2023-11-16 10:07:39,867:INFO:Importing libraries
2023-11-16 10:07:39,867:INFO:Copying training dataset
2023-11-16 10:07:39,868:INFO:Defining folds
2023-11-16 10:07:39,869:INFO:Declaring metric variables
2023-11-16 10:07:39,869:INFO:Importing untrained model
2023-11-16 10:07:39,869:INFO:Dummy Classifier Imported successfully
2023-11-16 10:07:39,869:INFO:Starting cross validation
2023-11-16 10:07:39,870:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:07:39,874:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,875:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,876:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,877:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,877:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,881:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,882:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,883:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,883:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,884:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,888:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,888:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,889:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,890:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,890:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,894:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,895:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,896:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,896:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,897:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,901:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:07:39,901:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,902:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:07:39,903:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:07:39,903:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:07:39,904:INFO:Calculating mean and std
2023-11-16 10:07:39,904:INFO:Creating metrics dataframe
2023-11-16 10:07:39,905:INFO:Uploading results into container
2023-11-16 10:07:39,906:INFO:Uploading model into container now
2023-11-16 10:07:39,906:INFO:_master_model_container: 9
2023-11-16 10:07:39,906:INFO:_display_container: 2
2023-11-16 10:07:39,906:INFO:DummyClassifier(constant=None, random_state=6235, strategy='prior')
2023-11-16 10:07:39,906:INFO:create_model() successfully completed......................................
2023-11-16 10:07:39,932:INFO:SubProcess create_model() end ==================================
2023-11-16 10:07:39,932:INFO:Creating metrics dataframe
2023-11-16 10:07:39,935:INFO:Initializing create_model()
2023-11-16 10:07:39,935:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff82fda1f0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:07:39,935:INFO:Checking exceptions
2023-11-16 10:07:39,936:INFO:Importing libraries
2023-11-16 10:07:39,936:INFO:Copying training dataset
2023-11-16 10:07:39,937:INFO:Defining folds
2023-11-16 10:07:39,937:INFO:Declaring metric variables
2023-11-16 10:07:39,937:INFO:Importing untrained model
2023-11-16 10:07:39,938:INFO:Declaring custom model
2023-11-16 10:07:39,938:INFO:K Neighbors Classifier Imported successfully
2023-11-16 10:07:39,938:INFO:Cross validation set to False
2023-11-16 10:07:39,938:INFO:Fitting Model
2023-11-16 10:07:39,942:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 10:07:39,942:INFO:create_model() successfully completed......................................
2023-11-16 10:07:39,973:INFO:_master_model_container: 9
2023-11-16 10:07:39,973:INFO:_display_container: 2
2023-11-16 10:07:39,973:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 10:07:39,973:INFO:compare_models() successfully completed......................................
2023-11-16 10:40:38,459:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:40:38,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:40:38,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:40:38,460:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:30,256:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:30,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:30,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:30,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,695:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,696:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,937:INFO:PyCaret ClassificationExperiment
2023-11-16 10:43:48,937:INFO:Logging name: clf-default-name
2023-11-16 10:43:48,937:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-16 10:43:48,938:INFO:version 3.2.0
2023-11-16 10:43:48,938:INFO:Initializing setup()
2023-11-16 10:43:48,938:INFO:self.USI: e4c3
2023-11-16 10:43:48,938:INFO:self._variable_keys: {'USI', 'y', 'fold_shuffle_param', 'memory', 'exp_name_log', 'gpu_param', 'X_test', 'target_param', 'fold_generator', 'exp_id', 'fold_groups_param', 'idx', '_ml_usecase', '_available_plots', 'seed', 'data', 'y_test', 'fix_imbalance', 'y_train', 'X_train', 'is_multiclass', 'X', 'log_plots_param', 'html_param', 'pipeline', 'n_jobs_param', 'gpu_n_jobs_param', 'logging_param'}
2023-11-16 10:43:48,938:INFO:Checking environment
2023-11-16 10:43:48,938:INFO:python_version: 3.8.18
2023-11-16 10:43:48,938:INFO:python_build: ('default', 'Nov  1 2023 11:08:38')
2023-11-16 10:43:48,939:INFO:machine: aarch64
2023-11-16 10:43:48,939:INFO:platform: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-16 10:43:48,940:INFO:Memory: svmem(total=8225300480, available=7157551104, percent=13.0, used=858771456, free=3675680768, active=1983275008, inactive=2022416384, buffers=106815488, cached=3584032768, shared=1400832, slab=367796224)
2023-11-16 10:43:48,941:INFO:Physical Core: 12
2023-11-16 10:43:48,941:INFO:Logical Core: 12
2023-11-16 10:43:48,942:INFO:Checking libraries
2023-11-16 10:43:48,942:INFO:System:
2023-11-16 10:43:48,942:INFO:    python: 3.8.18 (default, Nov  1 2023, 11:08:38)  [GCC 12.2.0]
2023-11-16 10:43:48,942:INFO:executable: /usr/local/bin/python
2023-11-16 10:43:48,942:INFO:   machine: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-16 10:43:48,942:INFO:PyCaret required dependencies:
2023-11-16 10:43:48,952:INFO:                 pip: 23.3.1
2023-11-16 10:43:48,952:INFO:          setuptools: 57.5.0
2023-11-16 10:43:48,952:INFO:             pycaret: 3.2.0
2023-11-16 10:43:48,952:INFO:             IPython: 8.12.3
2023-11-16 10:43:48,952:INFO:          ipywidgets: 8.1.1
2023-11-16 10:43:48,953:INFO:                tqdm: 4.66.1
2023-11-16 10:43:48,953:INFO:               numpy: 1.24.4
2023-11-16 10:43:48,953:INFO:              pandas: 1.5.3
2023-11-16 10:43:48,953:INFO:              jinja2: 3.1.2
2023-11-16 10:43:48,953:INFO:               scipy: 1.10.1
2023-11-16 10:43:48,953:INFO:              joblib: 1.3.2
2023-11-16 10:43:48,953:INFO:             sklearn: 1.2.2
2023-11-16 10:43:48,953:INFO:                pyod: 1.1.1
2023-11-16 10:43:48,953:INFO:            imblearn: 0.11.0
2023-11-16 10:43:48,953:INFO:   category_encoders: 2.6.3
2023-11-16 10:43:48,954:INFO:            lightgbm: 4.1.0
2023-11-16 10:43:48,954:INFO:               numba: 0.58.1
2023-11-16 10:43:48,954:INFO:            requests: 2.31.0
2023-11-16 10:43:48,954:INFO:          matplotlib: 3.6.0
2023-11-16 10:43:48,954:INFO:          scikitplot: 0.3.7
2023-11-16 10:43:48,954:INFO:         yellowbrick: 1.5
2023-11-16 10:43:48,954:INFO:              plotly: 5.18.0
2023-11-16 10:43:48,954:INFO:    plotly-resampler: Not installed
2023-11-16 10:43:48,954:INFO:             kaleido: 0.2.1
2023-11-16 10:43:48,955:INFO:           schemdraw: 0.15
2023-11-16 10:43:48,955:INFO:         statsmodels: 0.14.0
2023-11-16 10:43:48,955:INFO:              sktime: 0.21.1
2023-11-16 10:43:48,955:INFO:               tbats: 1.1.3
2023-11-16 10:43:48,955:INFO:            pmdarima: 2.0.4
2023-11-16 10:43:48,955:INFO:              psutil: 5.9.6
2023-11-16 10:43:48,955:INFO:          markupsafe: 2.1.3
2023-11-16 10:43:48,955:INFO:             pickle5: Not installed
2023-11-16 10:43:48,955:INFO:         cloudpickle: 3.0.0
2023-11-16 10:43:48,955:INFO:         deprecation: 2.1.0
2023-11-16 10:43:48,956:INFO:              xxhash: 3.4.1
2023-11-16 10:43:48,956:INFO:           wurlitzer: 3.0.3
2023-11-16 10:43:48,956:INFO:PyCaret optional dependencies:
2023-11-16 10:43:48,966:INFO:                shap: Not installed
2023-11-16 10:43:48,966:INFO:           interpret: Not installed
2023-11-16 10:43:48,966:INFO:                umap: Not installed
2023-11-16 10:43:48,966:INFO:     ydata_profiling: Not installed
2023-11-16 10:43:48,966:INFO:  explainerdashboard: Not installed
2023-11-16 10:43:48,966:INFO:             autoviz: Not installed
2023-11-16 10:43:48,966:INFO:           fairlearn: Not installed
2023-11-16 10:43:48,966:INFO:          deepchecks: Not installed
2023-11-16 10:43:48,966:INFO:             xgboost: Not installed
2023-11-16 10:43:48,967:INFO:            catboost: Not installed
2023-11-16 10:43:48,967:INFO:              kmodes: Not installed
2023-11-16 10:43:48,967:INFO:             mlxtend: Not installed
2023-11-16 10:43:48,967:INFO:       statsforecast: Not installed
2023-11-16 10:43:48,967:INFO:        tune_sklearn: Not installed
2023-11-16 10:43:48,967:INFO:                 ray: Not installed
2023-11-16 10:43:48,967:INFO:            hyperopt: Not installed
2023-11-16 10:43:48,967:INFO:              optuna: Not installed
2023-11-16 10:43:48,967:INFO:               skopt: Not installed
2023-11-16 10:43:48,967:INFO:              mlflow: Not installed
2023-11-16 10:43:48,968:INFO:              gradio: Not installed
2023-11-16 10:43:48,968:INFO:             fastapi: Not installed
2023-11-16 10:43:48,968:INFO:             uvicorn: Not installed
2023-11-16 10:43:48,968:INFO:              m2cgen: Not installed
2023-11-16 10:43:48,968:INFO:           evidently: Not installed
2023-11-16 10:43:48,968:INFO:               fugue: Not installed
2023-11-16 10:43:48,968:INFO:           streamlit: Not installed
2023-11-16 10:43:48,968:INFO:             prophet: Not installed
2023-11-16 10:43:48,968:INFO:None
2023-11-16 10:43:48,968:INFO:Set up GPU usage.
2023-11-16 10:43:48,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,969:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-16 10:43:48,969:INFO:Set up data.
2023-11-16 10:43:48,972:INFO:Set up folding strategy.
2023-11-16 10:43:48,972:INFO:Set up train/test split.
2023-11-16 10:43:48,974:INFO:Set up index.
2023-11-16 10:43:48,974:INFO:Assigning column types.
2023-11-16 10:43:48,975:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-16 10:43:48,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-16 10:43:48,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:48,993:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 10:43:48,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-16 10:43:49,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,045:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 10:43:49,045:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,056:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,056:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,061:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-16 10:43:49,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,080:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 10:43:49,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,089:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,113:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,113:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,114:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-16 10:43:49,114:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,122:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,124:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,130:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-16 10:43:49,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,157:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,159:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,164:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,164:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,182:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,182:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,182:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,191:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,193:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,193:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,198:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,199:INFO:Preparing preprocessing pipeline...
2023-11-16 10:43:49,200:INFO:Set up simple imputation.
2023-11-16 10:43:49,209:INFO:Finished creating preprocessing pipeline.
2023-11-16 10:43:49,211:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-16 10:43:49,211:INFO:Creating final display dataframe.
2023-11-16 10:43:49,234:INFO:Setup _display_container:                     Description             Value
0                    Session id               492
1                        Target            target
2                   Target type        Multiclass
3           Original data shape         (106, 13)
4        Transformed data shape         (106, 13)
5   Transformed train set shape          (74, 13)
6    Transformed test set shape          (32, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              e4c3
2023-11-16 10:43:49,236:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,255:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,265:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,267:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,271:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,300:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-16 10:43:49,300:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,303:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-16 10:43:49,304:INFO:setup() successfully completed in 0.37s...............
2023-11-16 10:43:49,304:INFO:Initializing compare_models()
2023-11-16 10:43:49,304:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-16 10:43:49,305:INFO:Checking exceptions
2023-11-16 10:43:49,306:INFO:Preparing display monitor
2023-11-16 10:43:49,308:INFO:Initializing Logistic Regression
2023-11-16 10:43:49,308:INFO:Total runtime is 2.745787302652995e-06 minutes
2023-11-16 10:43:49,308:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,308:INFO:Initializing create_model()
2023-11-16 10:43:49,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,309:INFO:Checking exceptions
2023-11-16 10:43:49,309:INFO:Importing libraries
2023-11-16 10:43:49,309:INFO:Copying training dataset
2023-11-16 10:43:49,310:INFO:Defining folds
2023-11-16 10:43:49,310:INFO:Declaring metric variables
2023-11-16 10:43:49,310:INFO:Importing untrained model
2023-11-16 10:43:49,311:INFO:Logistic Regression Imported successfully
2023-11-16 10:43:49,311:INFO:Starting cross validation
2023-11-16 10:43:49,311:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,327:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 10:43:49,327:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2023-11-16 10:43:49,327:INFO:Initializing create_model()
2023-11-16 10:43:49,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,328:INFO:Checking exceptions
2023-11-16 10:43:49,328:INFO:Importing libraries
2023-11-16 10:43:49,328:INFO:Copying training dataset
2023-11-16 10:43:49,329:INFO:Defining folds
2023-11-16 10:43:49,329:INFO:Declaring metric variables
2023-11-16 10:43:49,329:INFO:Importing untrained model
2023-11-16 10:43:49,329:INFO:Logistic Regression Imported successfully
2023-11-16 10:43:49,330:INFO:Starting cross validation
2023-11-16 10:43:49,330:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,344:ERROR:create_model() for lr raised an exception or returned all 0.0:
2023-11-16 10:43:49,345:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py", line 1241, in fit
    raise ValueError(
ValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0


2023-11-16 10:43:49,345:INFO:Initializing K Neighbors Classifier
2023-11-16 10:43:49,345:INFO:Total runtime is 0.0006144245465596517 minutes
2023-11-16 10:43:49,345:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,345:INFO:Initializing create_model()
2023-11-16 10:43:49,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,345:INFO:Checking exceptions
2023-11-16 10:43:49,345:INFO:Importing libraries
2023-11-16 10:43:49,346:INFO:Copying training dataset
2023-11-16 10:43:49,347:INFO:Defining folds
2023-11-16 10:43:49,347:INFO:Declaring metric variables
2023-11-16 10:43:49,347:INFO:Importing untrained model
2023-11-16 10:43:49,347:INFO:K Neighbors Classifier Imported successfully
2023-11-16 10:43:49,347:INFO:Starting cross validation
2023-11-16 10:43:49,348:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,384:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,385:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,386:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,387:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,388:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,420:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,421:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,422:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,423:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,423:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,457:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,458:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,459:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,460:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,460:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,493:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,494:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,495:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,496:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,496:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,528:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,529:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,530:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,531:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,531:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,532:INFO:Calculating mean and std
2023-11-16 10:43:49,533:INFO:Creating metrics dataframe
2023-11-16 10:43:49,534:INFO:Uploading results into container
2023-11-16 10:43:49,535:INFO:Uploading model into container now
2023-11-16 10:43:49,535:INFO:_master_model_container: 1
2023-11-16 10:43:49,535:INFO:_display_container: 2
2023-11-16 10:43:49,535:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 10:43:49,536:INFO:create_model() successfully completed......................................
2023-11-16 10:43:49,581:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:49,581:INFO:Creating metrics dataframe
2023-11-16 10:43:49,583:INFO:Initializing Naive Bayes
2023-11-16 10:43:49,584:INFO:Total runtime is 0.004594496885935466 minutes
2023-11-16 10:43:49,584:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,584:INFO:Initializing create_model()
2023-11-16 10:43:49,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,585:INFO:Checking exceptions
2023-11-16 10:43:49,585:INFO:Importing libraries
2023-11-16 10:43:49,585:INFO:Copying training dataset
2023-11-16 10:43:49,586:INFO:Defining folds
2023-11-16 10:43:49,586:INFO:Declaring metric variables
2023-11-16 10:43:49,587:INFO:Importing untrained model
2023-11-16 10:43:49,587:INFO:Naive Bayes Imported successfully
2023-11-16 10:43:49,587:INFO:Starting cross validation
2023-11-16 10:43:49,587:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,594:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,594:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,595:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,596:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,596:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,601:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,602:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,603:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,603:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,604:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,609:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,609:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,610:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,611:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,611:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,616:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,617:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,617:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,618:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,618:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,623:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,624:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,625:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,625:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,626:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,627:INFO:Calculating mean and std
2023-11-16 10:43:49,627:INFO:Creating metrics dataframe
2023-11-16 10:43:49,628:INFO:Uploading results into container
2023-11-16 10:43:49,628:INFO:Uploading model into container now
2023-11-16 10:43:49,629:INFO:_master_model_container: 2
2023-11-16 10:43:49,629:INFO:_display_container: 2
2023-11-16 10:43:49,629:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-16 10:43:49,629:INFO:create_model() successfully completed......................................
2023-11-16 10:43:49,659:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:49,659:INFO:Creating metrics dataframe
2023-11-16 10:43:49,661:INFO:Initializing Decision Tree Classifier
2023-11-16 10:43:49,661:INFO:Total runtime is 0.005887170632680258 minutes
2023-11-16 10:43:49,661:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,662:INFO:Initializing create_model()
2023-11-16 10:43:49,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,662:INFO:Checking exceptions
2023-11-16 10:43:49,662:INFO:Importing libraries
2023-11-16 10:43:49,662:INFO:Copying training dataset
2023-11-16 10:43:49,663:INFO:Defining folds
2023-11-16 10:43:49,664:INFO:Declaring metric variables
2023-11-16 10:43:49,664:INFO:Importing untrained model
2023-11-16 10:43:49,664:INFO:Decision Tree Classifier Imported successfully
2023-11-16 10:43:49,664:INFO:Starting cross validation
2023-11-16 10:43:49,665:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,671:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,672:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,672:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,673:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,674:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,679:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,679:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,680:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,681:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,681:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,686:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,687:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,688:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,688:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,689:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,694:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,694:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,695:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,696:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,696:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,701:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,702:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,702:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,703:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,704:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,704:INFO:Calculating mean and std
2023-11-16 10:43:49,705:INFO:Creating metrics dataframe
2023-11-16 10:43:49,706:INFO:Uploading results into container
2023-11-16 10:43:49,706:INFO:Uploading model into container now
2023-11-16 10:43:49,706:INFO:_master_model_container: 3
2023-11-16 10:43:49,706:INFO:_display_container: 2
2023-11-16 10:43:49,707:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=492, splitter='best')
2023-11-16 10:43:49,707:INFO:create_model() successfully completed......................................
2023-11-16 10:43:49,735:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:49,735:INFO:Creating metrics dataframe
2023-11-16 10:43:49,737:INFO:Initializing SVM - Linear Kernel
2023-11-16 10:43:49,737:INFO:Total runtime is 0.007153471310933432 minutes
2023-11-16 10:43:49,737:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,738:INFO:Initializing create_model()
2023-11-16 10:43:49,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,738:INFO:Checking exceptions
2023-11-16 10:43:49,738:INFO:Importing libraries
2023-11-16 10:43:49,738:INFO:Copying training dataset
2023-11-16 10:43:49,739:INFO:Defining folds
2023-11-16 10:43:49,739:INFO:Declaring metric variables
2023-11-16 10:43:49,739:INFO:Importing untrained model
2023-11-16 10:43:49,740:INFO:SVM - Linear Kernel Imported successfully
2023-11-16 10:43:49,740:INFO:Starting cross validation
2023-11-16 10:43:49,740:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,754:WARNING:create_model() for svm raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 10:43:49,755:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 10:43:49,755:INFO:Initializing create_model()
2023-11-16 10:43:49,755:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,755:INFO:Checking exceptions
2023-11-16 10:43:49,755:INFO:Importing libraries
2023-11-16 10:43:49,755:INFO:Copying training dataset
2023-11-16 10:43:49,756:INFO:Defining folds
2023-11-16 10:43:49,756:INFO:Declaring metric variables
2023-11-16 10:43:49,757:INFO:Importing untrained model
2023-11-16 10:43:49,757:INFO:SVM - Linear Kernel Imported successfully
2023-11-16 10:43:49,757:INFO:Starting cross validation
2023-11-16 10:43:49,757:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,772:ERROR:create_model() for svm raised an exception or returned all 0.0:
2023-11-16 10:43:49,772:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 894, in fit
    return self._fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 683, in _fit
    self._partial_fit(
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 637, in _partial_fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 10:43:49,772:INFO:Initializing Ridge Classifier
2023-11-16 10:43:49,772:INFO:Total runtime is 0.007738610108693441 minutes
2023-11-16 10:43:49,772:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,773:INFO:Initializing create_model()
2023-11-16 10:43:49,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,773:INFO:Checking exceptions
2023-11-16 10:43:49,773:INFO:Importing libraries
2023-11-16 10:43:49,773:INFO:Copying training dataset
2023-11-16 10:43:49,774:INFO:Defining folds
2023-11-16 10:43:49,774:INFO:Declaring metric variables
2023-11-16 10:43:49,775:INFO:Importing untrained model
2023-11-16 10:43:49,775:INFO:Ridge Classifier Imported successfully
2023-11-16 10:43:49,775:INFO:Starting cross validation
2023-11-16 10:43:49,775:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,782:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:43:49,783:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,784:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,785:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,785:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,790:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:43:49,791:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,792:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,792:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,793:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,798:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:43:49,798:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,799:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,800:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,800:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,805:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:43:49,806:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,807:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,807:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,808:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,812:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-16 10:43:49,813:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,814:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,815:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,815:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,816:INFO:Calculating mean and std
2023-11-16 10:43:49,816:INFO:Creating metrics dataframe
2023-11-16 10:43:49,817:INFO:Uploading results into container
2023-11-16 10:43:49,818:INFO:Uploading model into container now
2023-11-16 10:43:49,818:INFO:_master_model_container: 4
2023-11-16 10:43:49,818:INFO:_display_container: 2
2023-11-16 10:43:49,818:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=492, solver='auto',
                tol=0.0001)
2023-11-16 10:43:49,818:INFO:create_model() successfully completed......................................
2023-11-16 10:43:49,846:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:49,846:INFO:Creating metrics dataframe
2023-11-16 10:43:49,848:INFO:Initializing Quadratic Discriminant Analysis
2023-11-16 10:43:49,848:INFO:Total runtime is 0.009008022149403891 minutes
2023-11-16 10:43:49,849:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,849:INFO:Initializing create_model()
2023-11-16 10:43:49,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,849:INFO:Checking exceptions
2023-11-16 10:43:49,849:INFO:Importing libraries
2023-11-16 10:43:49,849:INFO:Copying training dataset
2023-11-16 10:43:49,850:INFO:Defining folds
2023-11-16 10:43:49,850:INFO:Declaring metric variables
2023-11-16 10:43:49,851:INFO:Importing untrained model
2023-11-16 10:43:49,851:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-16 10:43:49,851:INFO:Starting cross validation
2023-11-16 10:43:49,851:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,864:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2023-11-16 10:43:49,865:WARNING:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 10:43:49,865:INFO:Initializing create_model()
2023-11-16 10:43:49,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,865:INFO:Checking exceptions
2023-11-16 10:43:49,865:INFO:Importing libraries
2023-11-16 10:43:49,865:INFO:Copying training dataset
2023-11-16 10:43:49,866:INFO:Defining folds
2023-11-16 10:43:49,866:INFO:Declaring metric variables
2023-11-16 10:43:49,866:INFO:Importing untrained model
2023-11-16 10:43:49,867:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-16 10:43:49,867:INFO:Starting cross validation
2023-11-16 10:43:49,867:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,880:ERROR:create_model() for qda raised an exception or returned all 0.0:
2023-11-16 10:43:49,880:ERROR:Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 5 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 896, in fit
    raise ValueError(
ValueError: The number of classes has to be greater than one; got 1 class


2023-11-16 10:43:49,880:INFO:Initializing Ada Boost Classifier
2023-11-16 10:43:49,880:INFO:Total runtime is 0.009540192286173504 minutes
2023-11-16 10:43:49,881:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,881:INFO:Initializing create_model()
2023-11-16 10:43:49,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,881:INFO:Checking exceptions
2023-11-16 10:43:49,881:INFO:Importing libraries
2023-11-16 10:43:49,881:INFO:Copying training dataset
2023-11-16 10:43:49,882:INFO:Defining folds
2023-11-16 10:43:49,882:INFO:Declaring metric variables
2023-11-16 10:43:49,883:INFO:Importing untrained model
2023-11-16 10:43:49,883:INFO:Ada Boost Classifier Imported successfully
2023-11-16 10:43:49,883:INFO:Starting cross validation
2023-11-16 10:43:49,883:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,889:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,890:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,890:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,891:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,892:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,897:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,898:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,898:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,899:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,900:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,905:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,906:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,906:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,907:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,908:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,913:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,913:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,914:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,915:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,915:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,920:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:49,921:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,922:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,922:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,923:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,923:INFO:Calculating mean and std
2023-11-16 10:43:49,924:INFO:Creating metrics dataframe
2023-11-16 10:43:49,925:INFO:Uploading results into container
2023-11-16 10:43:49,925:INFO:Uploading model into container now
2023-11-16 10:43:49,925:INFO:_master_model_container: 5
2023-11-16 10:43:49,926:INFO:_display_container: 2
2023-11-16 10:43:49,926:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=492)
2023-11-16 10:43:49,926:INFO:create_model() successfully completed......................................
2023-11-16 10:43:49,954:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:49,954:INFO:Creating metrics dataframe
2023-11-16 10:43:49,956:INFO:Initializing Linear Discriminant Analysis
2023-11-16 10:43:49,956:INFO:Total runtime is 0.010806103547414146 minutes
2023-11-16 10:43:49,956:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:49,957:INFO:Initializing create_model()
2023-11-16 10:43:49,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:49,957:INFO:Checking exceptions
2023-11-16 10:43:49,957:INFO:Importing libraries
2023-11-16 10:43:49,957:INFO:Copying training dataset
2023-11-16 10:43:49,958:INFO:Defining folds
2023-11-16 10:43:49,958:INFO:Declaring metric variables
2023-11-16 10:43:49,958:INFO:Importing untrained model
2023-11-16 10:43:49,959:INFO:Linear Discriminant Analysis Imported successfully
2023-11-16 10:43:49,959:INFO:Starting cross validation
2023-11-16 10:43:49,959:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:49,966:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:43:49,967:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,967:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,968:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,968:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,973:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:43:49,974:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,975:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,976:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,976:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,981:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:43:49,982:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,982:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,983:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,983:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,988:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:43:49,989:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,990:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,991:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,991:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,996:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 336, in predict_proba
    return self.steps[-1][-1].predict_proba(X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 697, in predict_proba
    return softmax(decision)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/extmath.py", line 886, in softmax
    max_prob = xp.reshape(xp.max(X, axis=1), (-1, 1))
  File "<__array_function__ internals>", line 200, in amax
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 2820, in amax
    return _wrapreduction(a, np.maximum, 'max', axis, None, out,
  File "/usr/local/lib/python3.8/site-packages/numpy/core/fromnumeric.py", line 86, in _wrapreduction
    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
numpy.AxisError: axis 1 is out of bounds for array of dimension 1

  warnings.warn(

2023-11-16 10:43:49,996:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,997:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:49,998:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:49,998:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:49,999:INFO:Calculating mean and std
2023-11-16 10:43:49,999:INFO:Creating metrics dataframe
2023-11-16 10:43:50,001:INFO:Uploading results into container
2023-11-16 10:43:50,001:INFO:Uploading model into container now
2023-11-16 10:43:50,001:INFO:_master_model_container: 6
2023-11-16 10:43:50,001:INFO:_display_container: 2
2023-11-16 10:43:50,001:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-16 10:43:50,002:INFO:create_model() successfully completed......................................
2023-11-16 10:43:50,029:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:50,030:INFO:Creating metrics dataframe
2023-11-16 10:43:50,032:INFO:Initializing Extra Trees Classifier
2023-11-16 10:43:50,032:INFO:Total runtime is 0.012063606580098472 minutes
2023-11-16 10:43:50,032:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:50,032:INFO:Initializing create_model()
2023-11-16 10:43:50,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:50,032:INFO:Checking exceptions
2023-11-16 10:43:50,033:INFO:Importing libraries
2023-11-16 10:43:50,033:INFO:Copying training dataset
2023-11-16 10:43:50,034:INFO:Defining folds
2023-11-16 10:43:50,034:INFO:Declaring metric variables
2023-11-16 10:43:50,034:INFO:Importing untrained model
2023-11-16 10:43:50,034:INFO:Extra Trees Classifier Imported successfully
2023-11-16 10:43:50,035:INFO:Starting cross validation
2023-11-16 10:43:50,035:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:50,137:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,138:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,138:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,139:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,140:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,239:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,240:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,241:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,242:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,242:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,345:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,346:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,347:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,347:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,348:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,448:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,449:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,450:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,451:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,451:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,540:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,541:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,542:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,543:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,544:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,544:INFO:Calculating mean and std
2023-11-16 10:43:50,545:INFO:Creating metrics dataframe
2023-11-16 10:43:50,546:INFO:Uploading results into container
2023-11-16 10:43:50,547:INFO:Uploading model into container now
2023-11-16 10:43:50,547:INFO:_master_model_container: 7
2023-11-16 10:43:50,547:INFO:_display_container: 2
2023-11-16 10:43:50,547:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=492, verbose=0, warm_start=False)
2023-11-16 10:43:50,547:INFO:create_model() successfully completed......................................
2023-11-16 10:43:50,577:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:50,577:INFO:Creating metrics dataframe
2023-11-16 10:43:50,580:INFO:Initializing Light Gradient Boosting Machine
2023-11-16 10:43:50,580:INFO:Total runtime is 0.021197013060251874 minutes
2023-11-16 10:43:50,580:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:50,580:INFO:Initializing create_model()
2023-11-16 10:43:50,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:50,580:INFO:Checking exceptions
2023-11-16 10:43:50,581:INFO:Importing libraries
2023-11-16 10:43:50,581:INFO:Copying training dataset
2023-11-16 10:43:50,582:INFO:Defining folds
2023-11-16 10:43:50,582:INFO:Declaring metric variables
2023-11-16 10:43:50,582:INFO:Importing untrained model
2023-11-16 10:43:50,582:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-16 10:43:50,583:INFO:Starting cross validation
2023-11-16 10:43:50,583:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:50,588:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:43:50,588:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 59
2023-11-16 10:43:50,589:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000077 seconds.
2023-11-16 10:43:50,589:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:43:50,589:INFO:[LightGBM] [Info] Total Bins 255
2023-11-16 10:43:50,590:INFO:[LightGBM] [Info] Number of data points in the train set: 59, number of used features: 12
2023-11-16 10:43:50,590:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:43:50,590:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:43:50,590:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,590:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,591:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,592:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,593:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,594:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,595:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,596:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,597:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,598:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,599:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,601:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,601:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,601:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,601:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,601:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,605:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:43:50,606:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,606:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,607:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,608:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,611:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:43:50,611:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 59
2023-11-16 10:43:50,612:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000032 seconds.
2023-11-16 10:43:50,612:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:43:50,612:INFO:[LightGBM] [Info] Total Bins 254
2023-11-16 10:43:50,612:INFO:[LightGBM] [Info] Number of data points in the train set: 59, number of used features: 12
2023-11-16 10:43:50,612:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:43:50,613:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:43:50,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,613:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,614:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,616:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,617:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,618:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,619:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,621:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,623:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,627:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:43:50,628:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,628:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,629:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,630:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,634:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:43:50,634:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 59
2023-11-16 10:43:50,637:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002065 seconds.
2023-11-16 10:43:50,637:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:43:50,637:INFO:[LightGBM] [Info] Total Bins 256
2023-11-16 10:43:50,638:INFO:[LightGBM] [Info] Number of data points in the train set: 59, number of used features: 12
2023-11-16 10:43:50,638:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:43:50,638:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:43:50,638:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,638:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,639:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,640:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,641:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,642:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,645:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,646:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,648:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,649:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,649:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,652:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:43:50,653:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,654:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,654:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,655:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,659:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:43:50,659:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 59
2023-11-16 10:43:50,662:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001661 seconds.
2023-11-16 10:43:50,662:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:43:50,662:INFO:[LightGBM] [Info] Total Bins 254
2023-11-16 10:43:50,662:INFO:[LightGBM] [Info] Number of data points in the train set: 59, number of used features: 12
2023-11-16 10:43:50,663:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:43:50,663:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:43:50,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,665:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,667:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,668:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,672:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,674:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,678:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:43:50,678:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,679:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,680:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,680:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,685:INFO:[LightGBM] [Warning] Contains only one class
2023-11-16 10:43:50,685:INFO:[LightGBM] [Info] Number of positive: 0, number of negative: 60
2023-11-16 10:43:50,685:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000031 seconds.
2023-11-16 10:43:50,685:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-16 10:43:50,685:INFO:[LightGBM] [Info] Total Bins 259
2023-11-16 10:43:50,686:INFO:[LightGBM] [Info] Number of data points in the train set: 60, number of used features: 12
2023-11-16 10:43:50,686:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000000 -> initscore=-34.538776
2023-11-16 10:43:50,686:INFO:[LightGBM] [Info] Start training from score -34.538776
2023-11-16 10:43:50,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,687:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,689:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,695:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,696:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-11-16 10:43:50,700:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 188, in _select_proba_binary
    pos_label = self._kwargs.get("pos_label", classes[1])
IndexError: index 1 is out of bounds for axis 0 with size 1

  warnings.warn(

2023-11-16 10:43:50,701:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,702:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,703:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,703:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,704:INFO:Calculating mean and std
2023-11-16 10:43:50,704:INFO:Creating metrics dataframe
2023-11-16 10:43:50,706:INFO:Uploading results into container
2023-11-16 10:43:50,706:INFO:Uploading model into container now
2023-11-16 10:43:50,706:INFO:_master_model_container: 8
2023-11-16 10:43:50,706:INFO:_display_container: 2
2023-11-16 10:43:50,707:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=492, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-16 10:43:50,707:INFO:create_model() successfully completed......................................
2023-11-16 10:43:50,736:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:50,736:INFO:Creating metrics dataframe
2023-11-16 10:43:50,738:INFO:Initializing Dummy Classifier
2023-11-16 10:43:50,738:INFO:Total runtime is 0.02384070952733358 minutes
2023-11-16 10:43:50,739:INFO:SubProcess create_model() called ==================================
2023-11-16 10:43:50,739:INFO:Initializing create_model()
2023-11-16 10:43:50,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff40025820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:50,739:INFO:Checking exceptions
2023-11-16 10:43:50,739:INFO:Importing libraries
2023-11-16 10:43:50,739:INFO:Copying training dataset
2023-11-16 10:43:50,741:INFO:Defining folds
2023-11-16 10:43:50,741:INFO:Declaring metric variables
2023-11-16 10:43:50,741:INFO:Importing untrained model
2023-11-16 10:43:50,741:INFO:Dummy Classifier Imported successfully
2023-11-16 10:43:50,741:INFO:Starting cross validation
2023-11-16 10:43:50,742:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-16 10:43:50,746:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,747:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,748:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,749:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,749:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,753:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,754:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,755:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,756:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,756:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,760:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,761:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,762:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,762:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,763:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,767:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (15, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,767:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,768:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,769:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,769:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,773:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 321, in _score
    y_pred = self._select_proba_binary(y_pred, clf.classes_)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 198, in _select_proba_binary
    raise ValueError(err_msg)
ValueError: Got predict_proba of shape (14, 1), but need classifier with two classes for roc_auc_score scoring

  warnings.warn(

2023-11-16 10:43:50,774:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,775:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-16 10:43:50,776:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, "true nor predicted", "F-score is", len(true_sum))

2023-11-16 10:43:50,776:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:673: RuntimeWarning: invalid value encountered in scalar divide
  k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)

2023-11-16 10:43:50,777:INFO:Calculating mean and std
2023-11-16 10:43:50,777:INFO:Creating metrics dataframe
2023-11-16 10:43:50,778:INFO:Uploading results into container
2023-11-16 10:43:50,779:INFO:Uploading model into container now
2023-11-16 10:43:50,779:INFO:_master_model_container: 9
2023-11-16 10:43:50,779:INFO:_display_container: 2
2023-11-16 10:43:50,779:INFO:DummyClassifier(constant=None, random_state=492, strategy='prior')
2023-11-16 10:43:50,779:INFO:create_model() successfully completed......................................
2023-11-16 10:43:50,807:INFO:SubProcess create_model() end ==================================
2023-11-16 10:43:50,807:INFO:Creating metrics dataframe
2023-11-16 10:43:50,810:INFO:Initializing create_model()
2023-11-16 10:43:50,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7d539e80>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-16 10:43:50,810:INFO:Checking exceptions
2023-11-16 10:43:50,811:INFO:Importing libraries
2023-11-16 10:43:50,811:INFO:Copying training dataset
2023-11-16 10:43:50,812:INFO:Defining folds
2023-11-16 10:43:50,812:INFO:Declaring metric variables
2023-11-16 10:43:50,812:INFO:Importing untrained model
2023-11-16 10:43:50,812:INFO:Declaring custom model
2023-11-16 10:43:50,812:INFO:K Neighbors Classifier Imported successfully
2023-11-16 10:43:50,813:INFO:Cross validation set to False
2023-11-16 10:43:50,813:INFO:Fitting Model
2023-11-16 10:43:50,816:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 10:43:50,816:INFO:create_model() successfully completed......................................
2023-11-16 10:43:50,845:INFO:_master_model_container: 9
2023-11-16 10:43:50,845:INFO:_display_container: 2
2023-11-16 10:43:50,846:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-16 10:43:50,846:INFO:compare_models() successfully completed......................................
2023-11-20 10:03:20,002:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,478:INFO:PyCaret ClassificationExperiment
2023-11-20 10:03:20,479:INFO:Logging name: clf-default-name
2023-11-20 10:03:20,480:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-20 10:03:20,480:INFO:version 3.2.0
2023-11-20 10:03:20,480:INFO:Initializing setup()
2023-11-20 10:03:20,481:INFO:self.USI: 3b33
2023-11-20 10:03:20,481:INFO:self._variable_keys: {'exp_id', 'exp_name_log', 'log_plots_param', 'y_train', 'y_test', 'y', 'target_param', 'data', 'X_test', 'USI', 'gpu_param', 'seed', 'memory', 'fold_generator', 'fix_imbalance', 'pipeline', 'is_multiclass', 'idx', 'X_train', 'html_param', 'fold_groups_param', '_available_plots', 'X', 'gpu_n_jobs_param', 'logging_param', 'fold_shuffle_param', '_ml_usecase', 'n_jobs_param'}
2023-11-20 10:03:20,481:INFO:Checking environment
2023-11-20 10:03:20,481:INFO:python_version: 3.8.18
2023-11-20 10:03:20,482:INFO:python_build: ('default', 'Nov  1 2023 14:38:12')
2023-11-20 10:03:20,482:INFO:machine: x86_64
2023-11-20 10:03:20,483:INFO:platform: Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.34
2023-11-20 10:03:20,484:INFO:Memory: svmem(total=8139022336, available=6680449024, percent=17.9, used=1145720832, free=1944166400, active=2636378112, inactive=2688188416, buffers=210386944, cached=4838748160, shared=5611520, slab=563097600)
2023-11-20 10:03:20,486:INFO:Physical Core: 4
2023-11-20 10:03:20,486:INFO:Logical Core: 8
2023-11-20 10:03:20,487:INFO:Checking libraries
2023-11-20 10:03:20,487:INFO:System:
2023-11-20 10:03:20,487:INFO:    python: 3.8.18 (default, Nov  1 2023, 14:38:12)  [GCC 12.2.0]
2023-11-20 10:03:20,488:INFO:executable: /usr/local/bin/python
2023-11-20 10:03:20,488:INFO:   machine: Linux-5.15.133.1-microsoft-standard-WSL2-x86_64-with-glibc2.34
2023-11-20 10:03:20,488:INFO:PyCaret required dependencies:
2023-11-20 10:03:20,506:INFO:                 pip: 23.0.1
2023-11-20 10:03:20,507:INFO:          setuptools: 57.5.0
2023-11-20 10:03:20,507:INFO:             pycaret: 3.2.0
2023-11-20 10:03:20,508:INFO:             IPython: 8.12.3
2023-11-20 10:03:20,508:INFO:          ipywidgets: 8.1.1
2023-11-20 10:03:20,509:INFO:                tqdm: 4.66.1
2023-11-20 10:03:20,509:INFO:               numpy: 1.24.4
2023-11-20 10:03:20,509:INFO:              pandas: 1.5.3
2023-11-20 10:03:20,510:INFO:              jinja2: 3.1.2
2023-11-20 10:03:20,510:INFO:               scipy: 1.10.1
2023-11-20 10:03:20,510:INFO:              joblib: 1.3.2
2023-11-20 10:03:20,511:INFO:             sklearn: 1.2.2
2023-11-20 10:03:20,511:INFO:                pyod: 1.1.2
2023-11-20 10:03:20,511:INFO:            imblearn: 0.11.0
2023-11-20 10:03:20,511:INFO:   category_encoders: 2.6.3
2023-11-20 10:03:20,511:INFO:            lightgbm: 4.1.0
2023-11-20 10:03:20,512:INFO:               numba: 0.58.1
2023-11-20 10:03:20,512:INFO:            requests: 2.31.0
2023-11-20 10:03:20,512:INFO:          matplotlib: 3.6.0
2023-11-20 10:03:20,512:INFO:          scikitplot: 0.3.7
2023-11-20 10:03:20,512:INFO:         yellowbrick: 1.5
2023-11-20 10:03:20,513:INFO:              plotly: 5.18.0
2023-11-20 10:03:20,513:INFO:    plotly-resampler: Not installed
2023-11-20 10:03:20,513:INFO:             kaleido: 0.2.1
2023-11-20 10:03:20,513:INFO:           schemdraw: 0.15
2023-11-20 10:03:20,513:INFO:         statsmodels: 0.14.0
2023-11-20 10:03:20,514:INFO:              sktime: 0.21.1
2023-11-20 10:03:20,514:INFO:               tbats: 1.1.3
2023-11-20 10:03:20,514:INFO:            pmdarima: 2.0.4
2023-11-20 10:03:20,514:INFO:              psutil: 5.9.6
2023-11-20 10:03:20,514:INFO:          markupsafe: 2.1.3
2023-11-20 10:03:20,514:INFO:             pickle5: Not installed
2023-11-20 10:03:20,515:INFO:         cloudpickle: 3.0.0
2023-11-20 10:03:20,515:INFO:         deprecation: 2.1.0
2023-11-20 10:03:20,515:INFO:              xxhash: 3.4.1
2023-11-20 10:03:20,515:INFO:           wurlitzer: 3.0.3
2023-11-20 10:03:20,515:INFO:PyCaret optional dependencies:
2023-11-20 10:03:20,539:INFO:                shap: Not installed
2023-11-20 10:03:20,539:INFO:           interpret: Not installed
2023-11-20 10:03:20,539:INFO:                umap: Not installed
2023-11-20 10:03:20,540:INFO:     ydata_profiling: Not installed
2023-11-20 10:03:20,540:INFO:  explainerdashboard: Not installed
2023-11-20 10:03:20,540:INFO:             autoviz: Not installed
2023-11-20 10:03:20,541:INFO:           fairlearn: Not installed
2023-11-20 10:03:20,541:INFO:          deepchecks: Not installed
2023-11-20 10:03:20,541:INFO:             xgboost: Not installed
2023-11-20 10:03:20,541:INFO:            catboost: Not installed
2023-11-20 10:03:20,542:INFO:              kmodes: Not installed
2023-11-20 10:03:20,542:INFO:             mlxtend: Not installed
2023-11-20 10:03:20,542:INFO:       statsforecast: Not installed
2023-11-20 10:03:20,542:INFO:        tune_sklearn: Not installed
2023-11-20 10:03:20,543:INFO:                 ray: Not installed
2023-11-20 10:03:20,543:INFO:            hyperopt: Not installed
2023-11-20 10:03:20,543:INFO:              optuna: Not installed
2023-11-20 10:03:20,543:INFO:               skopt: Not installed
2023-11-20 10:03:20,543:INFO:              mlflow: Not installed
2023-11-20 10:03:20,544:INFO:              gradio: Not installed
2023-11-20 10:03:20,544:INFO:             fastapi: Not installed
2023-11-20 10:03:20,544:INFO:             uvicorn: Not installed
2023-11-20 10:03:20,544:INFO:              m2cgen: Not installed
2023-11-20 10:03:20,544:INFO:           evidently: Not installed
2023-11-20 10:03:20,545:INFO:               fugue: Not installed
2023-11-20 10:03:20,545:INFO:           streamlit: Not installed
2023-11-20 10:03:20,545:INFO:             prophet: Not installed
2023-11-20 10:03:20,545:INFO:None
2023-11-20 10:03:20,545:INFO:Set up GPU usage.
2023-11-20 10:03:20,546:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,546:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-20 10:03:20,546:INFO:Set up data.
2023-11-20 10:03:20,552:INFO:Set up folding strategy.
2023-11-20 10:03:20,553:INFO:Set up train/test split.
2023-11-20 10:03:20,556:INFO:Set up index.
2023-11-20 10:03:20,556:INFO:Assigning column types.
2023-11-20 10:03:20,559:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-20 10:03:20,559:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,591:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-20 10:03:20,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,594:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,595:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-20 10:03:20,596:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,612:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,616:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,670:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-20 10:03:20,671:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,671:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,673:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-20 10:03:20,673:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,695:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,701:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,702:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-20 10:03:20,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,738:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-20 10:03:20,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,755:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,758:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,760:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,766:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,800:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,802:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-20 10:03:20,803:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,823:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,831:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-20 10:03:20,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,862:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,881:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,882:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,888:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,939:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,943:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:20,945:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:20,953:INFO:Preparing preprocessing pipeline...
2023-11-20 10:03:20,955:INFO:Set up simple imputation.
2023-11-20 10:03:20,972:INFO:Finished creating preprocessing pipeline.
2023-11-20 10:03:20,977:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-20 10:03:20,982:INFO:Creating final display dataframe.
2023-11-20 10:03:21,030:INFO:Setup _display_container:                     Description             Value
0                    Session id              1549
1                        Target            target
2                   Target type            Binary
3           Original data shape         (210, 13)
4        Transformed data shape         (210, 13)
5   Transformed train set shape         (147, 13)
6    Transformed test set shape          (63, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3b33
2023-11-20 10:03:21,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,065:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,067:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,087:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:21,094:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:21,095:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,127:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,128:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 10:03:21,153:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:21,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 10:03:21,159:INFO:setup() successfully completed in 0.69s...............
2023-11-20 10:03:21,160:INFO:Initializing compare_models()
2023-11-20 10:03:21,160:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-20 10:03:21,160:INFO:Checking exceptions
2023-11-20 10:03:21,163:INFO:Preparing display monitor
2023-11-20 10:03:21,166:INFO:Initializing Logistic Regression
2023-11-20 10:03:21,166:INFO:Total runtime is 4.712740580240885e-06 minutes
2023-11-20 10:03:21,167:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:21,167:INFO:Initializing create_model()
2023-11-20 10:03:21,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:21,168:INFO:Checking exceptions
2023-11-20 10:03:21,169:INFO:Importing libraries
2023-11-20 10:03:21,169:INFO:Copying training dataset
2023-11-20 10:03:21,172:INFO:Defining folds
2023-11-20 10:03:21,173:INFO:Declaring metric variables
2023-11-20 10:03:21,173:INFO:Importing untrained model
2023-11-20 10:03:21,174:INFO:Logistic Regression Imported successfully
2023-11-20 10:03:21,175:INFO:Starting cross validation
2023-11-20 10:03:21,176:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:21,309:INFO:Calculating mean and std
2023-11-20 10:03:21,311:INFO:Creating metrics dataframe
2023-11-20 10:03:21,316:INFO:Uploading results into container
2023-11-20 10:03:21,317:INFO:Uploading model into container now
2023-11-20 10:03:21,318:INFO:_master_model_container: 1
2023-11-20 10:03:21,318:INFO:_display_container: 2
2023-11-20 10:03:21,319:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1549, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-20 10:03:21,319:INFO:create_model() successfully completed......................................
2023-11-20 10:03:21,380:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:21,381:INFO:Creating metrics dataframe
2023-11-20 10:03:21,385:INFO:Initializing K Neighbors Classifier
2023-11-20 10:03:21,386:INFO:Total runtime is 0.0036659797032674154 minutes
2023-11-20 10:03:21,387:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:21,387:INFO:Initializing create_model()
2023-11-20 10:03:21,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:21,388:INFO:Checking exceptions
2023-11-20 10:03:21,389:INFO:Importing libraries
2023-11-20 10:03:21,389:INFO:Copying training dataset
2023-11-20 10:03:21,394:INFO:Defining folds
2023-11-20 10:03:21,395:INFO:Declaring metric variables
2023-11-20 10:03:21,396:INFO:Importing untrained model
2023-11-20 10:03:21,397:INFO:K Neighbors Classifier Imported successfully
2023-11-20 10:03:21,398:INFO:Starting cross validation
2023-11-20 10:03:21,399:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:21,668:INFO:Calculating mean and std
2023-11-20 10:03:21,669:INFO:Creating metrics dataframe
2023-11-20 10:03:21,672:INFO:Uploading results into container
2023-11-20 10:03:21,673:INFO:Uploading model into container now
2023-11-20 10:03:21,674:INFO:_master_model_container: 2
2023-11-20 10:03:21,674:INFO:_display_container: 2
2023-11-20 10:03:21,675:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-20 10:03:21,675:INFO:create_model() successfully completed......................................
2023-11-20 10:03:21,724:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:21,725:INFO:Creating metrics dataframe
2023-11-20 10:03:21,732:INFO:Initializing Naive Bayes
2023-11-20 10:03:21,732:INFO:Total runtime is 0.009437274932861329 minutes
2023-11-20 10:03:21,733:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:21,734:INFO:Initializing create_model()
2023-11-20 10:03:21,735:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:21,735:INFO:Checking exceptions
2023-11-20 10:03:21,736:INFO:Importing libraries
2023-11-20 10:03:21,736:INFO:Copying training dataset
2023-11-20 10:03:21,740:INFO:Defining folds
2023-11-20 10:03:21,741:INFO:Declaring metric variables
2023-11-20 10:03:21,742:INFO:Importing untrained model
2023-11-20 10:03:21,742:INFO:Naive Bayes Imported successfully
2023-11-20 10:03:21,743:INFO:Starting cross validation
2023-11-20 10:03:21,745:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:21,828:INFO:Calculating mean and std
2023-11-20 10:03:21,829:INFO:Creating metrics dataframe
2023-11-20 10:03:21,833:INFO:Uploading results into container
2023-11-20 10:03:21,834:INFO:Uploading model into container now
2023-11-20 10:03:21,834:INFO:_master_model_container: 3
2023-11-20 10:03:21,834:INFO:_display_container: 2
2023-11-20 10:03:21,835:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-20 10:03:21,835:INFO:create_model() successfully completed......................................
2023-11-20 10:03:21,887:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:21,888:INFO:Creating metrics dataframe
2023-11-20 10:03:21,892:INFO:Initializing Decision Tree Classifier
2023-11-20 10:03:21,893:INFO:Total runtime is 0.012118975321451824 minutes
2023-11-20 10:03:21,894:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:21,895:INFO:Initializing create_model()
2023-11-20 10:03:21,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:21,896:INFO:Checking exceptions
2023-11-20 10:03:21,896:INFO:Importing libraries
2023-11-20 10:03:21,897:INFO:Copying training dataset
2023-11-20 10:03:21,899:INFO:Defining folds
2023-11-20 10:03:21,900:INFO:Declaring metric variables
2023-11-20 10:03:21,901:INFO:Importing untrained model
2023-11-20 10:03:21,902:INFO:Decision Tree Classifier Imported successfully
2023-11-20 10:03:21,903:INFO:Starting cross validation
2023-11-20 10:03:21,904:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:21,990:INFO:Calculating mean and std
2023-11-20 10:03:21,991:INFO:Creating metrics dataframe
2023-11-20 10:03:21,995:INFO:Uploading results into container
2023-11-20 10:03:21,996:INFO:Uploading model into container now
2023-11-20 10:03:21,996:INFO:_master_model_container: 4
2023-11-20 10:03:21,996:INFO:_display_container: 2
2023-11-20 10:03:21,997:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1549, splitter='best')
2023-11-20 10:03:21,997:INFO:create_model() successfully completed......................................
2023-11-20 10:03:22,049:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:22,050:INFO:Creating metrics dataframe
2023-11-20 10:03:22,054:INFO:Initializing SVM - Linear Kernel
2023-11-20 10:03:22,055:INFO:Total runtime is 0.014813248316446941 minutes
2023-11-20 10:03:22,055:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:22,056:INFO:Initializing create_model()
2023-11-20 10:03:22,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:22,057:INFO:Checking exceptions
2023-11-20 10:03:22,057:INFO:Importing libraries
2023-11-20 10:03:22,058:INFO:Copying training dataset
2023-11-20 10:03:22,060:INFO:Defining folds
2023-11-20 10:03:22,061:INFO:Declaring metric variables
2023-11-20 10:03:22,061:INFO:Importing untrained model
2023-11-20 10:03:22,062:INFO:SVM - Linear Kernel Imported successfully
2023-11-20 10:03:22,063:INFO:Starting cross validation
2023-11-20 10:03:22,064:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:22,076:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-20 10:03:22,092:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-20 10:03:22,106:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-20 10:03:22,121:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-20 10:03:22,136:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-20 10:03:22,142:INFO:Calculating mean and std
2023-11-20 10:03:22,143:INFO:Creating metrics dataframe
2023-11-20 10:03:22,147:INFO:Uploading results into container
2023-11-20 10:03:22,148:INFO:Uploading model into container now
2023-11-20 10:03:22,149:INFO:_master_model_container: 5
2023-11-20 10:03:22,150:INFO:_display_container: 2
2023-11-20 10:03:22,151:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1549, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-20 10:03:22,151:INFO:create_model() successfully completed......................................
2023-11-20 10:03:22,201:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:22,202:INFO:Creating metrics dataframe
2023-11-20 10:03:22,206:INFO:Initializing Ridge Classifier
2023-11-20 10:03:22,207:INFO:Total runtime is 0.017342448234558105 minutes
2023-11-20 10:03:22,207:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:22,208:INFO:Initializing create_model()
2023-11-20 10:03:22,208:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:22,208:INFO:Checking exceptions
2023-11-20 10:03:22,209:INFO:Importing libraries
2023-11-20 10:03:22,209:INFO:Copying training dataset
2023-11-20 10:03:22,212:INFO:Defining folds
2023-11-20 10:03:22,213:INFO:Declaring metric variables
2023-11-20 10:03:22,215:INFO:Importing untrained model
2023-11-20 10:03:22,217:INFO:Ridge Classifier Imported successfully
2023-11-20 10:03:22,219:INFO:Starting cross validation
2023-11-20 10:03:22,220:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:22,235:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-20 10:03:22,250:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-20 10:03:22,265:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-20 10:03:22,280:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-20 10:03:22,296:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-20 10:03:22,302:INFO:Calculating mean and std
2023-11-20 10:03:22,303:INFO:Creating metrics dataframe
2023-11-20 10:03:22,307:INFO:Uploading results into container
2023-11-20 10:03:22,308:INFO:Uploading model into container now
2023-11-20 10:03:22,309:INFO:_master_model_container: 6
2023-11-20 10:03:22,309:INFO:_display_container: 2
2023-11-20 10:03:22,310:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1549, solver='auto',
                tol=0.0001)
2023-11-20 10:03:22,310:INFO:create_model() successfully completed......................................
2023-11-20 10:03:22,360:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:22,361:INFO:Creating metrics dataframe
2023-11-20 10:03:22,365:INFO:Initializing Quadratic Discriminant Analysis
2023-11-20 10:03:22,366:INFO:Total runtime is 0.01999267339706421 minutes
2023-11-20 10:03:22,366:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:22,367:INFO:Initializing create_model()
2023-11-20 10:03:22,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:22,367:INFO:Checking exceptions
2023-11-20 10:03:22,368:INFO:Importing libraries
2023-11-20 10:03:22,368:INFO:Copying training dataset
2023-11-20 10:03:22,371:INFO:Defining folds
2023-11-20 10:03:22,372:INFO:Declaring metric variables
2023-11-20 10:03:22,372:INFO:Importing untrained model
2023-11-20 10:03:22,373:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-20 10:03:22,373:INFO:Starting cross validation
2023-11-20 10:03:22,374:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:22,454:INFO:Calculating mean and std
2023-11-20 10:03:22,455:INFO:Creating metrics dataframe
2023-11-20 10:03:22,458:INFO:Uploading results into container
2023-11-20 10:03:22,460:INFO:Uploading model into container now
2023-11-20 10:03:22,460:INFO:_master_model_container: 7
2023-11-20 10:03:22,461:INFO:_display_container: 2
2023-11-20 10:03:22,462:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-20 10:03:22,462:INFO:create_model() successfully completed......................................
2023-11-20 10:03:22,511:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:22,512:INFO:Creating metrics dataframe
2023-11-20 10:03:22,517:INFO:Initializing Ada Boost Classifier
2023-11-20 10:03:22,517:INFO:Total runtime is 0.022520971298217774 minutes
2023-11-20 10:03:22,518:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:22,519:INFO:Initializing create_model()
2023-11-20 10:03:22,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:22,520:INFO:Checking exceptions
2023-11-20 10:03:22,520:INFO:Importing libraries
2023-11-20 10:03:22,521:INFO:Copying training dataset
2023-11-20 10:03:22,523:INFO:Defining folds
2023-11-20 10:03:22,524:INFO:Declaring metric variables
2023-11-20 10:03:22,524:INFO:Importing untrained model
2023-11-20 10:03:22,525:INFO:Ada Boost Classifier Imported successfully
2023-11-20 10:03:22,526:INFO:Starting cross validation
2023-11-20 10:03:22,527:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:22,905:INFO:Calculating mean and std
2023-11-20 10:03:22,906:INFO:Creating metrics dataframe
2023-11-20 10:03:22,910:INFO:Uploading results into container
2023-11-20 10:03:22,911:INFO:Uploading model into container now
2023-11-20 10:03:22,912:INFO:_master_model_container: 8
2023-11-20 10:03:22,912:INFO:_display_container: 2
2023-11-20 10:03:22,913:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1549)
2023-11-20 10:03:22,913:INFO:create_model() successfully completed......................................
2023-11-20 10:03:22,964:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:22,965:INFO:Creating metrics dataframe
2023-11-20 10:03:22,970:INFO:Initializing Linear Discriminant Analysis
2023-11-20 10:03:22,971:INFO:Total runtime is 0.030079849561055503 minutes
2023-11-20 10:03:22,972:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:22,972:INFO:Initializing create_model()
2023-11-20 10:03:22,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:22,973:INFO:Checking exceptions
2023-11-20 10:03:22,974:INFO:Importing libraries
2023-11-20 10:03:22,975:INFO:Copying training dataset
2023-11-20 10:03:22,978:INFO:Defining folds
2023-11-20 10:03:22,979:INFO:Declaring metric variables
2023-11-20 10:03:22,980:INFO:Importing untrained model
2023-11-20 10:03:22,981:INFO:Linear Discriminant Analysis Imported successfully
2023-11-20 10:03:22,981:INFO:Starting cross validation
2023-11-20 10:03:22,982:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:23,064:INFO:Calculating mean and std
2023-11-20 10:03:23,065:INFO:Creating metrics dataframe
2023-11-20 10:03:23,069:INFO:Uploading results into container
2023-11-20 10:03:23,070:INFO:Uploading model into container now
2023-11-20 10:03:23,070:INFO:_master_model_container: 9
2023-11-20 10:03:23,071:INFO:_display_container: 2
2023-11-20 10:03:23,071:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-20 10:03:23,071:INFO:create_model() successfully completed......................................
2023-11-20 10:03:23,122:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:23,123:INFO:Creating metrics dataframe
2023-11-20 10:03:23,127:INFO:Initializing Extra Trees Classifier
2023-11-20 10:03:23,128:INFO:Total runtime is 0.032698190212249754 minutes
2023-11-20 10:03:23,129:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:23,129:INFO:Initializing create_model()
2023-11-20 10:03:23,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:23,130:INFO:Checking exceptions
2023-11-20 10:03:23,131:INFO:Importing libraries
2023-11-20 10:03:23,131:INFO:Copying training dataset
2023-11-20 10:03:23,135:INFO:Defining folds
2023-11-20 10:03:23,135:INFO:Declaring metric variables
2023-11-20 10:03:23,136:INFO:Importing untrained model
2023-11-20 10:03:23,137:INFO:Extra Trees Classifier Imported successfully
2023-11-20 10:03:23,137:INFO:Starting cross validation
2023-11-20 10:03:23,139:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:24,590:INFO:Calculating mean and std
2023-11-20 10:03:24,591:INFO:Creating metrics dataframe
2023-11-20 10:03:24,594:INFO:Uploading results into container
2023-11-20 10:03:24,595:INFO:Uploading model into container now
2023-11-20 10:03:24,595:INFO:_master_model_container: 10
2023-11-20 10:03:24,596:INFO:_display_container: 2
2023-11-20 10:03:24,596:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1549, verbose=0, warm_start=False)
2023-11-20 10:03:24,596:INFO:create_model() successfully completed......................................
2023-11-20 10:03:24,644:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:24,645:INFO:Creating metrics dataframe
2023-11-20 10:03:24,650:INFO:Initializing Light Gradient Boosting Machine
2023-11-20 10:03:24,650:INFO:Total runtime is 0.05807009935379028 minutes
2023-11-20 10:03:24,651:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:24,652:INFO:Initializing create_model()
2023-11-20 10:03:24,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:24,653:INFO:Checking exceptions
2023-11-20 10:03:24,653:INFO:Importing libraries
2023-11-20 10:03:24,654:INFO:Copying training dataset
2023-11-20 10:03:24,657:INFO:Defining folds
2023-11-20 10:03:24,657:INFO:Declaring metric variables
2023-11-20 10:03:24,658:INFO:Importing untrained model
2023-11-20 10:03:24,659:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-20 10:03:24,659:INFO:Starting cross validation
2023-11-20 10:03:24,661:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:24,703:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-20 10:03:24,711:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000062 seconds.
2023-11-20 10:03:24,711:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-20 10:03:24,712:INFO:[LightGBM] [Info] Total Bins 487
2023-11-20 10:03:24,712:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-20 10:03:24,713:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-20 10:03:24,713:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-20 10:03:24,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,773:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-20 10:03:24,774:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000055 seconds.
2023-11-20 10:03:24,774:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-20 10:03:24,774:INFO:[LightGBM] [Info] Total Bins 487
2023-11-20 10:03:24,775:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-20 10:03:24,775:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-20 10:03:24,775:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-20 10:03:24,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,982:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-20 10:03:24,982:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000054 seconds.
2023-11-20 10:03:24,982:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-20 10:03:24,983:INFO:[LightGBM] [Info] Total Bins 492
2023-11-20 10:03:24,983:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-20 10:03:24,983:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-20 10:03:24,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:24,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,040:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-20 10:03:25,041:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000048 seconds.
2023-11-20 10:03:25,041:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-20 10:03:25,041:INFO:[LightGBM] [Info] Total Bins 492
2023-11-20 10:03:25,041:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-20 10:03:25,042:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-20 10:03:25,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,098:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 60
2023-11-20 10:03:25,098:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000051 seconds.
2023-11-20 10:03:25,099:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-20 10:03:25,099:INFO:[LightGBM] [Info] Total Bins 492
2023-11-20 10:03:25,099:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-20 10:03:25,100:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491525 -> initscore=-0.033902
2023-11-20 10:03:25,100:INFO:[LightGBM] [Info] Start training from score -0.033902
2023-11-20 10:03:25,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 10:03:25,173:INFO:Calculating mean and std
2023-11-20 10:03:25,174:INFO:Creating metrics dataframe
2023-11-20 10:03:25,180:INFO:Uploading results into container
2023-11-20 10:03:25,181:INFO:Uploading model into container now
2023-11-20 10:03:25,182:INFO:_master_model_container: 11
2023-11-20 10:03:25,182:INFO:_display_container: 2
2023-11-20 10:03:25,183:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1549, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-20 10:03:25,183:INFO:create_model() successfully completed......................................
2023-11-20 10:03:25,241:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:25,241:INFO:Creating metrics dataframe
2023-11-20 10:03:25,246:INFO:Initializing Dummy Classifier
2023-11-20 10:03:25,246:INFO:Total runtime is 0.06800220807393392 minutes
2023-11-20 10:03:25,247:INFO:SubProcess create_model() called ==================================
2023-11-20 10:03:25,247:INFO:Initializing create_model()
2023-11-20 10:03:25,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fde38910ac0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:25,248:INFO:Checking exceptions
2023-11-20 10:03:25,248:INFO:Importing libraries
2023-11-20 10:03:25,248:INFO:Copying training dataset
2023-11-20 10:03:25,251:INFO:Defining folds
2023-11-20 10:03:25,251:INFO:Declaring metric variables
2023-11-20 10:03:25,252:INFO:Importing untrained model
2023-11-20 10:03:25,253:INFO:Dummy Classifier Imported successfully
2023-11-20 10:03:25,253:INFO:Starting cross validation
2023-11-20 10:03:25,254:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 10:03:25,271:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-20 10:03:25,288:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-20 10:03:25,303:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-20 10:03:25,318:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-20 10:03:25,335:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-20 10:03:25,341:INFO:Calculating mean and std
2023-11-20 10:03:25,342:INFO:Creating metrics dataframe
2023-11-20 10:03:25,344:INFO:Uploading results into container
2023-11-20 10:03:25,346:INFO:Uploading model into container now
2023-11-20 10:03:25,347:INFO:_master_model_container: 12
2023-11-20 10:03:25,347:INFO:_display_container: 2
2023-11-20 10:03:25,348:INFO:DummyClassifier(constant=None, random_state=1549, strategy='prior')
2023-11-20 10:03:25,348:INFO:create_model() successfully completed......................................
2023-11-20 10:03:25,395:INFO:SubProcess create_model() end ==================================
2023-11-20 10:03:25,397:INFO:Creating metrics dataframe
2023-11-20 10:03:25,403:INFO:Initializing create_model()
2023-11-20 10:03:25,403:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fde6940dbe0>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1549, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 10:03:25,404:INFO:Checking exceptions
2023-11-20 10:03:25,405:INFO:Importing libraries
2023-11-20 10:03:25,406:INFO:Copying training dataset
2023-11-20 10:03:25,408:INFO:Defining folds
2023-11-20 10:03:25,409:INFO:Declaring metric variables
2023-11-20 10:03:25,410:INFO:Importing untrained model
2023-11-20 10:03:25,411:INFO:Declaring custom model
2023-11-20 10:03:25,412:INFO:SVM - Linear Kernel Imported successfully
2023-11-20 10:03:25,413:INFO:Cross validation set to False
2023-11-20 10:03:25,414:INFO:Fitting Model
2023-11-20 10:03:25,422:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1549, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-20 10:03:25,423:INFO:create_model() successfully completed......................................
2023-11-20 10:03:25,480:INFO:_master_model_container: 12
2023-11-20 10:03:25,481:INFO:_display_container: 2
2023-11-20 10:03:25,482:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1549, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-20 10:03:25,482:INFO:compare_models() successfully completed......................................
2023-11-20 15:53:43,400:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,400:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,401:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,401:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,747:INFO:PyCaret ClassificationExperiment
2023-11-20 15:53:43,748:INFO:Logging name: clf-default-name
2023-11-20 15:53:43,748:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-20 15:53:43,748:INFO:version 3.2.0
2023-11-20 15:53:43,748:INFO:Initializing setup()
2023-11-20 15:53:43,750:INFO:self.USI: 7266
2023-11-20 15:53:43,750:INFO:self._variable_keys: {'pipeline', '_available_plots', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'gpu_param', 'fold_groups_param', 'logging_param', 'fix_imbalance', 'exp_name_log', '_ml_usecase', 'target_param', 'y', 'data', 'exp_id', 'seed', 'fold_generator', 'fold_shuffle_param', 'idx', 'html_param', 'y_train', 'X', 'y_test', 'X_test', 'X_train', 'memory', 'n_jobs_param', 'log_plots_param'}
2023-11-20 15:53:43,750:INFO:Checking environment
2023-11-20 15:53:43,751:INFO:python_version: 3.8.18
2023-11-20 15:53:43,751:INFO:python_build: ('default', 'Nov  1 2023 11:08:38')
2023-11-20 15:53:43,751:INFO:machine: aarch64
2023-11-20 15:53:43,752:INFO:platform: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-20 15:53:43,753:INFO:Memory: svmem(total=8225304576, available=7145627648, percent=13.1, used=870768640, free=5187837952, active=420413440, inactive=2138890240, buffers=95158272, cached=2071539712, shared=1298432, slab=303771648)
2023-11-20 15:53:43,754:INFO:Physical Core: 12
2023-11-20 15:53:43,754:INFO:Logical Core: 12
2023-11-20 15:53:43,754:INFO:Checking libraries
2023-11-20 15:53:43,755:INFO:System:
2023-11-20 15:53:43,755:INFO:    python: 3.8.18 (default, Nov  1 2023, 11:08:38)  [GCC 12.2.0]
2023-11-20 15:53:43,755:INFO:executable: /usr/local/bin/python
2023-11-20 15:53:43,755:INFO:   machine: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-20 15:53:43,755:INFO:PyCaret required dependencies:
2023-11-20 15:53:43,813:INFO:                 pip: 23.3.1
2023-11-20 15:53:43,814:INFO:          setuptools: 57.5.0
2023-11-20 15:53:43,814:INFO:             pycaret: 3.2.0
2023-11-20 15:53:43,814:INFO:             IPython: 8.12.3
2023-11-20 15:53:43,814:INFO:          ipywidgets: 8.1.1
2023-11-20 15:53:43,814:INFO:                tqdm: 4.66.1
2023-11-20 15:53:43,814:INFO:               numpy: 1.24.4
2023-11-20 15:53:43,815:INFO:              pandas: 1.5.3
2023-11-20 15:53:43,815:INFO:              jinja2: 3.1.2
2023-11-20 15:53:43,815:INFO:               scipy: 1.10.1
2023-11-20 15:53:43,815:INFO:              joblib: 1.3.2
2023-11-20 15:53:43,815:INFO:             sklearn: 1.2.2
2023-11-20 15:53:43,815:INFO:                pyod: 1.1.2
2023-11-20 15:53:43,815:INFO:            imblearn: 0.11.0
2023-11-20 15:53:43,816:INFO:   category_encoders: 2.6.3
2023-11-20 15:53:43,816:INFO:            lightgbm: 4.1.0
2023-11-20 15:53:43,816:INFO:               numba: 0.58.1
2023-11-20 15:53:43,816:INFO:            requests: 2.31.0
2023-11-20 15:53:43,816:INFO:          matplotlib: 3.6.0
2023-11-20 15:53:43,816:INFO:          scikitplot: 0.3.7
2023-11-20 15:53:43,817:INFO:         yellowbrick: 1.5
2023-11-20 15:53:43,817:INFO:              plotly: 5.18.0
2023-11-20 15:53:43,817:INFO:    plotly-resampler: Not installed
2023-11-20 15:53:43,817:INFO:             kaleido: 0.2.1
2023-11-20 15:53:43,817:INFO:           schemdraw: 0.15
2023-11-20 15:53:43,818:INFO:         statsmodels: 0.14.0
2023-11-20 15:53:43,818:INFO:              sktime: 0.21.1
2023-11-20 15:53:43,818:INFO:               tbats: 1.1.3
2023-11-20 15:53:43,818:INFO:            pmdarima: 2.0.4
2023-11-20 15:53:43,818:INFO:              psutil: 5.9.6
2023-11-20 15:53:43,818:INFO:          markupsafe: 2.1.3
2023-11-20 15:53:43,818:INFO:             pickle5: Not installed
2023-11-20 15:53:43,819:INFO:         cloudpickle: 3.0.0
2023-11-20 15:53:43,819:INFO:         deprecation: 2.1.0
2023-11-20 15:53:43,819:INFO:              xxhash: 3.4.1
2023-11-20 15:53:43,819:INFO:           wurlitzer: 3.0.3
2023-11-20 15:53:43,819:INFO:PyCaret optional dependencies:
2023-11-20 15:53:43,849:INFO:                shap: Not installed
2023-11-20 15:53:43,849:INFO:           interpret: Not installed
2023-11-20 15:53:43,849:INFO:                umap: Not installed
2023-11-20 15:53:43,849:INFO:     ydata_profiling: Not installed
2023-11-20 15:53:43,850:INFO:  explainerdashboard: Not installed
2023-11-20 15:53:43,850:INFO:             autoviz: Not installed
2023-11-20 15:53:43,850:INFO:           fairlearn: Not installed
2023-11-20 15:53:43,850:INFO:          deepchecks: Not installed
2023-11-20 15:53:43,850:INFO:             xgboost: Not installed
2023-11-20 15:53:43,850:INFO:            catboost: Not installed
2023-11-20 15:53:43,851:INFO:              kmodes: Not installed
2023-11-20 15:53:43,851:INFO:             mlxtend: Not installed
2023-11-20 15:53:43,851:INFO:       statsforecast: Not installed
2023-11-20 15:53:43,851:INFO:        tune_sklearn: Not installed
2023-11-20 15:53:43,851:INFO:                 ray: Not installed
2023-11-20 15:53:43,851:INFO:            hyperopt: Not installed
2023-11-20 15:53:43,851:INFO:              optuna: Not installed
2023-11-20 15:53:43,852:INFO:               skopt: Not installed
2023-11-20 15:53:43,852:INFO:              mlflow: Not installed
2023-11-20 15:53:43,852:INFO:              gradio: Not installed
2023-11-20 15:53:43,852:INFO:             fastapi: Not installed
2023-11-20 15:53:43,852:INFO:             uvicorn: Not installed
2023-11-20 15:53:43,852:INFO:              m2cgen: Not installed
2023-11-20 15:53:43,852:INFO:           evidently: Not installed
2023-11-20 15:53:43,853:INFO:               fugue: Not installed
2023-11-20 15:53:43,853:INFO:           streamlit: Not installed
2023-11-20 15:53:43,853:INFO:             prophet: Not installed
2023-11-20 15:53:43,853:INFO:None
2023-11-20 15:53:43,853:INFO:Set up GPU usage.
2023-11-20 15:53:43,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,853:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-20 15:53:43,853:INFO:Set up data.
2023-11-20 15:53:43,862:INFO:Set up folding strategy.
2023-11-20 15:53:43,862:INFO:Set up train/test split.
2023-11-20 15:53:43,864:INFO:Set up index.
2023-11-20 15:53:43,864:INFO:Assigning column types.
2023-11-20 15:53:43,865:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-20 15:53:43,865:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,883:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-20 15:53:43,883:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,885:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,886:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-20 15:53:43,886:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,897:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,899:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 15:53:43,923:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 15:53:43,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,943:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-20 15:53:43,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,945:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-20 15:53:43,945:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,961:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,964:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:43,966:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 15:53:43,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 15:53:43,983:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-20 15:53:43,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,004:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-20 15:53:44,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,013:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,015:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 15:53:44,023:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 15:53:44,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,042:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-20 15:53:44,042:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,054:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 15:53:44,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 15:53:44,061:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-20 15:53:44,061:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,089:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 15:53:44,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 15:53:44,098:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,116:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,116:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,125:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,127:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,128:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 15:53:44,134:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 15:53:44,136:INFO:Preparing preprocessing pipeline...
2023-11-20 15:53:44,138:INFO:Set up simple imputation.
2023-11-20 15:53:44,147:INFO:Finished creating preprocessing pipeline.
2023-11-20 15:53:44,150:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-20 15:53:44,150:INFO:Creating final display dataframe.
2023-11-20 15:53:44,175:INFO:Setup _display_container:                     Description             Value
0                    Session id              5537
1                        Target            target
2                   Target type            Binary
3           Original data shape         (210, 13)
4        Transformed data shape         (210, 13)
5   Transformed train set shape         (147, 13)
6    Transformed test set shape          (63, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              7266
2023-11-20 15:53:44,177:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 15:53:44,214:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 15:53:44,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,233:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,247:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,249:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-20 15:53:44,250:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 15:53:44,258:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-20 15:53:44,259:INFO:setup() successfully completed in 0.51s...............
2023-11-20 15:53:44,259:INFO:Initializing compare_models()
2023-11-20 15:53:44,259:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff93d71be0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffff93d71be0>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-20 15:53:44,260:INFO:Checking exceptions
2023-11-20 15:53:44,262:INFO:Preparing display monitor
2023-11-20 15:53:44,266:INFO:Initializing Logistic Regression
2023-11-20 15:53:44,267:INFO:Total runtime is 4.7763188680013025e-06 minutes
2023-11-20 15:53:44,267:INFO:SubProcess create_model() called ==================================
2023-11-20 15:53:44,267:INFO:Initializing create_model()
2023-11-20 15:53:44,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff93d71be0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff6afd0a90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 15:53:44,268:INFO:Checking exceptions
2023-11-20 15:53:44,268:INFO:Importing libraries
2023-11-20 15:53:44,268:INFO:Copying training dataset
2023-11-20 15:53:44,270:INFO:Defining folds
2023-11-20 15:53:44,270:INFO:Declaring metric variables
2023-11-20 15:53:44,271:INFO:Importing untrained model
2023-11-20 15:53:44,271:INFO:Logistic Regression Imported successfully
2023-11-20 15:53:44,271:INFO:Starting cross validation
2023-11-20 15:53:44,272:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 15:53:44,336:INFO:Calculating mean and std
2023-11-20 15:53:44,336:INFO:Creating metrics dataframe
2023-11-20 15:53:44,338:INFO:Uploading results into container
2023-11-20 15:53:44,338:INFO:Uploading model into container now
2023-11-20 15:53:44,339:INFO:_master_model_container: 1
2023-11-20 15:53:44,339:INFO:_display_container: 2
2023-11-20 15:53:44,339:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5537, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-20 15:53:44,339:INFO:create_model() successfully completed......................................
2023-11-20 15:53:44,421:INFO:SubProcess create_model() end ==================================
2023-11-20 15:53:44,421:INFO:Creating metrics dataframe
2023-11-20 15:53:44,424:INFO:Initializing K Neighbors Classifier
2023-11-20 15:53:44,424:INFO:Total runtime is 0.0026279330253601075 minutes
2023-11-20 15:53:44,424:INFO:SubProcess create_model() called ==================================
2023-11-20 15:53:44,424:INFO:Initializing create_model()
2023-11-20 15:53:44,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff93d71be0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff6afd0a90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 15:53:44,425:INFO:Checking exceptions
2023-11-20 15:53:44,425:INFO:Importing libraries
2023-11-20 15:53:44,425:INFO:Copying training dataset
2023-11-20 15:53:44,426:INFO:Defining folds
2023-11-20 15:53:44,427:INFO:Declaring metric variables
2023-11-20 15:53:44,427:INFO:Importing untrained model
2023-11-20 15:53:44,427:INFO:K Neighbors Classifier Imported successfully
2023-11-20 15:53:44,427:INFO:Starting cross validation
2023-11-20 15:53:44,428:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 15:53:44,626:INFO:Calculating mean and std
2023-11-20 15:53:44,627:INFO:Creating metrics dataframe
2023-11-20 15:53:44,629:INFO:Uploading results into container
2023-11-20 15:53:44,629:INFO:Uploading model into container now
2023-11-20 15:53:44,629:INFO:_master_model_container: 2
2023-11-20 15:53:44,629:INFO:_display_container: 2
2023-11-20 15:53:44,630:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-20 15:53:44,630:INFO:create_model() successfully completed......................................
2023-11-20 15:53:44,693:INFO:SubProcess create_model() end ==================================
2023-11-20 15:53:44,693:INFO:Creating metrics dataframe
2023-11-20 15:53:44,696:INFO:Initializing Naive Bayes
2023-11-20 15:53:44,696:INFO:Total runtime is 0.007169767220815023 minutes
2023-11-20 15:53:44,697:INFO:SubProcess create_model() called ==================================
2023-11-20 15:53:44,697:INFO:Initializing create_model()
2023-11-20 15:53:44,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff93d71be0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff6afd0a90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 15:53:44,697:INFO:Checking exceptions
2023-11-20 15:53:44,697:INFO:Importing libraries
2023-11-20 15:53:44,698:INFO:Copying training dataset
2023-11-20 15:53:44,699:INFO:Defining folds
2023-11-20 15:53:44,699:INFO:Declaring metric variables
2023-11-20 15:53:44,699:INFO:Importing untrained model
2023-11-20 15:53:44,700:INFO:Naive Bayes Imported successfully
2023-11-20 15:53:44,700:INFO:Starting cross validation
2023-11-20 15:53:44,701:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 15:53:44,745:INFO:Calculating mean and std
2023-11-20 15:53:44,745:INFO:Creating metrics dataframe
2023-11-20 15:53:44,747:INFO:Uploading results into container
2023-11-20 15:53:44,747:INFO:Uploading model into container now
2023-11-20 15:53:44,748:INFO:_master_model_container: 3
2023-11-20 15:53:44,748:INFO:_display_container: 2
2023-11-20 15:53:44,748:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-20 15:53:44,748:INFO:create_model() successfully completed......................................
2023-11-20 15:53:44,813:INFO:SubProcess create_model() end ==================================
2023-11-20 15:53:44,814:INFO:Creating metrics dataframe
2023-11-20 15:53:44,817:INFO:Initializing Decision Tree Classifier
2023-11-20 15:53:44,817:INFO:Total runtime is 0.009176846345265707 minutes
2023-11-20 15:53:44,817:INFO:SubProcess create_model() called ==================================
2023-11-20 15:53:44,817:INFO:Initializing create_model()
2023-11-20 15:53:44,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff93d71be0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff6afd0a90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 15:53:44,818:INFO:Checking exceptions
2023-11-20 15:53:44,818:INFO:Importing libraries
2023-11-20 15:53:44,818:INFO:Copying training dataset
2023-11-20 15:53:44,819:INFO:Defining folds
2023-11-20 15:53:44,820:INFO:Declaring metric variables
2023-11-20 15:53:44,820:INFO:Importing untrained model
2023-11-20 15:53:44,820:INFO:Decision Tree Classifier Imported successfully
2023-11-20 15:53:44,820:INFO:Starting cross validation
2023-11-20 15:53:44,821:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 15:53:44,861:INFO:Calculating mean and std
2023-11-20 15:53:44,862:INFO:Creating metrics dataframe
2023-11-20 15:53:44,863:INFO:Uploading results into container
2023-11-20 15:53:44,864:INFO:Uploading model into container now
2023-11-20 15:53:44,864:INFO:_master_model_container: 4
2023-11-20 15:53:44,864:INFO:_display_container: 2
2023-11-20 15:53:44,864:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5537, splitter='best')
2023-11-20 15:53:44,864:INFO:create_model() successfully completed......................................
2023-11-20 15:53:44,926:INFO:SubProcess create_model() end ==================================
2023-11-20 15:53:44,927:INFO:Creating metrics dataframe
2023-11-20 15:53:44,930:INFO:Initializing SVM - Linear Kernel
2023-11-20 15:53:44,930:INFO:Total runtime is 0.011062884330749513 minutes
2023-11-20 15:53:44,930:INFO:SubProcess create_model() called ==================================
2023-11-20 15:53:44,931:INFO:Initializing create_model()
2023-11-20 15:53:44,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff93d71be0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff6afd0a90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 15:53:44,931:INFO:Checking exceptions
2023-11-20 15:53:44,931:INFO:Importing libraries
2023-11-20 15:53:44,931:INFO:Copying training dataset
2023-11-20 15:53:44,933:INFO:Defining folds
2023-11-20 15:53:44,933:INFO:Declaring metric variables
2023-11-20 15:53:44,933:INFO:Importing untrained model
2023-11-20 15:53:44,934:INFO:SVM - Linear Kernel Imported successfully
2023-11-20 15:53:44,934:INFO:Starting cross validation
2023-11-20 15:53:44,935:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 15:53:44,942:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-20 15:53:44,950:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-20 15:53:44,956:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-20 15:53:44,963:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-20 15:53:44,971:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-20 15:53:44,973:INFO:Calculating mean and std
2023-11-20 15:53:44,974:INFO:Creating metrics dataframe
2023-11-20 15:53:44,975:INFO:Uploading results into container
2023-11-20 15:53:44,975:INFO:Uploading model into container now
2023-11-20 15:53:44,976:INFO:_master_model_container: 5
2023-11-20 15:53:44,976:INFO:_display_container: 2
2023-11-20 15:53:44,976:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5537, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-20 15:53:44,976:INFO:create_model() successfully completed......................................
2023-11-20 15:53:45,036:INFO:SubProcess create_model() end ==================================
2023-11-20 15:53:45,037:INFO:Creating metrics dataframe
2023-11-20 15:53:45,040:INFO:Initializing Ridge Classifier
2023-11-20 15:53:45,040:INFO:Total runtime is 0.012893978754679363 minutes
2023-11-20 15:53:45,040:INFO:SubProcess create_model() called ==================================
2023-11-20 15:53:45,040:INFO:Initializing create_model()
2023-11-20 15:53:45,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff93d71be0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff6afd0a90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 15:53:45,041:INFO:Checking exceptions
2023-11-20 15:53:45,041:INFO:Importing libraries
2023-11-20 15:53:45,041:INFO:Copying training dataset
2023-11-20 15:53:45,043:INFO:Defining folds
2023-11-20 15:53:45,043:INFO:Declaring metric variables
2023-11-20 15:53:45,043:INFO:Importing untrained model
2023-11-20 15:53:45,043:INFO:Ridge Classifier Imported successfully
2023-11-20 15:53:45,044:INFO:Starting cross validation
2023-11-20 15:53:45,045:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 15:53:45,054:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-20 15:53:45,061:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-20 15:53:45,068:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-20 15:53:45,075:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-20 15:53:45,082:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-20 15:53:45,085:INFO:Calculating mean and std
2023-11-20 15:53:45,086:INFO:Creating metrics dataframe
2023-11-20 15:53:45,087:INFO:Uploading results into container
2023-11-20 15:53:45,087:INFO:Uploading model into container now
2023-11-20 15:53:45,088:INFO:_master_model_container: 6
2023-11-20 15:53:45,088:INFO:_display_container: 2
2023-11-20 15:53:45,088:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5537, solver='auto',
                tol=0.0001)
2023-11-20 15:53:45,088:INFO:create_model() successfully completed......................................
2023-11-20 15:53:45,153:INFO:SubProcess create_model() end ==================================
2023-11-20 15:53:45,153:INFO:Creating metrics dataframe
2023-11-20 15:53:45,156:INFO:Initializing Quadratic Discriminant Analysis
2023-11-20 15:53:45,156:INFO:Total runtime is 0.014836732546488445 minutes
2023-11-20 15:53:45,157:INFO:SubProcess create_model() called ==================================
2023-11-20 15:53:45,157:INFO:Initializing create_model()
2023-11-20 15:53:45,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff93d71be0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff6afd0a90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 15:53:45,157:INFO:Checking exceptions
2023-11-20 15:53:45,157:INFO:Importing libraries
2023-11-20 15:53:45,158:INFO:Copying training dataset
2023-11-20 15:53:45,159:INFO:Defining folds
2023-11-20 15:53:45,159:INFO:Declaring metric variables
2023-11-20 15:53:45,160:INFO:Importing untrained model
2023-11-20 15:53:45,160:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-20 15:53:45,160:INFO:Starting cross validation
2023-11-20 15:53:45,161:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 15:53:45,205:INFO:Calculating mean and std
2023-11-20 15:53:45,205:INFO:Creating metrics dataframe
2023-11-20 15:53:45,207:INFO:Uploading results into container
2023-11-20 15:53:45,207:INFO:Uploading model into container now
2023-11-20 15:53:45,208:INFO:_master_model_container: 7
2023-11-20 15:53:45,208:INFO:_display_container: 2
2023-11-20 15:53:45,208:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-20 15:53:45,208:INFO:create_model() successfully completed......................................
2023-11-20 15:53:45,271:INFO:SubProcess create_model() end ==================================
2023-11-20 15:53:45,272:INFO:Creating metrics dataframe
2023-11-20 15:53:45,274:INFO:Initializing Ada Boost Classifier
2023-11-20 15:53:45,275:INFO:Total runtime is 0.016807885964711507 minutes
2023-11-20 15:53:45,275:INFO:SubProcess create_model() called ==================================
2023-11-20 15:53:45,275:INFO:Initializing create_model()
2023-11-20 15:53:45,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff93d71be0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff6afd0a90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 15:53:45,275:INFO:Checking exceptions
2023-11-20 15:53:45,276:INFO:Importing libraries
2023-11-20 15:53:45,276:INFO:Copying training dataset
2023-11-20 15:53:45,277:INFO:Defining folds
2023-11-20 15:53:45,277:INFO:Declaring metric variables
2023-11-20 15:53:45,278:INFO:Importing untrained model
2023-11-20 15:53:45,278:INFO:Ada Boost Classifier Imported successfully
2023-11-20 15:53:45,278:INFO:Starting cross validation
2023-11-20 15:53:45,279:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 15:53:45,461:INFO:Calculating mean and std
2023-11-20 15:53:45,461:INFO:Creating metrics dataframe
2023-11-20 15:53:45,463:INFO:Uploading results into container
2023-11-20 15:53:45,463:INFO:Uploading model into container now
2023-11-20 15:53:45,464:INFO:_master_model_container: 8
2023-11-20 15:53:45,464:INFO:_display_container: 2
2023-11-20 15:53:45,464:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=5537)
2023-11-20 15:53:45,464:INFO:create_model() successfully completed......................................
2023-11-20 15:53:45,529:INFO:SubProcess create_model() end ==================================
2023-11-20 15:53:45,529:INFO:Creating metrics dataframe
2023-11-20 15:53:45,532:INFO:Initializing Linear Discriminant Analysis
2023-11-20 15:53:45,532:INFO:Total runtime is 0.02109576463699341 minutes
2023-11-20 15:53:45,532:INFO:SubProcess create_model() called ==================================
2023-11-20 15:53:45,533:INFO:Initializing create_model()
2023-11-20 15:53:45,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff93d71be0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff6afd0a90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 15:53:45,533:INFO:Checking exceptions
2023-11-20 15:53:45,533:INFO:Importing libraries
2023-11-20 15:53:45,533:INFO:Copying training dataset
2023-11-20 15:53:45,535:INFO:Defining folds
2023-11-20 15:53:45,535:INFO:Declaring metric variables
2023-11-20 15:53:45,535:INFO:Importing untrained model
2023-11-20 15:53:45,535:INFO:Linear Discriminant Analysis Imported successfully
2023-11-20 15:53:45,536:INFO:Starting cross validation
2023-11-20 15:53:45,536:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 15:53:45,575:INFO:Calculating mean and std
2023-11-20 15:53:45,576:INFO:Creating metrics dataframe
2023-11-20 15:53:45,577:INFO:Uploading results into container
2023-11-20 15:53:45,577:INFO:Uploading model into container now
2023-11-20 15:53:45,578:INFO:_master_model_container: 9
2023-11-20 15:53:45,578:INFO:_display_container: 2
2023-11-20 15:53:45,578:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-20 15:53:45,578:INFO:create_model() successfully completed......................................
2023-11-20 15:53:45,637:INFO:SubProcess create_model() end ==================================
2023-11-20 15:53:45,637:INFO:Creating metrics dataframe
2023-11-20 15:53:45,640:INFO:Initializing Extra Trees Classifier
2023-11-20 15:53:45,640:INFO:Total runtime is 0.022902119159698486 minutes
2023-11-20 15:53:45,641:INFO:SubProcess create_model() called ==================================
2023-11-20 15:53:45,641:INFO:Initializing create_model()
2023-11-20 15:53:45,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff93d71be0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff6afd0a90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 15:53:45,641:INFO:Checking exceptions
2023-11-20 15:53:45,641:INFO:Importing libraries
2023-11-20 15:53:45,641:INFO:Copying training dataset
2023-11-20 15:53:45,643:INFO:Defining folds
2023-11-20 15:53:45,643:INFO:Declaring metric variables
2023-11-20 15:53:45,643:INFO:Importing untrained model
2023-11-20 15:53:45,644:INFO:Extra Trees Classifier Imported successfully
2023-11-20 15:53:45,644:INFO:Starting cross validation
2023-11-20 15:53:45,644:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 15:53:46,447:INFO:Calculating mean and std
2023-11-20 15:53:46,448:INFO:Creating metrics dataframe
2023-11-20 15:53:46,449:INFO:Uploading results into container
2023-11-20 15:53:46,450:INFO:Uploading model into container now
2023-11-20 15:53:46,450:INFO:_master_model_container: 10
2023-11-20 15:53:46,450:INFO:_display_container: 2
2023-11-20 15:53:46,451:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5537, verbose=0, warm_start=False)
2023-11-20 15:53:46,451:INFO:create_model() successfully completed......................................
2023-11-20 15:53:46,515:INFO:SubProcess create_model() end ==================================
2023-11-20 15:53:46,515:INFO:Creating metrics dataframe
2023-11-20 15:53:46,518:INFO:Initializing Light Gradient Boosting Machine
2023-11-20 15:53:46,518:INFO:Total runtime is 0.037531503041585285 minutes
2023-11-20 15:53:46,518:INFO:SubProcess create_model() called ==================================
2023-11-20 15:53:46,519:INFO:Initializing create_model()
2023-11-20 15:53:46,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff93d71be0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff6afd0a90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 15:53:46,519:INFO:Checking exceptions
2023-11-20 15:53:46,519:INFO:Importing libraries
2023-11-20 15:53:46,519:INFO:Copying training dataset
2023-11-20 15:53:46,521:INFO:Defining folds
2023-11-20 15:53:46,521:INFO:Declaring metric variables
2023-11-20 15:53:46,521:INFO:Importing untrained model
2023-11-20 15:53:46,521:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-20 15:53:46,522:INFO:Starting cross validation
2023-11-20 15:53:46,522:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 15:53:46,529:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-20 15:53:46,530:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000266 seconds.
2023-11-20 15:53:46,530:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-20 15:53:46,530:INFO:[LightGBM] [Info] Total Bins 488
2023-11-20 15:53:46,531:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-20 15:53:46,532:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-20 15:53:46,532:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-20 15:53:46,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,638:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-20 15:53:46,639:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000057 seconds.
2023-11-20 15:53:46,639:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-20 15:53:46,639:INFO:[LightGBM] [Info] Total Bins 488
2023-11-20 15:53:46,640:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-20 15:53:46,640:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-20 15:53:46,640:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-20 15:53:46,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,709:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 60
2023-11-20 15:53:46,709:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000052 seconds.
2023-11-20 15:53:46,710:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-20 15:53:46,710:INFO:[LightGBM] [Info] Total Bins 492
2023-11-20 15:53:46,710:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-20 15:53:46,710:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491525 -> initscore=-0.033902
2023-11-20 15:53:46,711:INFO:[LightGBM] [Info] Start training from score -0.033902
2023-11-20 15:53:46,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf

2023-11-20 15:53:46,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,776:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-20 15:53:46,777:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.
2023-11-20 15:53:46,777:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-20 15:53:46,777:INFO:[LightGBM] [Info] Total Bins 492
2023-11-20 15:53:46,778:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-20 15:53:46,778:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-20 15:53:46,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,878:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-20 15:53:46,878:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.
2023-11-20 15:53:46,879:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-20 15:53:46,879:INFO:[LightGBM] [Info] Total Bins 492
2023-11-20 15:53:46,879:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-20 15:53:46,879:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-20 15:53:46,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-20 15:53:46,979:INFO:Calculating mean and std
2023-11-20 15:53:46,979:INFO:Creating metrics dataframe
2023-11-20 15:53:46,981:INFO:Uploading results into container
2023-11-20 15:53:46,981:INFO:Uploading model into container now
2023-11-20 15:53:46,982:INFO:_master_model_container: 11
2023-11-20 15:53:46,982:INFO:_display_container: 2
2023-11-20 15:53:46,982:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5537, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-20 15:53:46,982:INFO:create_model() successfully completed......................................
2023-11-20 15:53:47,047:INFO:SubProcess create_model() end ==================================
2023-11-20 15:53:47,047:INFO:Creating metrics dataframe
2023-11-20 15:53:47,050:INFO:Initializing Dummy Classifier
2023-11-20 15:53:47,051:INFO:Total runtime is 0.04640513261159261 minutes
2023-11-20 15:53:47,051:INFO:SubProcess create_model() called ==================================
2023-11-20 15:53:47,051:INFO:Initializing create_model()
2023-11-20 15:53:47,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff93d71be0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff6afd0a90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 15:53:47,051:INFO:Checking exceptions
2023-11-20 15:53:47,052:INFO:Importing libraries
2023-11-20 15:53:47,052:INFO:Copying training dataset
2023-11-20 15:53:47,053:INFO:Defining folds
2023-11-20 15:53:47,053:INFO:Declaring metric variables
2023-11-20 15:53:47,053:INFO:Importing untrained model
2023-11-20 15:53:47,053:INFO:Dummy Classifier Imported successfully
2023-11-20 15:53:47,054:INFO:Starting cross validation
2023-11-20 15:53:47,054:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-20 15:53:47,062:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-20 15:53:47,069:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-20 15:53:47,075:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-20 15:53:47,081:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-20 15:53:47,088:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-20 15:53:47,089:INFO:Calculating mean and std
2023-11-20 15:53:47,090:INFO:Creating metrics dataframe
2023-11-20 15:53:47,091:INFO:Uploading results into container
2023-11-20 15:53:47,091:INFO:Uploading model into container now
2023-11-20 15:53:47,092:INFO:_master_model_container: 12
2023-11-20 15:53:47,092:INFO:_display_container: 2
2023-11-20 15:53:47,092:INFO:DummyClassifier(constant=None, random_state=5537, strategy='prior')
2023-11-20 15:53:47,092:INFO:create_model() successfully completed......................................
2023-11-20 15:53:47,148:INFO:SubProcess create_model() end ==================================
2023-11-20 15:53:47,148:INFO:Creating metrics dataframe
2023-11-20 15:53:47,152:INFO:Initializing create_model()
2023-11-20 15:53:47,152:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff93d71be0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5537, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-20 15:53:47,152:INFO:Checking exceptions
2023-11-20 15:53:47,152:INFO:Importing libraries
2023-11-20 15:53:47,153:INFO:Copying training dataset
2023-11-20 15:53:47,154:INFO:Defining folds
2023-11-20 15:53:47,154:INFO:Declaring metric variables
2023-11-20 15:53:47,154:INFO:Importing untrained model
2023-11-20 15:53:47,154:INFO:Declaring custom model
2023-11-20 15:53:47,155:INFO:Logistic Regression Imported successfully
2023-11-20 15:53:47,155:INFO:Cross validation set to False
2023-11-20 15:53:47,155:INFO:Fitting Model
2023-11-20 15:53:47,163:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5537, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-20 15:53:47,163:INFO:create_model() successfully completed......................................
2023-11-20 15:53:47,224:INFO:_master_model_container: 12
2023-11-20 15:53:47,225:INFO:_display_container: 2
2023-11-20 15:53:47,226:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5537, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-20 15:53:47,226:INFO:compare_models() successfully completed......................................
2023-11-26 07:00:05,211:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,212:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,212:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,212:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,466:INFO:PyCaret ClassificationExperiment
2023-11-26 07:00:05,466:INFO:Logging name: clf-default-name
2023-11-26 07:00:05,466:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-26 07:00:05,466:INFO:version 3.2.0
2023-11-26 07:00:05,466:INFO:Initializing setup()
2023-11-26 07:00:05,466:INFO:self.USI: ded5
2023-11-26 07:00:05,467:INFO:self._variable_keys: {'y', 'X_test', 'y_train', 'pipeline', 'html_param', 'exp_name_log', 'gpu_param', 'X', '_available_plots', 'data', 'seed', 'fold_generator', 'X_train', 'y_test', '_ml_usecase', 'exp_id', 'logging_param', 'log_plots_param', 'gpu_n_jobs_param', 'target_param', 'fix_imbalance', 'n_jobs_param', 'USI', 'memory', 'idx', 'fold_groups_param', 'fold_shuffle_param', 'is_multiclass'}
2023-11-26 07:00:05,467:INFO:Checking environment
2023-11-26 07:00:05,467:INFO:python_version: 3.8.18
2023-11-26 07:00:05,467:INFO:python_build: ('default', 'Nov 21 2023 19:36:55')
2023-11-26 07:00:05,467:INFO:machine: aarch64
2023-11-26 07:00:05,468:INFO:platform: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 07:00:05,468:INFO:Memory: svmem(total=8225304576, available=7119798272, percent=13.4, used=896716800, free=3575173120, active=1956454400, inactive=2090016768, buffers=114892800, cached=3638521856, shared=1212416, slab=429137920)
2023-11-26 07:00:05,469:INFO:Physical Core: 12
2023-11-26 07:00:05,470:INFO:Logical Core: 12
2023-11-26 07:00:05,470:INFO:Checking libraries
2023-11-26 07:00:05,470:INFO:System:
2023-11-26 07:00:05,470:INFO:    python: 3.8.18 (default, Nov 21 2023, 19:36:55)  [GCC 12.2.0]
2023-11-26 07:00:05,470:INFO:executable: /usr/local/bin/python
2023-11-26 07:00:05,470:INFO:   machine: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 07:00:05,470:INFO:PyCaret required dependencies:
2023-11-26 07:00:05,478:INFO:                 pip: 23.3.1
2023-11-26 07:00:05,478:INFO:          setuptools: 57.5.0
2023-11-26 07:00:05,478:INFO:             pycaret: 3.2.0
2023-11-26 07:00:05,478:INFO:             IPython: 8.12.3
2023-11-26 07:00:05,478:INFO:          ipywidgets: 8.1.1
2023-11-26 07:00:05,478:INFO:                tqdm: 4.66.1
2023-11-26 07:00:05,479:INFO:               numpy: 1.24.4
2023-11-26 07:00:05,479:INFO:              pandas: 1.5.3
2023-11-26 07:00:05,479:INFO:              jinja2: 3.1.2
2023-11-26 07:00:05,479:INFO:               scipy: 1.10.1
2023-11-26 07:00:05,479:INFO:              joblib: 1.3.2
2023-11-26 07:00:05,479:INFO:             sklearn: 1.2.2
2023-11-26 07:00:05,479:INFO:                pyod: 1.1.2
2023-11-26 07:00:05,479:INFO:            imblearn: 0.11.0
2023-11-26 07:00:05,479:INFO:   category_encoders: 2.6.3
2023-11-26 07:00:05,479:INFO:            lightgbm: 4.1.0
2023-11-26 07:00:05,479:INFO:               numba: 0.58.1
2023-11-26 07:00:05,479:INFO:            requests: 2.31.0
2023-11-26 07:00:05,479:INFO:          matplotlib: 3.6.0
2023-11-26 07:00:05,480:INFO:          scikitplot: 0.3.7
2023-11-26 07:00:05,480:INFO:         yellowbrick: 1.5
2023-11-26 07:00:05,480:INFO:              plotly: 5.18.0
2023-11-26 07:00:05,480:INFO:    plotly-resampler: Not installed
2023-11-26 07:00:05,480:INFO:             kaleido: 0.2.1
2023-11-26 07:00:05,480:INFO:           schemdraw: 0.15
2023-11-26 07:00:05,480:INFO:         statsmodels: 0.14.0
2023-11-26 07:00:05,480:INFO:              sktime: 0.21.1
2023-11-26 07:00:05,480:INFO:               tbats: 1.1.3
2023-11-26 07:00:05,480:INFO:            pmdarima: 2.0.4
2023-11-26 07:00:05,480:INFO:              psutil: 5.9.6
2023-11-26 07:00:05,480:INFO:          markupsafe: 2.1.3
2023-11-26 07:00:05,481:INFO:             pickle5: Not installed
2023-11-26 07:00:05,481:INFO:         cloudpickle: 3.0.0
2023-11-26 07:00:05,481:INFO:         deprecation: 2.1.0
2023-11-26 07:00:05,481:INFO:              xxhash: 3.4.1
2023-11-26 07:00:05,481:INFO:           wurlitzer: 3.0.3
2023-11-26 07:00:05,481:INFO:PyCaret optional dependencies:
2023-11-26 07:00:05,491:INFO:                shap: Not installed
2023-11-26 07:00:05,491:INFO:           interpret: Not installed
2023-11-26 07:00:05,491:INFO:                umap: Not installed
2023-11-26 07:00:05,491:INFO:     ydata_profiling: Not installed
2023-11-26 07:00:05,491:INFO:  explainerdashboard: Not installed
2023-11-26 07:00:05,491:INFO:             autoviz: Not installed
2023-11-26 07:00:05,491:INFO:           fairlearn: Not installed
2023-11-26 07:00:05,491:INFO:          deepchecks: Not installed
2023-11-26 07:00:05,491:INFO:             xgboost: Not installed
2023-11-26 07:00:05,492:INFO:            catboost: Not installed
2023-11-26 07:00:05,492:INFO:              kmodes: Not installed
2023-11-26 07:00:05,492:INFO:             mlxtend: Not installed
2023-11-26 07:00:05,492:INFO:       statsforecast: Not installed
2023-11-26 07:00:05,492:INFO:        tune_sklearn: Not installed
2023-11-26 07:00:05,492:INFO:                 ray: Not installed
2023-11-26 07:00:05,492:INFO:            hyperopt: Not installed
2023-11-26 07:00:05,492:INFO:              optuna: Not installed
2023-11-26 07:00:05,492:INFO:               skopt: Not installed
2023-11-26 07:00:05,493:INFO:              mlflow: Not installed
2023-11-26 07:00:05,493:INFO:              gradio: Not installed
2023-11-26 07:00:05,494:INFO:             fastapi: Not installed
2023-11-26 07:00:05,494:INFO:             uvicorn: Not installed
2023-11-26 07:00:05,494:INFO:              m2cgen: Not installed
2023-11-26 07:00:05,494:INFO:           evidently: Not installed
2023-11-26 07:00:05,494:INFO:               fugue: Not installed
2023-11-26 07:00:05,494:INFO:           streamlit: Not installed
2023-11-26 07:00:05,494:INFO:             prophet: Not installed
2023-11-26 07:00:05,494:INFO:None
2023-11-26 07:00:05,494:INFO:Set up GPU usage.
2023-11-26 07:00:05,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,494:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-26 07:00:05,495:INFO:Set up data.
2023-11-26 07:00:05,498:INFO:Set up folding strategy.
2023-11-26 07:00:05,498:INFO:Set up train/test split.
2023-11-26 07:00:05,499:INFO:Set up index.
2023-11-26 07:00:05,500:INFO:Assigning column types.
2023-11-26 07:00:05,501:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-26 07:00:05,501:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,519:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 07:00:05,519:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,521:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,521:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 07:00:05,521:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,531:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,533:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,534:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:00:05,550:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:00:05,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,568:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 07:00:05,568:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,569:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,569:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 07:00:05,569:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,578:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:00:05,586:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:00:05,586:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-26 07:00:05,586:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,604:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,605:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 07:00:05,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,616:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:00:05,622:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:00:05,622:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,642:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 07:00:05,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,651:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,653:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,654:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:00:05,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:00:05,658:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-26 07:00:05,658:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,676:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,677:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,687:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,688:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:00:05,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:00:05,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,710:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,719:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,721:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:00:05,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:00:05,728:INFO:Preparing preprocessing pipeline...
2023-11-26 07:00:05,728:INFO:Set up simple imputation.
2023-11-26 07:00:05,737:INFO:Finished creating preprocessing pipeline.
2023-11-26 07:00:05,739:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-26 07:00:05,739:INFO:Creating final display dataframe.
2023-11-26 07:00:05,763:INFO:Setup _display_container:                     Description             Value
0                    Session id              3247
1                        Target            target
2                   Target type            Binary
3           Original data shape         (210, 13)
4        Transformed data shape         (210, 13)
5   Transformed train set shape         (147, 13)
6    Transformed test set shape          (63, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              ded5
2023-11-26 07:00:05,766:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,783:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,783:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,783:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,792:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,794:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:00:05,798:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:00:05,799:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,816:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,816:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,825:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:00:05,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:00:05,832:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:00:05,832:INFO:setup() successfully completed in 0.37s...............
2023-11-26 07:00:05,832:INFO:Initializing compare_models()
2023-11-26 07:00:05,833:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-26 07:00:05,833:INFO:Checking exceptions
2023-11-26 07:00:05,834:INFO:Preparing display monitor
2023-11-26 07:00:05,836:INFO:Initializing Logistic Regression
2023-11-26 07:00:05,836:INFO:Total runtime is 1.8874804178873699e-06 minutes
2023-11-26 07:00:05,836:INFO:SubProcess create_model() called ==================================
2023-11-26 07:00:05,836:INFO:Initializing create_model()
2023-11-26 07:00:05,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff576bddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:00:05,836:INFO:Checking exceptions
2023-11-26 07:00:05,837:INFO:Importing libraries
2023-11-26 07:00:05,837:INFO:Copying training dataset
2023-11-26 07:00:05,838:INFO:Defining folds
2023-11-26 07:00:05,838:INFO:Declaring metric variables
2023-11-26 07:00:05,838:INFO:Importing untrained model
2023-11-26 07:00:05,838:INFO:Logistic Regression Imported successfully
2023-11-26 07:00:05,838:INFO:Starting cross validation
2023-11-26 07:00:05,839:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:00:05,896:INFO:Calculating mean and std
2023-11-26 07:00:05,896:INFO:Creating metrics dataframe
2023-11-26 07:00:05,898:INFO:Uploading results into container
2023-11-26 07:00:05,898:INFO:Uploading model into container now
2023-11-26 07:00:05,898:INFO:_master_model_container: 1
2023-11-26 07:00:05,898:INFO:_display_container: 2
2023-11-26 07:00:05,899:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3247, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-26 07:00:05,899:INFO:create_model() successfully completed......................................
2023-11-26 07:00:05,935:INFO:SubProcess create_model() end ==================================
2023-11-26 07:00:05,935:INFO:Creating metrics dataframe
2023-11-26 07:00:05,937:INFO:Initializing K Neighbors Classifier
2023-11-26 07:00:05,937:INFO:Total runtime is 0.0016907453536987305 minutes
2023-11-26 07:00:05,937:INFO:SubProcess create_model() called ==================================
2023-11-26 07:00:05,938:INFO:Initializing create_model()
2023-11-26 07:00:05,938:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff576bddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:00:05,938:INFO:Checking exceptions
2023-11-26 07:00:05,938:INFO:Importing libraries
2023-11-26 07:00:05,938:INFO:Copying training dataset
2023-11-26 07:00:05,939:INFO:Defining folds
2023-11-26 07:00:05,939:INFO:Declaring metric variables
2023-11-26 07:00:05,940:INFO:Importing untrained model
2023-11-26 07:00:05,940:INFO:K Neighbors Classifier Imported successfully
2023-11-26 07:00:05,940:INFO:Starting cross validation
2023-11-26 07:00:05,940:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:00:06,115:INFO:Calculating mean and std
2023-11-26 07:00:06,115:INFO:Creating metrics dataframe
2023-11-26 07:00:06,117:INFO:Uploading results into container
2023-11-26 07:00:06,117:INFO:Uploading model into container now
2023-11-26 07:00:06,118:INFO:_master_model_container: 2
2023-11-26 07:00:06,118:INFO:_display_container: 2
2023-11-26 07:00:06,118:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-26 07:00:06,118:INFO:create_model() successfully completed......................................
2023-11-26 07:00:06,147:INFO:SubProcess create_model() end ==================================
2023-11-26 07:00:06,148:INFO:Creating metrics dataframe
2023-11-26 07:00:06,150:INFO:Initializing Naive Bayes
2023-11-26 07:00:06,150:INFO:Total runtime is 0.005236244201660157 minutes
2023-11-26 07:00:06,150:INFO:SubProcess create_model() called ==================================
2023-11-26 07:00:06,150:INFO:Initializing create_model()
2023-11-26 07:00:06,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff576bddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:00:06,151:INFO:Checking exceptions
2023-11-26 07:00:06,151:INFO:Importing libraries
2023-11-26 07:00:06,151:INFO:Copying training dataset
2023-11-26 07:00:06,152:INFO:Defining folds
2023-11-26 07:00:06,152:INFO:Declaring metric variables
2023-11-26 07:00:06,152:INFO:Importing untrained model
2023-11-26 07:00:06,152:INFO:Naive Bayes Imported successfully
2023-11-26 07:00:06,153:INFO:Starting cross validation
2023-11-26 07:00:06,153:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:00:06,191:INFO:Calculating mean and std
2023-11-26 07:00:06,191:INFO:Creating metrics dataframe
2023-11-26 07:00:06,193:INFO:Uploading results into container
2023-11-26 07:00:06,193:INFO:Uploading model into container now
2023-11-26 07:00:06,193:INFO:_master_model_container: 3
2023-11-26 07:00:06,193:INFO:_display_container: 2
2023-11-26 07:00:06,193:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-26 07:00:06,194:INFO:create_model() successfully completed......................................
2023-11-26 07:00:06,222:INFO:SubProcess create_model() end ==================================
2023-11-26 07:00:06,222:INFO:Creating metrics dataframe
2023-11-26 07:00:06,224:INFO:Initializing Decision Tree Classifier
2023-11-26 07:00:06,224:INFO:Total runtime is 0.006471772988637289 minutes
2023-11-26 07:00:06,224:INFO:SubProcess create_model() called ==================================
2023-11-26 07:00:06,224:INFO:Initializing create_model()
2023-11-26 07:00:06,225:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff576bddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:00:06,225:INFO:Checking exceptions
2023-11-26 07:00:06,225:INFO:Importing libraries
2023-11-26 07:00:06,225:INFO:Copying training dataset
2023-11-26 07:00:06,226:INFO:Defining folds
2023-11-26 07:00:06,226:INFO:Declaring metric variables
2023-11-26 07:00:06,226:INFO:Importing untrained model
2023-11-26 07:00:06,226:INFO:Decision Tree Classifier Imported successfully
2023-11-26 07:00:06,227:INFO:Starting cross validation
2023-11-26 07:00:06,227:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:00:06,266:INFO:Calculating mean and std
2023-11-26 07:00:06,266:INFO:Creating metrics dataframe
2023-11-26 07:00:06,267:INFO:Uploading results into container
2023-11-26 07:00:06,268:INFO:Uploading model into container now
2023-11-26 07:00:06,268:INFO:_master_model_container: 4
2023-11-26 07:00:06,268:INFO:_display_container: 2
2023-11-26 07:00:06,268:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3247, splitter='best')
2023-11-26 07:00:06,268:INFO:create_model() successfully completed......................................
2023-11-26 07:00:06,295:INFO:SubProcess create_model() end ==================================
2023-11-26 07:00:06,295:INFO:Creating metrics dataframe
2023-11-26 07:00:06,297:INFO:Initializing SVM - Linear Kernel
2023-11-26 07:00:06,297:INFO:Total runtime is 0.0076933105786641445 minutes
2023-11-26 07:00:06,298:INFO:SubProcess create_model() called ==================================
2023-11-26 07:00:06,298:INFO:Initializing create_model()
2023-11-26 07:00:06,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff576bddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:00:06,298:INFO:Checking exceptions
2023-11-26 07:00:06,298:INFO:Importing libraries
2023-11-26 07:00:06,298:INFO:Copying training dataset
2023-11-26 07:00:06,300:INFO:Defining folds
2023-11-26 07:00:06,300:INFO:Declaring metric variables
2023-11-26 07:00:06,300:INFO:Importing untrained model
2023-11-26 07:00:06,300:INFO:SVM - Linear Kernel Imported successfully
2023-11-26 07:00:06,300:INFO:Starting cross validation
2023-11-26 07:00:06,301:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:00:06,307:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 07:00:06,314:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 07:00:06,321:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 07:00:06,328:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 07:00:06,335:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 07:00:06,337:INFO:Calculating mean and std
2023-11-26 07:00:06,337:INFO:Creating metrics dataframe
2023-11-26 07:00:06,339:INFO:Uploading results into container
2023-11-26 07:00:06,339:INFO:Uploading model into container now
2023-11-26 07:00:06,339:INFO:_master_model_container: 5
2023-11-26 07:00:06,339:INFO:_display_container: 2
2023-11-26 07:00:06,340:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3247, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-26 07:00:06,340:INFO:create_model() successfully completed......................................
2023-11-26 07:00:06,369:INFO:SubProcess create_model() end ==================================
2023-11-26 07:00:06,369:INFO:Creating metrics dataframe
2023-11-26 07:00:06,371:INFO:Initializing Ridge Classifier
2023-11-26 07:00:06,371:INFO:Total runtime is 0.00891937812169393 minutes
2023-11-26 07:00:06,371:INFO:SubProcess create_model() called ==================================
2023-11-26 07:00:06,371:INFO:Initializing create_model()
2023-11-26 07:00:06,371:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff576bddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:00:06,372:INFO:Checking exceptions
2023-11-26 07:00:06,372:INFO:Importing libraries
2023-11-26 07:00:06,372:INFO:Copying training dataset
2023-11-26 07:00:06,373:INFO:Defining folds
2023-11-26 07:00:06,373:INFO:Declaring metric variables
2023-11-26 07:00:06,373:INFO:Importing untrained model
2023-11-26 07:00:06,373:INFO:Ridge Classifier Imported successfully
2023-11-26 07:00:06,373:INFO:Starting cross validation
2023-11-26 07:00:06,374:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:00:06,382:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 07:00:06,389:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 07:00:06,396:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 07:00:06,403:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 07:00:06,409:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 07:00:06,412:INFO:Calculating mean and std
2023-11-26 07:00:06,413:INFO:Creating metrics dataframe
2023-11-26 07:00:06,414:INFO:Uploading results into container
2023-11-26 07:00:06,414:INFO:Uploading model into container now
2023-11-26 07:00:06,415:INFO:_master_model_container: 6
2023-11-26 07:00:06,415:INFO:_display_container: 2
2023-11-26 07:00:06,415:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3247, solver='auto',
                tol=0.0001)
2023-11-26 07:00:06,415:INFO:create_model() successfully completed......................................
2023-11-26 07:00:06,444:INFO:SubProcess create_model() end ==================================
2023-11-26 07:00:06,445:INFO:Creating metrics dataframe
2023-11-26 07:00:06,447:INFO:Initializing Quadratic Discriminant Analysis
2023-11-26 07:00:06,447:INFO:Total runtime is 0.010186906655629477 minutes
2023-11-26 07:00:06,447:INFO:SubProcess create_model() called ==================================
2023-11-26 07:00:06,447:INFO:Initializing create_model()
2023-11-26 07:00:06,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff576bddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:00:06,448:INFO:Checking exceptions
2023-11-26 07:00:06,448:INFO:Importing libraries
2023-11-26 07:00:06,448:INFO:Copying training dataset
2023-11-26 07:00:06,449:INFO:Defining folds
2023-11-26 07:00:06,449:INFO:Declaring metric variables
2023-11-26 07:00:06,449:INFO:Importing untrained model
2023-11-26 07:00:06,449:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-26 07:00:06,449:INFO:Starting cross validation
2023-11-26 07:00:06,450:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:00:06,487:INFO:Calculating mean and std
2023-11-26 07:00:06,487:INFO:Creating metrics dataframe
2023-11-26 07:00:06,489:INFO:Uploading results into container
2023-11-26 07:00:06,489:INFO:Uploading model into container now
2023-11-26 07:00:06,489:INFO:_master_model_container: 7
2023-11-26 07:00:06,489:INFO:_display_container: 2
2023-11-26 07:00:06,490:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-26 07:00:06,490:INFO:create_model() successfully completed......................................
2023-11-26 07:00:06,521:INFO:SubProcess create_model() end ==================================
2023-11-26 07:00:06,521:INFO:Creating metrics dataframe
2023-11-26 07:00:06,524:INFO:Initializing Ada Boost Classifier
2023-11-26 07:00:06,524:INFO:Total runtime is 0.011467242240905763 minutes
2023-11-26 07:00:06,524:INFO:SubProcess create_model() called ==================================
2023-11-26 07:00:06,524:INFO:Initializing create_model()
2023-11-26 07:00:06,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff576bddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:00:06,524:INFO:Checking exceptions
2023-11-26 07:00:06,524:INFO:Importing libraries
2023-11-26 07:00:06,525:INFO:Copying training dataset
2023-11-26 07:00:06,526:INFO:Defining folds
2023-11-26 07:00:06,526:INFO:Declaring metric variables
2023-11-26 07:00:06,527:INFO:Importing untrained model
2023-11-26 07:00:06,527:INFO:Ada Boost Classifier Imported successfully
2023-11-26 07:00:06,527:INFO:Starting cross validation
2023-11-26 07:00:06,528:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:00:06,708:INFO:Calculating mean and std
2023-11-26 07:00:06,709:INFO:Creating metrics dataframe
2023-11-26 07:00:06,710:INFO:Uploading results into container
2023-11-26 07:00:06,710:INFO:Uploading model into container now
2023-11-26 07:00:06,710:INFO:_master_model_container: 8
2023-11-26 07:00:06,711:INFO:_display_container: 2
2023-11-26 07:00:06,711:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=3247)
2023-11-26 07:00:06,711:INFO:create_model() successfully completed......................................
2023-11-26 07:00:06,740:INFO:SubProcess create_model() end ==================================
2023-11-26 07:00:06,740:INFO:Creating metrics dataframe
2023-11-26 07:00:06,743:INFO:Initializing Linear Discriminant Analysis
2023-11-26 07:00:06,743:INFO:Total runtime is 0.01511655648549398 minutes
2023-11-26 07:00:06,743:INFO:SubProcess create_model() called ==================================
2023-11-26 07:00:06,743:INFO:Initializing create_model()
2023-11-26 07:00:06,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff576bddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:00:06,743:INFO:Checking exceptions
2023-11-26 07:00:06,743:INFO:Importing libraries
2023-11-26 07:00:06,744:INFO:Copying training dataset
2023-11-26 07:00:06,745:INFO:Defining folds
2023-11-26 07:00:06,745:INFO:Declaring metric variables
2023-11-26 07:00:06,745:INFO:Importing untrained model
2023-11-26 07:00:06,745:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 07:00:06,745:INFO:Starting cross validation
2023-11-26 07:00:06,746:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:00:06,784:INFO:Calculating mean and std
2023-11-26 07:00:06,784:INFO:Creating metrics dataframe
2023-11-26 07:00:06,785:INFO:Uploading results into container
2023-11-26 07:00:06,786:INFO:Uploading model into container now
2023-11-26 07:00:06,786:INFO:_master_model_container: 9
2023-11-26 07:00:06,786:INFO:_display_container: 2
2023-11-26 07:00:06,786:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:00:06,786:INFO:create_model() successfully completed......................................
2023-11-26 07:00:06,814:INFO:SubProcess create_model() end ==================================
2023-11-26 07:00:06,814:INFO:Creating metrics dataframe
2023-11-26 07:00:06,817:INFO:Initializing Extra Trees Classifier
2023-11-26 07:00:06,817:INFO:Total runtime is 0.016349188486735028 minutes
2023-11-26 07:00:06,817:INFO:SubProcess create_model() called ==================================
2023-11-26 07:00:06,817:INFO:Initializing create_model()
2023-11-26 07:00:06,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff576bddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:00:06,817:INFO:Checking exceptions
2023-11-26 07:00:06,817:INFO:Importing libraries
2023-11-26 07:00:06,817:INFO:Copying training dataset
2023-11-26 07:00:06,819:INFO:Defining folds
2023-11-26 07:00:06,819:INFO:Declaring metric variables
2023-11-26 07:00:06,819:INFO:Importing untrained model
2023-11-26 07:00:06,819:INFO:Extra Trees Classifier Imported successfully
2023-11-26 07:00:06,819:INFO:Starting cross validation
2023-11-26 07:00:06,820:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:00:07,504:INFO:Calculating mean and std
2023-11-26 07:00:07,504:INFO:Creating metrics dataframe
2023-11-26 07:00:07,506:INFO:Uploading results into container
2023-11-26 07:00:07,506:INFO:Uploading model into container now
2023-11-26 07:00:07,506:INFO:_master_model_container: 10
2023-11-26 07:00:07,506:INFO:_display_container: 2
2023-11-26 07:00:07,507:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3247, verbose=0, warm_start=False)
2023-11-26 07:00:07,507:INFO:create_model() successfully completed......................................
2023-11-26 07:00:07,539:INFO:SubProcess create_model() end ==================================
2023-11-26 07:00:07,539:INFO:Creating metrics dataframe
2023-11-26 07:00:07,541:INFO:Initializing Light Gradient Boosting Machine
2023-11-26 07:00:07,542:INFO:Total runtime is 0.028427783648173017 minutes
2023-11-26 07:00:07,542:INFO:SubProcess create_model() called ==================================
2023-11-26 07:00:07,542:INFO:Initializing create_model()
2023-11-26 07:00:07,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff576bddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:00:07,542:INFO:Checking exceptions
2023-11-26 07:00:07,542:INFO:Importing libraries
2023-11-26 07:00:07,542:INFO:Copying training dataset
2023-11-26 07:00:07,543:INFO:Defining folds
2023-11-26 07:00:07,544:INFO:Declaring metric variables
2023-11-26 07:00:07,544:INFO:Importing untrained model
2023-11-26 07:00:07,544:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-26 07:00:07,544:INFO:Starting cross validation
2023-11-26 07:00:07,545:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:00:07,550:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 07:00:07,552:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.
2023-11-26 07:00:07,552:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-26 07:00:07,552:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-26 07:00:07,552:INFO:[LightGBM] [Info] Total Bins 488
2023-11-26 07:00:07,552:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 07:00:07,553:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 07:00:07,553:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 07:00:07,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,662:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 07:00:07,663:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.
2023-11-26 07:00:07,663:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 07:00:07,663:INFO:[LightGBM] [Info] Total Bins 485
2023-11-26 07:00:07,663:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 07:00:07,664:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 07:00:07,664:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 07:00:07,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,747:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 07:00:07,747:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.
2023-11-26 07:00:07,747:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 07:00:07,747:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 07:00:07,747:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 07:00:07,748:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 07:00:07,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,805:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 07:00:07,806:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000419 seconds.
2023-11-26 07:00:07,806:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 07:00:07,806:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 07:00:07,806:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 07:00:07,807:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 07:00:07,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,901:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 60
2023-11-26 07:00:07,901:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.
2023-11-26 07:00:07,902:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 07:00:07,902:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 07:00:07,902:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 07:00:07,902:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491525 -> initscore=-0.033902
2023-11-26 07:00:07,903:INFO:[LightGBM] [Info] Start training from score -0.033902
2023-11-26 07:00:07,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:00:07,967:INFO:Calculating mean and std
2023-11-26 07:00:07,968:INFO:Creating metrics dataframe
2023-11-26 07:00:07,969:INFO:Uploading results into container
2023-11-26 07:00:07,970:INFO:Uploading model into container now
2023-11-26 07:00:07,970:INFO:_master_model_container: 11
2023-11-26 07:00:07,970:INFO:_display_container: 2
2023-11-26 07:00:07,970:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3247, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-26 07:00:07,971:INFO:create_model() successfully completed......................................
2023-11-26 07:00:08,000:INFO:SubProcess create_model() end ==================================
2023-11-26 07:00:08,000:INFO:Creating metrics dataframe
2023-11-26 07:00:08,003:INFO:Initializing Dummy Classifier
2023-11-26 07:00:08,003:INFO:Total runtime is 0.03611809015274048 minutes
2023-11-26 07:00:08,003:INFO:SubProcess create_model() called ==================================
2023-11-26 07:00:08,003:INFO:Initializing create_model()
2023-11-26 07:00:08,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff576bddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:00:08,004:INFO:Checking exceptions
2023-11-26 07:00:08,004:INFO:Importing libraries
2023-11-26 07:00:08,004:INFO:Copying training dataset
2023-11-26 07:00:08,005:INFO:Defining folds
2023-11-26 07:00:08,005:INFO:Declaring metric variables
2023-11-26 07:00:08,005:INFO:Importing untrained model
2023-11-26 07:00:08,005:INFO:Dummy Classifier Imported successfully
2023-11-26 07:00:08,006:INFO:Starting cross validation
2023-11-26 07:00:08,006:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:00:08,013:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 07:00:08,019:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 07:00:08,026:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 07:00:08,032:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 07:00:08,039:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 07:00:08,040:INFO:Calculating mean and std
2023-11-26 07:00:08,041:INFO:Creating metrics dataframe
2023-11-26 07:00:08,042:INFO:Uploading results into container
2023-11-26 07:00:08,042:INFO:Uploading model into container now
2023-11-26 07:00:08,042:INFO:_master_model_container: 12
2023-11-26 07:00:08,043:INFO:_display_container: 2
2023-11-26 07:00:08,043:INFO:DummyClassifier(constant=None, random_state=3247, strategy='prior')
2023-11-26 07:00:08,043:INFO:create_model() successfully completed......................................
2023-11-26 07:00:08,073:INFO:SubProcess create_model() end ==================================
2023-11-26 07:00:08,073:INFO:Creating metrics dataframe
2023-11-26 07:00:08,076:INFO:Initializing create_model()
2023-11-26 07:00:08,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3247, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:00:08,076:INFO:Checking exceptions
2023-11-26 07:00:08,077:INFO:Importing libraries
2023-11-26 07:00:08,077:INFO:Copying training dataset
2023-11-26 07:00:08,078:INFO:Defining folds
2023-11-26 07:00:08,078:INFO:Declaring metric variables
2023-11-26 07:00:08,078:INFO:Importing untrained model
2023-11-26 07:00:08,078:INFO:Declaring custom model
2023-11-26 07:00:08,079:INFO:SVM - Linear Kernel Imported successfully
2023-11-26 07:00:08,079:INFO:Cross validation set to False
2023-11-26 07:00:08,079:INFO:Fitting Model
2023-11-26 07:00:08,083:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3247, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-26 07:00:08,083:INFO:create_model() successfully completed......................................
2023-11-26 07:00:08,113:INFO:_master_model_container: 12
2023-11-26 07:00:08,113:INFO:_display_container: 2
2023-11-26 07:00:08,114:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3247, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-26 07:00:08,114:INFO:compare_models() successfully completed......................................
2023-11-26 07:00:08,114:INFO:Initializing create_model()
2023-11-26 07:00:08,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:00:08,114:INFO:Checking exceptions
2023-11-26 07:00:08,115:INFO:Importing libraries
2023-11-26 07:00:08,115:INFO:Copying training dataset
2023-11-26 07:00:08,117:INFO:Defining folds
2023-11-26 07:00:08,117:INFO:Declaring metric variables
2023-11-26 07:00:08,117:INFO:Importing untrained model
2023-11-26 07:00:08,117:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 07:00:08,117:INFO:Starting cross validation
2023-11-26 07:00:08,118:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:00:08,156:INFO:Calculating mean and std
2023-11-26 07:00:08,156:INFO:Creating metrics dataframe
2023-11-26 07:00:08,157:INFO:Finalizing model
2023-11-26 07:00:08,160:INFO:Uploading results into container
2023-11-26 07:00:08,161:INFO:Uploading model into container now
2023-11-26 07:00:08,165:INFO:_master_model_container: 13
2023-11-26 07:00:08,165:INFO:_display_container: 3
2023-11-26 07:00:08,165:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:00:08,165:INFO:create_model() successfully completed......................................
2023-11-26 07:00:08,195:INFO:Initializing tune_model()
2023-11-26 07:00:08,196:INFO:tune_model(estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>)
2023-11-26 07:00:08,196:INFO:Checking exceptions
2023-11-26 07:00:08,197:INFO:Copying training dataset
2023-11-26 07:00:08,198:INFO:Checking base model
2023-11-26 07:00:08,198:INFO:Base model : Linear Discriminant Analysis
2023-11-26 07:00:08,198:INFO:Declaring metric variables
2023-11-26 07:00:08,199:INFO:Defining Hyperparameters
2023-11-26 07:00:08,226:INFO:Tuning with n_jobs=-1
2023-11-26 07:00:08,226:INFO:Initializing RandomizedSearchCV
2023-11-26 07:00:09,436:INFO:best_params: {'actual_estimator__solver': 'eigen', 'actual_estimator__shrinkage': 'auto'}
2023-11-26 07:00:09,437:INFO:Hyperparameter search completed
2023-11-26 07:00:09,437:INFO:SubProcess create_model() called ==================================
2023-11-26 07:00:09,438:INFO:Initializing create_model()
2023-11-26 07:00:09,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4687cf10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'eigen', 'shrinkage': 'auto'})
2023-11-26 07:00:09,438:INFO:Checking exceptions
2023-11-26 07:00:09,438:INFO:Importing libraries
2023-11-26 07:00:09,438:INFO:Copying training dataset
2023-11-26 07:00:09,441:INFO:Defining folds
2023-11-26 07:00:09,441:INFO:Declaring metric variables
2023-11-26 07:00:09,441:INFO:Importing untrained model
2023-11-26 07:00:09,441:INFO:Declaring custom model
2023-11-26 07:00:09,442:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 07:00:09,442:INFO:Starting cross validation
2023-11-26 07:00:09,442:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:00:09,510:INFO:Calculating mean and std
2023-11-26 07:00:09,510:INFO:Creating metrics dataframe
2023-11-26 07:00:09,514:INFO:Finalizing model
2023-11-26 07:00:09,519:INFO:Uploading results into container
2023-11-26 07:00:09,520:INFO:Uploading model into container now
2023-11-26 07:00:09,524:INFO:_master_model_container: 14
2023-11-26 07:00:09,524:INFO:_display_container: 4
2023-11-26 07:00:09,525:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:00:09,525:INFO:create_model() successfully completed......................................
2023-11-26 07:00:09,567:INFO:SubProcess create_model() end ==================================
2023-11-26 07:00:09,568:INFO:choose_better activated
2023-11-26 07:00:09,568:INFO:SubProcess create_model() called ==================================
2023-11-26 07:00:09,568:INFO:Initializing create_model()
2023-11-26 07:00:09,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:00:09,569:INFO:Checking exceptions
2023-11-26 07:00:09,569:INFO:Importing libraries
2023-11-26 07:00:09,569:INFO:Copying training dataset
2023-11-26 07:00:09,571:INFO:Defining folds
2023-11-26 07:00:09,571:INFO:Declaring metric variables
2023-11-26 07:00:09,571:INFO:Importing untrained model
2023-11-26 07:00:09,571:INFO:Declaring custom model
2023-11-26 07:00:09,571:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 07:00:09,571:INFO:Starting cross validation
2023-11-26 07:00:09,572:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:00:09,613:INFO:Calculating mean and std
2023-11-26 07:00:09,613:INFO:Creating metrics dataframe
2023-11-26 07:00:09,614:INFO:Finalizing model
2023-11-26 07:00:09,618:INFO:Uploading results into container
2023-11-26 07:00:09,618:INFO:Uploading model into container now
2023-11-26 07:00:09,618:INFO:_master_model_container: 15
2023-11-26 07:00:09,618:INFO:_display_container: 5
2023-11-26 07:00:09,618:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:00:09,619:INFO:create_model() successfully completed......................................
2023-11-26 07:00:09,649:INFO:SubProcess create_model() end ==================================
2023-11-26 07:00:09,650:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 1.0
2023-11-26 07:00:09,650:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001) result for AUC is 1.0
2023-11-26 07:00:09,650:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) is best model
2023-11-26 07:00:09,651:INFO:choose_better completed
2023-11-26 07:00:09,651:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-11-26 07:00:09,655:INFO:_master_model_container: 15
2023-11-26 07:00:09,655:INFO:_display_container: 4
2023-11-26 07:00:09,655:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:00:09,655:INFO:tune_model() successfully completed......................................
2023-11-26 07:00:09,681:INFO:Initializing evaluate_model()
2023-11-26 07:00:09,682:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-26 07:00:09,684:INFO:Initializing plot_model()
2023-11-26 07:00:09,685:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, system=True)
2023-11-26 07:00:09,685:INFO:Checking exceptions
2023-11-26 07:00:09,685:INFO:Preloading libraries
2023-11-26 07:00:09,685:INFO:Copying training dataset
2023-11-26 07:00:09,686:INFO:Plot type: pipeline
2023-11-26 07:00:09,725:INFO:Visual Rendered Successfully
2023-11-26 07:00:09,756:INFO:plot_model() successfully completed......................................
2023-11-26 07:00:09,759:INFO:Initializing finalize_model()
2023-11-26 07:00:09,760:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-11-26 07:00:09,760:INFO:Finalizing LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:00:09,763:INFO:Initializing create_model()
2023-11-26 07:00:09,765:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:00:09,765:INFO:Checking exceptions
2023-11-26 07:00:09,766:INFO:Importing libraries
2023-11-26 07:00:09,766:INFO:Copying training dataset
2023-11-26 07:00:09,767:INFO:Defining folds
2023-11-26 07:00:09,767:INFO:Declaring metric variables
2023-11-26 07:00:09,768:INFO:Importing untrained model
2023-11-26 07:00:09,768:INFO:Declaring custom model
2023-11-26 07:00:09,769:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 07:00:09,769:INFO:Cross validation set to False
2023-11-26 07:00:09,770:INFO:Fitting Model
2023-11-26 07:00:09,782:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 07:00:09,782:INFO:create_model() successfully completed......................................
2023-11-26 07:00:09,829:INFO:_master_model_container: 15
2023-11-26 07:00:09,829:INFO:_display_container: 4
2023-11-26 07:00:09,831:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 07:00:09,831:INFO:finalize_model() successfully completed......................................
2023-11-26 07:00:09,861:INFO:Initializing predict_model()
2023-11-26 07:00:09,861:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff81f91be0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff467a01f0>)
2023-11-26 07:00:09,861:INFO:Checking exceptions
2023-11-26 07:00:09,861:INFO:Preloading libraries
2023-11-26 07:01:06,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:06,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:06,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:06,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:06,920:INFO:PyCaret ClassificationExperiment
2023-11-26 07:01:06,921:INFO:Logging name: clf-default-name
2023-11-26 07:01:06,921:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-26 07:01:06,921:INFO:version 3.2.0
2023-11-26 07:01:06,921:INFO:Initializing setup()
2023-11-26 07:01:06,921:INFO:self.USI: e300
2023-11-26 07:01:06,921:INFO:self._variable_keys: {'html_param', 'n_jobs_param', 'seed', '_available_plots', 'idx', 'fold_groups_param', 'exp_name_log', 'X_test', 'log_plots_param', 'gpu_param', 'pipeline', 'logging_param', 'is_multiclass', 'y', 'exp_id', 'fold_shuffle_param', 'gpu_n_jobs_param', '_ml_usecase', 'X', 'X_train', 'fold_generator', 'target_param', 'fix_imbalance', 'memory', 'y_train', 'USI', 'y_test', 'data'}
2023-11-26 07:01:06,921:INFO:Checking environment
2023-11-26 07:01:06,921:INFO:python_version: 3.8.18
2023-11-26 07:01:06,922:INFO:python_build: ('default', 'Nov 21 2023 19:36:55')
2023-11-26 07:01:06,922:INFO:machine: aarch64
2023-11-26 07:01:06,922:INFO:platform: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 07:01:06,923:INFO:Memory: svmem(total=8225304576, available=7109480448, percent=13.6, used=907030528, free=3563986944, active=2007252992, inactive=2049032192, buffers=114913280, cached=3639373824, shared=1216512, slab=429899776)
2023-11-26 07:01:06,923:INFO:Physical Core: 12
2023-11-26 07:01:06,923:INFO:Logical Core: 12
2023-11-26 07:01:06,923:INFO:Checking libraries
2023-11-26 07:01:06,924:INFO:System:
2023-11-26 07:01:06,924:INFO:    python: 3.8.18 (default, Nov 21 2023, 19:36:55)  [GCC 12.2.0]
2023-11-26 07:01:06,924:INFO:executable: /usr/local/bin/python
2023-11-26 07:01:06,924:INFO:   machine: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 07:01:06,924:INFO:PyCaret required dependencies:
2023-11-26 07:01:06,932:INFO:                 pip: 23.3.1
2023-11-26 07:01:06,932:INFO:          setuptools: 57.5.0
2023-11-26 07:01:06,932:INFO:             pycaret: 3.2.0
2023-11-26 07:01:06,932:INFO:             IPython: 8.12.3
2023-11-26 07:01:06,932:INFO:          ipywidgets: 8.1.1
2023-11-26 07:01:06,932:INFO:                tqdm: 4.66.1
2023-11-26 07:01:06,932:INFO:               numpy: 1.24.4
2023-11-26 07:01:06,933:INFO:              pandas: 1.5.3
2023-11-26 07:01:06,933:INFO:              jinja2: 3.1.2
2023-11-26 07:01:06,933:INFO:               scipy: 1.10.1
2023-11-26 07:01:06,933:INFO:              joblib: 1.3.2
2023-11-26 07:01:06,933:INFO:             sklearn: 1.2.2
2023-11-26 07:01:06,933:INFO:                pyod: 1.1.2
2023-11-26 07:01:06,933:INFO:            imblearn: 0.11.0
2023-11-26 07:01:06,933:INFO:   category_encoders: 2.6.3
2023-11-26 07:01:06,933:INFO:            lightgbm: 4.1.0
2023-11-26 07:01:06,933:INFO:               numba: 0.58.1
2023-11-26 07:01:06,934:INFO:            requests: 2.31.0
2023-11-26 07:01:06,934:INFO:          matplotlib: 3.6.0
2023-11-26 07:01:06,934:INFO:          scikitplot: 0.3.7
2023-11-26 07:01:06,934:INFO:         yellowbrick: 1.5
2023-11-26 07:01:06,934:INFO:              plotly: 5.18.0
2023-11-26 07:01:06,934:INFO:    plotly-resampler: Not installed
2023-11-26 07:01:06,934:INFO:             kaleido: 0.2.1
2023-11-26 07:01:06,934:INFO:           schemdraw: 0.15
2023-11-26 07:01:06,934:INFO:         statsmodels: 0.14.0
2023-11-26 07:01:06,934:INFO:              sktime: 0.21.1
2023-11-26 07:01:06,935:INFO:               tbats: 1.1.3
2023-11-26 07:01:06,935:INFO:            pmdarima: 2.0.4
2023-11-26 07:01:06,935:INFO:              psutil: 5.9.6
2023-11-26 07:01:06,935:INFO:          markupsafe: 2.1.3
2023-11-26 07:01:06,935:INFO:             pickle5: Not installed
2023-11-26 07:01:06,935:INFO:         cloudpickle: 3.0.0
2023-11-26 07:01:06,935:INFO:         deprecation: 2.1.0
2023-11-26 07:01:06,935:INFO:              xxhash: 3.4.1
2023-11-26 07:01:06,935:INFO:           wurlitzer: 3.0.3
2023-11-26 07:01:06,936:INFO:PyCaret optional dependencies:
2023-11-26 07:01:06,946:INFO:                shap: Not installed
2023-11-26 07:01:06,946:INFO:           interpret: Not installed
2023-11-26 07:01:06,946:INFO:                umap: Not installed
2023-11-26 07:01:06,947:INFO:     ydata_profiling: Not installed
2023-11-26 07:01:06,947:INFO:  explainerdashboard: Not installed
2023-11-26 07:01:06,947:INFO:             autoviz: Not installed
2023-11-26 07:01:06,947:INFO:           fairlearn: Not installed
2023-11-26 07:01:06,947:INFO:          deepchecks: Not installed
2023-11-26 07:01:06,947:INFO:             xgboost: Not installed
2023-11-26 07:01:06,947:INFO:            catboost: Not installed
2023-11-26 07:01:06,947:INFO:              kmodes: Not installed
2023-11-26 07:01:06,947:INFO:             mlxtend: Not installed
2023-11-26 07:01:06,947:INFO:       statsforecast: Not installed
2023-11-26 07:01:06,948:INFO:        tune_sklearn: Not installed
2023-11-26 07:01:06,948:INFO:                 ray: Not installed
2023-11-26 07:01:06,948:INFO:            hyperopt: Not installed
2023-11-26 07:01:06,948:INFO:              optuna: Not installed
2023-11-26 07:01:06,948:INFO:               skopt: Not installed
2023-11-26 07:01:06,948:INFO:              mlflow: Not installed
2023-11-26 07:01:06,948:INFO:              gradio: Not installed
2023-11-26 07:01:06,948:INFO:             fastapi: Not installed
2023-11-26 07:01:06,948:INFO:             uvicorn: Not installed
2023-11-26 07:01:06,949:INFO:              m2cgen: Not installed
2023-11-26 07:01:06,949:INFO:           evidently: Not installed
2023-11-26 07:01:06,949:INFO:               fugue: Not installed
2023-11-26 07:01:06,949:INFO:           streamlit: Not installed
2023-11-26 07:01:06,949:INFO:             prophet: Not installed
2023-11-26 07:01:06,949:INFO:None
2023-11-26 07:01:06,949:INFO:Set up GPU usage.
2023-11-26 07:01:06,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:06,949:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-26 07:01:06,949:INFO:Set up data.
2023-11-26 07:01:06,952:INFO:Set up folding strategy.
2023-11-26 07:01:06,952:INFO:Set up train/test split.
2023-11-26 07:01:06,954:INFO:Set up index.
2023-11-26 07:01:06,954:INFO:Assigning column types.
2023-11-26 07:01:06,956:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-26 07:01:06,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:06,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 07:01:06,973:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:06,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:06,974:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 07:01:06,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:06,984:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:06,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:06,987:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:01:06,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:01:06,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,016:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 07:01:07,016:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,017:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,017:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 07:01:07,017:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,026:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:01:07,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:01:07,033:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-26 07:01:07,033:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,051:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 07:01:07,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,060:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,063:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:01:07,066:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:01:07,066:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,083:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 07:01:07,084:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,092:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:01:07,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:01:07,098:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-26 07:01:07,098:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,116:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,124:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,126:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:01:07,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:01:07,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,157:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,158:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:01:07,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:01:07,164:INFO:Preparing preprocessing pipeline...
2023-11-26 07:01:07,165:INFO:Set up simple imputation.
2023-11-26 07:01:07,174:INFO:Finished creating preprocessing pipeline.
2023-11-26 07:01:07,176:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-26 07:01:07,176:INFO:Creating final display dataframe.
2023-11-26 07:01:07,199:INFO:Setup _display_container:                     Description             Value
0                    Session id              3182
1                        Target            target
2                   Target type            Binary
3           Original data shape         (210, 13)
4        Transformed data shape         (210, 13)
5   Transformed train set shape         (147, 13)
6    Transformed test set shape          (63, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              e300
2023-11-26 07:01:07,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,230:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:01:07,236:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:01:07,237:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,254:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,255:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,255:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,264:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,265:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:01:07,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:01:07,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:01:07,271:INFO:setup() successfully completed in 0.35s...............
2023-11-26 07:01:10,486:INFO:Initializing compare_models()
2023-11-26 07:01:10,487:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-26 07:01:10,487:INFO:Checking exceptions
2023-11-26 07:01:10,491:INFO:Preparing display monitor
2023-11-26 07:01:10,496:INFO:Initializing Logistic Regression
2023-11-26 07:01:10,497:INFO:Total runtime is 1.022020975748698e-05 minutes
2023-11-26 07:01:10,497:INFO:SubProcess create_model() called ==================================
2023-11-26 07:01:10,498:INFO:Initializing create_model()
2023-11-26 07:01:10,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff53410430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:01:10,498:INFO:Checking exceptions
2023-11-26 07:01:10,499:INFO:Importing libraries
2023-11-26 07:01:10,499:INFO:Copying training dataset
2023-11-26 07:01:10,503:INFO:Defining folds
2023-11-26 07:01:10,503:INFO:Declaring metric variables
2023-11-26 07:01:10,504:INFO:Importing untrained model
2023-11-26 07:01:10,505:INFO:Logistic Regression Imported successfully
2023-11-26 07:01:10,505:INFO:Starting cross validation
2023-11-26 07:01:10,506:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:01:10,581:INFO:Calculating mean and std
2023-11-26 07:01:10,582:INFO:Creating metrics dataframe
2023-11-26 07:01:10,583:INFO:Uploading results into container
2023-11-26 07:01:10,584:INFO:Uploading model into container now
2023-11-26 07:01:10,584:INFO:_master_model_container: 1
2023-11-26 07:01:10,584:INFO:_display_container: 2
2023-11-26 07:01:10,584:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3182, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-26 07:01:10,584:INFO:create_model() successfully completed......................................
2023-11-26 07:01:10,622:INFO:SubProcess create_model() end ==================================
2023-11-26 07:01:10,623:INFO:Creating metrics dataframe
2023-11-26 07:01:10,625:INFO:Initializing K Neighbors Classifier
2023-11-26 07:01:10,625:INFO:Total runtime is 0.0021501938501993817 minutes
2023-11-26 07:01:10,626:INFO:SubProcess create_model() called ==================================
2023-11-26 07:01:10,626:INFO:Initializing create_model()
2023-11-26 07:01:10,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff53410430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:01:10,626:INFO:Checking exceptions
2023-11-26 07:01:10,626:INFO:Importing libraries
2023-11-26 07:01:10,626:INFO:Copying training dataset
2023-11-26 07:01:10,628:INFO:Defining folds
2023-11-26 07:01:10,628:INFO:Declaring metric variables
2023-11-26 07:01:10,628:INFO:Importing untrained model
2023-11-26 07:01:10,629:INFO:K Neighbors Classifier Imported successfully
2023-11-26 07:01:10,629:INFO:Starting cross validation
2023-11-26 07:01:10,629:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:01:10,806:INFO:Calculating mean and std
2023-11-26 07:01:10,807:INFO:Creating metrics dataframe
2023-11-26 07:01:10,808:INFO:Uploading results into container
2023-11-26 07:01:10,809:INFO:Uploading model into container now
2023-11-26 07:01:10,809:INFO:_master_model_container: 2
2023-11-26 07:01:10,809:INFO:_display_container: 2
2023-11-26 07:01:10,809:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-26 07:01:10,809:INFO:create_model() successfully completed......................................
2023-11-26 07:01:10,842:INFO:SubProcess create_model() end ==================================
2023-11-26 07:01:10,842:INFO:Creating metrics dataframe
2023-11-26 07:01:10,845:INFO:Initializing Naive Bayes
2023-11-26 07:01:10,845:INFO:Total runtime is 0.005811301867167155 minutes
2023-11-26 07:01:10,845:INFO:SubProcess create_model() called ==================================
2023-11-26 07:01:10,846:INFO:Initializing create_model()
2023-11-26 07:01:10,846:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff53410430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:01:10,846:INFO:Checking exceptions
2023-11-26 07:01:10,846:INFO:Importing libraries
2023-11-26 07:01:10,846:INFO:Copying training dataset
2023-11-26 07:01:10,847:INFO:Defining folds
2023-11-26 07:01:10,847:INFO:Declaring metric variables
2023-11-26 07:01:10,848:INFO:Importing untrained model
2023-11-26 07:01:10,848:INFO:Naive Bayes Imported successfully
2023-11-26 07:01:10,848:INFO:Starting cross validation
2023-11-26 07:01:10,848:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:01:10,886:INFO:Calculating mean and std
2023-11-26 07:01:10,887:INFO:Creating metrics dataframe
2023-11-26 07:01:10,888:INFO:Uploading results into container
2023-11-26 07:01:10,889:INFO:Uploading model into container now
2023-11-26 07:01:10,889:INFO:_master_model_container: 3
2023-11-26 07:01:10,889:INFO:_display_container: 2
2023-11-26 07:01:10,889:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-26 07:01:10,889:INFO:create_model() successfully completed......................................
2023-11-26 07:01:10,918:INFO:SubProcess create_model() end ==================================
2023-11-26 07:01:10,919:INFO:Creating metrics dataframe
2023-11-26 07:01:10,921:INFO:Initializing Decision Tree Classifier
2023-11-26 07:01:10,921:INFO:Total runtime is 0.007076859474182129 minutes
2023-11-26 07:01:10,921:INFO:SubProcess create_model() called ==================================
2023-11-26 07:01:10,921:INFO:Initializing create_model()
2023-11-26 07:01:10,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff53410430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:01:10,922:INFO:Checking exceptions
2023-11-26 07:01:10,922:INFO:Importing libraries
2023-11-26 07:01:10,922:INFO:Copying training dataset
2023-11-26 07:01:10,923:INFO:Defining folds
2023-11-26 07:01:10,923:INFO:Declaring metric variables
2023-11-26 07:01:10,923:INFO:Importing untrained model
2023-11-26 07:01:10,924:INFO:Decision Tree Classifier Imported successfully
2023-11-26 07:01:10,924:INFO:Starting cross validation
2023-11-26 07:01:10,924:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:01:10,963:INFO:Calculating mean and std
2023-11-26 07:01:10,964:INFO:Creating metrics dataframe
2023-11-26 07:01:10,965:INFO:Uploading results into container
2023-11-26 07:01:10,965:INFO:Uploading model into container now
2023-11-26 07:01:10,965:INFO:_master_model_container: 4
2023-11-26 07:01:10,966:INFO:_display_container: 2
2023-11-26 07:01:10,966:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3182, splitter='best')
2023-11-26 07:01:10,966:INFO:create_model() successfully completed......................................
2023-11-26 07:01:10,993:INFO:SubProcess create_model() end ==================================
2023-11-26 07:01:10,993:INFO:Creating metrics dataframe
2023-11-26 07:01:10,995:INFO:Initializing SVM - Linear Kernel
2023-11-26 07:01:10,996:INFO:Total runtime is 0.008318932851155598 minutes
2023-11-26 07:01:10,996:INFO:SubProcess create_model() called ==================================
2023-11-26 07:01:10,996:INFO:Initializing create_model()
2023-11-26 07:01:10,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff53410430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:01:10,996:INFO:Checking exceptions
2023-11-26 07:01:10,996:INFO:Importing libraries
2023-11-26 07:01:10,996:INFO:Copying training dataset
2023-11-26 07:01:10,998:INFO:Defining folds
2023-11-26 07:01:10,998:INFO:Declaring metric variables
2023-11-26 07:01:10,998:INFO:Importing untrained model
2023-11-26 07:01:10,998:INFO:SVM - Linear Kernel Imported successfully
2023-11-26 07:01:10,999:INFO:Starting cross validation
2023-11-26 07:01:10,999:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:01:11,005:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 07:01:11,012:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 07:01:11,019:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 07:01:11,026:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 07:01:11,033:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 07:01:11,036:INFO:Calculating mean and std
2023-11-26 07:01:11,036:INFO:Creating metrics dataframe
2023-11-26 07:01:11,037:INFO:Uploading results into container
2023-11-26 07:01:11,037:INFO:Uploading model into container now
2023-11-26 07:01:11,038:INFO:_master_model_container: 5
2023-11-26 07:01:11,038:INFO:_display_container: 2
2023-11-26 07:01:11,038:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3182, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-26 07:01:11,038:INFO:create_model() successfully completed......................................
2023-11-26 07:01:11,065:INFO:SubProcess create_model() end ==================================
2023-11-26 07:01:11,066:INFO:Creating metrics dataframe
2023-11-26 07:01:11,068:INFO:Initializing Ridge Classifier
2023-11-26 07:01:11,068:INFO:Total runtime is 0.009523709615071613 minutes
2023-11-26 07:01:11,068:INFO:SubProcess create_model() called ==================================
2023-11-26 07:01:11,068:INFO:Initializing create_model()
2023-11-26 07:01:11,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff53410430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:01:11,069:INFO:Checking exceptions
2023-11-26 07:01:11,069:INFO:Importing libraries
2023-11-26 07:01:11,069:INFO:Copying training dataset
2023-11-26 07:01:11,070:INFO:Defining folds
2023-11-26 07:01:11,070:INFO:Declaring metric variables
2023-11-26 07:01:11,070:INFO:Importing untrained model
2023-11-26 07:01:11,070:INFO:Ridge Classifier Imported successfully
2023-11-26 07:01:11,070:INFO:Starting cross validation
2023-11-26 07:01:11,071:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:01:11,077:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 07:01:11,084:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 07:01:11,091:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 07:01:11,098:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 07:01:11,105:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 07:01:11,107:INFO:Calculating mean and std
2023-11-26 07:01:11,108:INFO:Creating metrics dataframe
2023-11-26 07:01:11,109:INFO:Uploading results into container
2023-11-26 07:01:11,109:INFO:Uploading model into container now
2023-11-26 07:01:11,110:INFO:_master_model_container: 6
2023-11-26 07:01:11,110:INFO:_display_container: 2
2023-11-26 07:01:11,110:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3182, solver='auto',
                tol=0.0001)
2023-11-26 07:01:11,110:INFO:create_model() successfully completed......................................
2023-11-26 07:01:11,137:INFO:SubProcess create_model() end ==================================
2023-11-26 07:01:11,137:INFO:Creating metrics dataframe
2023-11-26 07:01:11,139:INFO:Initializing Quadratic Discriminant Analysis
2023-11-26 07:01:11,140:INFO:Total runtime is 0.010719780127207437 minutes
2023-11-26 07:01:11,140:INFO:SubProcess create_model() called ==================================
2023-11-26 07:01:11,140:INFO:Initializing create_model()
2023-11-26 07:01:11,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff53410430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:01:11,140:INFO:Checking exceptions
2023-11-26 07:01:11,140:INFO:Importing libraries
2023-11-26 07:01:11,141:INFO:Copying training dataset
2023-11-26 07:01:11,142:INFO:Defining folds
2023-11-26 07:01:11,142:INFO:Declaring metric variables
2023-11-26 07:01:11,142:INFO:Importing untrained model
2023-11-26 07:01:11,142:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-26 07:01:11,143:INFO:Starting cross validation
2023-11-26 07:01:11,143:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:01:11,180:INFO:Calculating mean and std
2023-11-26 07:01:11,180:INFO:Creating metrics dataframe
2023-11-26 07:01:11,182:INFO:Uploading results into container
2023-11-26 07:01:11,182:INFO:Uploading model into container now
2023-11-26 07:01:11,182:INFO:_master_model_container: 7
2023-11-26 07:01:11,182:INFO:_display_container: 2
2023-11-26 07:01:11,182:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-26 07:01:11,182:INFO:create_model() successfully completed......................................
2023-11-26 07:01:11,209:INFO:SubProcess create_model() end ==================================
2023-11-26 07:01:11,209:INFO:Creating metrics dataframe
2023-11-26 07:01:11,212:INFO:Initializing Ada Boost Classifier
2023-11-26 07:01:11,212:INFO:Total runtime is 0.011920034885406494 minutes
2023-11-26 07:01:11,212:INFO:SubProcess create_model() called ==================================
2023-11-26 07:01:11,212:INFO:Initializing create_model()
2023-11-26 07:01:11,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff53410430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:01:11,212:INFO:Checking exceptions
2023-11-26 07:01:11,212:INFO:Importing libraries
2023-11-26 07:01:11,213:INFO:Copying training dataset
2023-11-26 07:01:11,214:INFO:Defining folds
2023-11-26 07:01:11,214:INFO:Declaring metric variables
2023-11-26 07:01:11,214:INFO:Importing untrained model
2023-11-26 07:01:11,214:INFO:Ada Boost Classifier Imported successfully
2023-11-26 07:01:11,215:INFO:Starting cross validation
2023-11-26 07:01:11,215:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:01:11,392:INFO:Calculating mean and std
2023-11-26 07:01:11,393:INFO:Creating metrics dataframe
2023-11-26 07:01:11,394:INFO:Uploading results into container
2023-11-26 07:01:11,394:INFO:Uploading model into container now
2023-11-26 07:01:11,395:INFO:_master_model_container: 8
2023-11-26 07:01:11,395:INFO:_display_container: 2
2023-11-26 07:01:11,395:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=3182)
2023-11-26 07:01:11,395:INFO:create_model() successfully completed......................................
2023-11-26 07:01:11,423:INFO:SubProcess create_model() end ==================================
2023-11-26 07:01:11,423:INFO:Creating metrics dataframe
2023-11-26 07:01:11,425:INFO:Initializing Linear Discriminant Analysis
2023-11-26 07:01:11,425:INFO:Total runtime is 0.015482866764068603 minutes
2023-11-26 07:01:11,426:INFO:SubProcess create_model() called ==================================
2023-11-26 07:01:11,426:INFO:Initializing create_model()
2023-11-26 07:01:11,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff53410430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:01:11,426:INFO:Checking exceptions
2023-11-26 07:01:11,426:INFO:Importing libraries
2023-11-26 07:01:11,426:INFO:Copying training dataset
2023-11-26 07:01:11,427:INFO:Defining folds
2023-11-26 07:01:11,428:INFO:Declaring metric variables
2023-11-26 07:01:11,428:INFO:Importing untrained model
2023-11-26 07:01:11,428:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 07:01:11,428:INFO:Starting cross validation
2023-11-26 07:01:11,429:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:01:11,466:INFO:Calculating mean and std
2023-11-26 07:01:11,467:INFO:Creating metrics dataframe
2023-11-26 07:01:11,468:INFO:Uploading results into container
2023-11-26 07:01:11,468:INFO:Uploading model into container now
2023-11-26 07:01:11,469:INFO:_master_model_container: 9
2023-11-26 07:01:11,469:INFO:_display_container: 2
2023-11-26 07:01:11,469:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:01:11,469:INFO:create_model() successfully completed......................................
2023-11-26 07:01:11,496:INFO:SubProcess create_model() end ==================================
2023-11-26 07:01:11,496:INFO:Creating metrics dataframe
2023-11-26 07:01:11,499:INFO:Initializing Extra Trees Classifier
2023-11-26 07:01:11,499:INFO:Total runtime is 0.0167088786760966 minutes
2023-11-26 07:01:11,499:INFO:SubProcess create_model() called ==================================
2023-11-26 07:01:11,499:INFO:Initializing create_model()
2023-11-26 07:01:11,500:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff53410430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:01:11,500:INFO:Checking exceptions
2023-11-26 07:01:11,500:INFO:Importing libraries
2023-11-26 07:01:11,500:INFO:Copying training dataset
2023-11-26 07:01:11,501:INFO:Defining folds
2023-11-26 07:01:11,501:INFO:Declaring metric variables
2023-11-26 07:01:11,502:INFO:Importing untrained model
2023-11-26 07:01:11,502:INFO:Extra Trees Classifier Imported successfully
2023-11-26 07:01:11,502:INFO:Starting cross validation
2023-11-26 07:01:11,502:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:01:12,177:INFO:Calculating mean and std
2023-11-26 07:01:12,177:INFO:Creating metrics dataframe
2023-11-26 07:01:12,179:INFO:Uploading results into container
2023-11-26 07:01:12,179:INFO:Uploading model into container now
2023-11-26 07:01:12,179:INFO:_master_model_container: 10
2023-11-26 07:01:12,179:INFO:_display_container: 2
2023-11-26 07:01:12,180:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3182, verbose=0, warm_start=False)
2023-11-26 07:01:12,180:INFO:create_model() successfully completed......................................
2023-11-26 07:01:12,210:INFO:SubProcess create_model() end ==================================
2023-11-26 07:01:12,211:INFO:Creating metrics dataframe
2023-11-26 07:01:12,213:INFO:Initializing Light Gradient Boosting Machine
2023-11-26 07:01:12,213:INFO:Total runtime is 0.028614620367685955 minutes
2023-11-26 07:01:12,214:INFO:SubProcess create_model() called ==================================
2023-11-26 07:01:12,214:INFO:Initializing create_model()
2023-11-26 07:01:12,214:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff53410430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:01:12,214:INFO:Checking exceptions
2023-11-26 07:01:12,214:INFO:Importing libraries
2023-11-26 07:01:12,214:INFO:Copying training dataset
2023-11-26 07:01:12,215:INFO:Defining folds
2023-11-26 07:01:12,216:INFO:Declaring metric variables
2023-11-26 07:01:12,216:INFO:Importing untrained model
2023-11-26 07:01:12,216:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-26 07:01:12,216:INFO:Starting cross validation
2023-11-26 07:01:12,217:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:01:12,222:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 07:01:12,224:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001765 seconds.
2023-11-26 07:01:12,225:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 07:01:12,225:INFO:[LightGBM] [Info] Total Bins 489
2023-11-26 07:01:12,225:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 07:01:12,225:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 07:01:12,226:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 07:01:12,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,276:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 07:01:12,276:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.
2023-11-26 07:01:12,276:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 07:01:12,276:INFO:[LightGBM] [Info] Total Bins 488
2023-11-26 07:01:12,277:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 07:01:12,277:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 07:01:12,277:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 07:01:12,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,371:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 60
2023-11-26 07:01:12,372:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.
2023-11-26 07:01:12,372:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 07:01:12,372:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 07:01:12,372:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 07:01:12,372:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491525 -> initscore=-0.033902
2023-11-26 07:01:12,373:INFO:[LightGBM] [Info] Start training from score -0.033902
2023-11-26 07:01:12,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf

2023-11-26 07:01:12,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,459:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 07:01:12,459:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000035 seconds.
2023-11-26 07:01:12,460:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 07:01:12,460:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 07:01:12,460:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 07:01:12,460:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 07:01:12,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,498:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,518:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 07:01:12,518:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.
2023-11-26 07:01:12,518:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 07:01:12,518:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 07:01:12,518:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 07:01:12,519:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 07:01:12,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:01:12,643:INFO:Calculating mean and std
2023-11-26 07:01:12,644:INFO:Creating metrics dataframe
2023-11-26 07:01:12,645:INFO:Uploading results into container
2023-11-26 07:01:12,646:INFO:Uploading model into container now
2023-11-26 07:01:12,646:INFO:_master_model_container: 11
2023-11-26 07:01:12,646:INFO:_display_container: 2
2023-11-26 07:01:12,646:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3182, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-26 07:01:12,647:INFO:create_model() successfully completed......................................
2023-11-26 07:01:12,677:INFO:SubProcess create_model() end ==================================
2023-11-26 07:01:12,678:INFO:Creating metrics dataframe
2023-11-26 07:01:12,680:INFO:Initializing Dummy Classifier
2023-11-26 07:01:12,680:INFO:Total runtime is 0.0363935391108195 minutes
2023-11-26 07:01:12,680:INFO:SubProcess create_model() called ==================================
2023-11-26 07:01:12,680:INFO:Initializing create_model()
2023-11-26 07:01:12,681:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff53410430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:01:12,681:INFO:Checking exceptions
2023-11-26 07:01:12,681:INFO:Importing libraries
2023-11-26 07:01:12,681:INFO:Copying training dataset
2023-11-26 07:01:12,682:INFO:Defining folds
2023-11-26 07:01:12,682:INFO:Declaring metric variables
2023-11-26 07:01:12,683:INFO:Importing untrained model
2023-11-26 07:01:12,683:INFO:Dummy Classifier Imported successfully
2023-11-26 07:01:12,683:INFO:Starting cross validation
2023-11-26 07:01:12,683:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:01:12,690:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 07:01:12,697:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 07:01:12,703:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 07:01:12,709:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 07:01:12,716:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 07:01:12,717:INFO:Calculating mean and std
2023-11-26 07:01:12,718:INFO:Creating metrics dataframe
2023-11-26 07:01:12,719:INFO:Uploading results into container
2023-11-26 07:01:12,719:INFO:Uploading model into container now
2023-11-26 07:01:12,719:INFO:_master_model_container: 12
2023-11-26 07:01:12,719:INFO:_display_container: 2
2023-11-26 07:01:12,720:INFO:DummyClassifier(constant=None, random_state=3182, strategy='prior')
2023-11-26 07:01:12,720:INFO:create_model() successfully completed......................................
2023-11-26 07:01:12,747:INFO:SubProcess create_model() end ==================================
2023-11-26 07:01:12,747:INFO:Creating metrics dataframe
2023-11-26 07:01:12,750:INFO:Initializing create_model()
2023-11-26 07:01:12,751:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3182, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:01:12,751:INFO:Checking exceptions
2023-11-26 07:01:12,751:INFO:Importing libraries
2023-11-26 07:01:12,751:INFO:Copying training dataset
2023-11-26 07:01:12,752:INFO:Defining folds
2023-11-26 07:01:12,753:INFO:Declaring metric variables
2023-11-26 07:01:12,753:INFO:Importing untrained model
2023-11-26 07:01:12,753:INFO:Declaring custom model
2023-11-26 07:01:12,753:INFO:SVM - Linear Kernel Imported successfully
2023-11-26 07:01:12,754:INFO:Cross validation set to False
2023-11-26 07:01:12,754:INFO:Fitting Model
2023-11-26 07:01:12,757:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3182, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-26 07:01:12,757:INFO:create_model() successfully completed......................................
2023-11-26 07:01:12,789:INFO:_master_model_container: 12
2023-11-26 07:01:12,789:INFO:_display_container: 2
2023-11-26 07:01:12,789:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3182, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-26 07:01:12,789:INFO:compare_models() successfully completed......................................
2023-11-26 07:01:38,950:INFO:Initializing create_model()
2023-11-26 07:01:38,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:01:38,951:INFO:Checking exceptions
2023-11-26 07:01:38,955:INFO:Importing libraries
2023-11-26 07:01:38,955:INFO:Copying training dataset
2023-11-26 07:01:38,960:INFO:Defining folds
2023-11-26 07:01:38,961:INFO:Declaring metric variables
2023-11-26 07:01:38,961:INFO:Importing untrained model
2023-11-26 07:01:38,962:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 07:01:38,963:INFO:Starting cross validation
2023-11-26 07:01:38,965:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:01:39,027:INFO:Calculating mean and std
2023-11-26 07:01:39,027:INFO:Creating metrics dataframe
2023-11-26 07:01:39,028:INFO:Finalizing model
2023-11-26 07:01:39,033:INFO:Uploading results into container
2023-11-26 07:01:39,033:INFO:Uploading model into container now
2023-11-26 07:01:39,037:INFO:_master_model_container: 13
2023-11-26 07:01:39,037:INFO:_display_container: 3
2023-11-26 07:01:39,037:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:01:39,037:INFO:create_model() successfully completed......................................
2023-11-26 07:02:02,052:INFO:Initializing tune_model()
2023-11-26 07:02:02,053:INFO:tune_model(estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>)
2023-11-26 07:02:02,053:INFO:Checking exceptions
2023-11-26 07:02:02,057:INFO:Copying training dataset
2023-11-26 07:02:02,060:INFO:Checking base model
2023-11-26 07:02:02,061:INFO:Base model : Linear Discriminant Analysis
2023-11-26 07:02:02,062:INFO:Declaring metric variables
2023-11-26 07:02:02,062:INFO:Defining Hyperparameters
2023-11-26 07:02:02,124:INFO:Tuning with n_jobs=-1
2023-11-26 07:02:02,125:INFO:Initializing RandomizedSearchCV
2023-11-26 07:02:03,190:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
5 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 571, in fit
    self._validate_params()
  File "/usr/local/lib/python3.8/site-packages/sklearn/base.py", line 600, in _validate_params
    validate_parameter_constraints(
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'shrinkage' parameter of LinearDiscriminantAnalysis must be a str among {'auto'}, a float in the range [0, 1] or None. Got 'empirical' instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-11-26 07:02:03,191:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.99079365 0.99079365        nan 0.99822222 0.99822222 0.99822222
 0.99911111 0.99911111 0.99726984 0.9935873 ]
  warnings.warn(

2023-11-26 07:02:03,192:INFO:best_params: {'actual_estimator__solver': 'eigen', 'actual_estimator__shrinkage': 0.1}
2023-11-26 07:02:03,192:INFO:Hyperparameter search completed
2023-11-26 07:02:03,192:INFO:SubProcess create_model() called ==================================
2023-11-26 07:02:03,193:INFO:Initializing create_model()
2023-11-26 07:02:03,193:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4b394c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'eigen', 'shrinkage': 0.1})
2023-11-26 07:02:03,193:INFO:Checking exceptions
2023-11-26 07:02:03,193:INFO:Importing libraries
2023-11-26 07:02:03,193:INFO:Copying training dataset
2023-11-26 07:02:03,195:INFO:Defining folds
2023-11-26 07:02:03,195:INFO:Declaring metric variables
2023-11-26 07:02:03,195:INFO:Importing untrained model
2023-11-26 07:02:03,196:INFO:Declaring custom model
2023-11-26 07:02:03,196:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 07:02:03,196:INFO:Starting cross validation
2023-11-26 07:02:03,197:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:02:03,247:INFO:Calculating mean and std
2023-11-26 07:02:03,248:INFO:Creating metrics dataframe
2023-11-26 07:02:03,251:INFO:Finalizing model
2023-11-26 07:02:03,262:INFO:Uploading results into container
2023-11-26 07:02:03,263:INFO:Uploading model into container now
2023-11-26 07:02:03,266:INFO:_master_model_container: 14
2023-11-26 07:02:03,267:INFO:_display_container: 4
2023-11-26 07:02:03,270:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:02:03,270:INFO:create_model() successfully completed......................................
2023-11-26 07:02:03,308:INFO:SubProcess create_model() end ==================================
2023-11-26 07:02:03,308:INFO:choose_better activated
2023-11-26 07:02:03,308:INFO:SubProcess create_model() called ==================================
2023-11-26 07:02:03,308:INFO:Initializing create_model()
2023-11-26 07:02:03,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:02:03,309:INFO:Checking exceptions
2023-11-26 07:02:03,309:INFO:Importing libraries
2023-11-26 07:02:03,309:INFO:Copying training dataset
2023-11-26 07:02:03,311:INFO:Defining folds
2023-11-26 07:02:03,311:INFO:Declaring metric variables
2023-11-26 07:02:03,311:INFO:Importing untrained model
2023-11-26 07:02:03,311:INFO:Declaring custom model
2023-11-26 07:02:03,311:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 07:02:03,312:INFO:Starting cross validation
2023-11-26 07:02:03,312:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:02:03,351:INFO:Calculating mean and std
2023-11-26 07:02:03,352:INFO:Creating metrics dataframe
2023-11-26 07:02:03,352:INFO:Finalizing model
2023-11-26 07:02:03,356:INFO:Uploading results into container
2023-11-26 07:02:03,356:INFO:Uploading model into container now
2023-11-26 07:02:03,357:INFO:_master_model_container: 15
2023-11-26 07:02:03,357:INFO:_display_container: 5
2023-11-26 07:02:03,357:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:02:03,357:INFO:create_model() successfully completed......................................
2023-11-26 07:02:03,386:INFO:SubProcess create_model() end ==================================
2023-11-26 07:02:03,387:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9982
2023-11-26 07:02:03,387:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9991
2023-11-26 07:02:03,387:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001) is best model
2023-11-26 07:02:03,387:INFO:choose_better completed
2023-11-26 07:02:03,391:INFO:_master_model_container: 15
2023-11-26 07:02:03,391:INFO:_display_container: 4
2023-11-26 07:02:03,391:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:02:03,392:INFO:tune_model() successfully completed......................................
2023-11-26 07:02:20,666:INFO:Initializing evaluate_model()
2023-11-26 07:02:20,666:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-26 07:02:20,674:INFO:Initializing plot_model()
2023-11-26 07:02:20,675:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, system=True)
2023-11-26 07:02:20,675:INFO:Checking exceptions
2023-11-26 07:02:20,677:INFO:Preloading libraries
2023-11-26 07:02:20,677:INFO:Copying training dataset
2023-11-26 07:02:20,677:INFO:Plot type: pipeline
2023-11-26 07:02:20,731:INFO:Visual Rendered Successfully
2023-11-26 07:02:20,769:INFO:plot_model() successfully completed......................................
2023-11-26 07:17:00,947:INFO:Initializing finalize_model()
2023-11-26 07:17:00,949:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-11-26 07:17:00,951:INFO:Finalizing LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:17:00,968:INFO:Initializing create_model()
2023-11-26 07:17:00,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:17:00,969:INFO:Checking exceptions
2023-11-26 07:17:00,972:INFO:Importing libraries
2023-11-26 07:17:00,972:INFO:Copying training dataset
2023-11-26 07:17:00,973:INFO:Defining folds
2023-11-26 07:17:00,973:INFO:Declaring metric variables
2023-11-26 07:17:00,974:INFO:Importing untrained model
2023-11-26 07:17:00,974:INFO:Declaring custom model
2023-11-26 07:17:00,975:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 07:17:00,977:INFO:Cross validation set to False
2023-11-26 07:17:00,977:INFO:Fitting Model
2023-11-26 07:17:00,999:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 07:17:00,999:INFO:create_model() successfully completed......................................
2023-11-26 07:17:01,091:INFO:_master_model_container: 15
2023-11-26 07:17:01,092:INFO:_display_container: 4
2023-11-26 07:17:01,094:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 07:17:01,094:INFO:finalize_model() successfully completed......................................
2023-11-26 07:17:12,394:INFO:Initializing predict_model()
2023-11-26 07:17:12,396:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff536e9f70>)
2023-11-26 07:17:12,396:INFO:Checking exceptions
2023-11-26 07:17:12,396:INFO:Preloading libraries
2023-11-26 07:23:59,917:INFO:Initializing predict_model()
2023-11-26 07:23:59,920:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff909f61c0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff536bf790>)
2023-11-26 07:23:59,920:INFO:Checking exceptions
2023-11-26 07:23:59,920:INFO:Preloading libraries
2023-11-26 07:24:18,699:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:18,699:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:18,699:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:18,699:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:18,980:INFO:PyCaret ClassificationExperiment
2023-11-26 07:24:18,981:INFO:Logging name: clf-default-name
2023-11-26 07:24:18,981:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-26 07:24:18,981:INFO:version 3.2.0
2023-11-26 07:24:18,981:INFO:Initializing setup()
2023-11-26 07:24:18,981:INFO:self.USI: 5199
2023-11-26 07:24:18,981:INFO:self._variable_keys: {'X_test', 'gpu_n_jobs_param', 'target_param', 'data', 'logging_param', 'exp_id', 'n_jobs_param', 'seed', 'exp_name_log', 'X', 'memory', 'USI', 'fold_generator', 'X_train', 'fold_groups_param', 'y_test', 'fold_shuffle_param', 'html_param', 'y', 'gpu_param', 'is_multiclass', 'log_plots_param', 'pipeline', 'fix_imbalance', 'y_train', '_available_plots', '_ml_usecase', 'idx'}
2023-11-26 07:24:18,981:INFO:Checking environment
2023-11-26 07:24:18,981:INFO:python_version: 3.8.18
2023-11-26 07:24:18,982:INFO:python_build: ('default', 'Nov 21 2023 19:36:55')
2023-11-26 07:24:18,982:INFO:machine: aarch64
2023-11-26 07:24:18,983:INFO:platform: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 07:24:18,983:INFO:Memory: svmem(total=8225304576, available=7106064384, percent=13.6, used=910323712, free=3560423424, active=2014285824, inactive=2040385536, buffers=115048448, cached=3639508992, shared=1339392, slab=430477312)
2023-11-26 07:24:18,984:INFO:Physical Core: 12
2023-11-26 07:24:18,984:INFO:Logical Core: 12
2023-11-26 07:24:18,984:INFO:Checking libraries
2023-11-26 07:24:18,984:INFO:System:
2023-11-26 07:24:18,984:INFO:    python: 3.8.18 (default, Nov 21 2023, 19:36:55)  [GCC 12.2.0]
2023-11-26 07:24:18,984:INFO:executable: /usr/local/bin/python
2023-11-26 07:24:18,984:INFO:   machine: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 07:24:18,984:INFO:PyCaret required dependencies:
2023-11-26 07:24:18,994:INFO:                 pip: 23.3.1
2023-11-26 07:24:18,994:INFO:          setuptools: 57.5.0
2023-11-26 07:24:18,995:INFO:             pycaret: 3.2.0
2023-11-26 07:24:18,995:INFO:             IPython: 8.12.3
2023-11-26 07:24:18,995:INFO:          ipywidgets: 8.1.1
2023-11-26 07:24:18,995:INFO:                tqdm: 4.66.1
2023-11-26 07:24:18,995:INFO:               numpy: 1.24.4
2023-11-26 07:24:18,995:INFO:              pandas: 1.5.3
2023-11-26 07:24:18,995:INFO:              jinja2: 3.1.2
2023-11-26 07:24:18,995:INFO:               scipy: 1.10.1
2023-11-26 07:24:18,996:INFO:              joblib: 1.3.2
2023-11-26 07:24:18,996:INFO:             sklearn: 1.2.2
2023-11-26 07:24:18,996:INFO:                pyod: 1.1.2
2023-11-26 07:24:18,996:INFO:            imblearn: 0.11.0
2023-11-26 07:24:18,996:INFO:   category_encoders: 2.6.3
2023-11-26 07:24:18,996:INFO:            lightgbm: 4.1.0
2023-11-26 07:24:18,996:INFO:               numba: 0.58.1
2023-11-26 07:24:18,996:INFO:            requests: 2.31.0
2023-11-26 07:24:18,996:INFO:          matplotlib: 3.6.0
2023-11-26 07:24:18,996:INFO:          scikitplot: 0.3.7
2023-11-26 07:24:18,997:INFO:         yellowbrick: 1.5
2023-11-26 07:24:18,997:INFO:              plotly: 5.18.0
2023-11-26 07:24:18,997:INFO:    plotly-resampler: Not installed
2023-11-26 07:24:18,997:INFO:             kaleido: 0.2.1
2023-11-26 07:24:18,997:INFO:           schemdraw: 0.15
2023-11-26 07:24:18,997:INFO:         statsmodels: 0.14.0
2023-11-26 07:24:18,997:INFO:              sktime: 0.21.1
2023-11-26 07:24:18,997:INFO:               tbats: 1.1.3
2023-11-26 07:24:18,997:INFO:            pmdarima: 2.0.4
2023-11-26 07:24:18,997:INFO:              psutil: 5.9.6
2023-11-26 07:24:18,998:INFO:          markupsafe: 2.1.3
2023-11-26 07:24:18,998:INFO:             pickle5: Not installed
2023-11-26 07:24:18,998:INFO:         cloudpickle: 3.0.0
2023-11-26 07:24:18,998:INFO:         deprecation: 2.1.0
2023-11-26 07:24:18,998:INFO:              xxhash: 3.4.1
2023-11-26 07:24:18,998:INFO:           wurlitzer: 3.0.3
2023-11-26 07:24:18,998:INFO:PyCaret optional dependencies:
2023-11-26 07:24:19,009:INFO:                shap: Not installed
2023-11-26 07:24:19,009:INFO:           interpret: Not installed
2023-11-26 07:24:19,009:INFO:                umap: Not installed
2023-11-26 07:24:19,010:INFO:     ydata_profiling: Not installed
2023-11-26 07:24:19,010:INFO:  explainerdashboard: Not installed
2023-11-26 07:24:19,010:INFO:             autoviz: Not installed
2023-11-26 07:24:19,010:INFO:           fairlearn: Not installed
2023-11-26 07:24:19,010:INFO:          deepchecks: Not installed
2023-11-26 07:24:19,010:INFO:             xgboost: Not installed
2023-11-26 07:24:19,010:INFO:            catboost: Not installed
2023-11-26 07:24:19,010:INFO:              kmodes: Not installed
2023-11-26 07:24:19,010:INFO:             mlxtend: Not installed
2023-11-26 07:24:19,010:INFO:       statsforecast: Not installed
2023-11-26 07:24:19,010:INFO:        tune_sklearn: Not installed
2023-11-26 07:24:19,010:INFO:                 ray: Not installed
2023-11-26 07:24:19,010:INFO:            hyperopt: Not installed
2023-11-26 07:24:19,010:INFO:              optuna: Not installed
2023-11-26 07:24:19,010:INFO:               skopt: Not installed
2023-11-26 07:24:19,011:INFO:              mlflow: Not installed
2023-11-26 07:24:19,011:INFO:              gradio: Not installed
2023-11-26 07:24:19,011:INFO:             fastapi: Not installed
2023-11-26 07:24:19,011:INFO:             uvicorn: Not installed
2023-11-26 07:24:19,011:INFO:              m2cgen: Not installed
2023-11-26 07:24:19,011:INFO:           evidently: Not installed
2023-11-26 07:24:19,011:INFO:               fugue: Not installed
2023-11-26 07:24:19,011:INFO:           streamlit: Not installed
2023-11-26 07:24:19,011:INFO:             prophet: Not installed
2023-11-26 07:24:19,011:INFO:None
2023-11-26 07:24:19,011:INFO:Set up GPU usage.
2023-11-26 07:24:19,011:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,011:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-26 07:24:19,011:INFO:Set up data.
2023-11-26 07:24:19,014:INFO:Set up folding strategy.
2023-11-26 07:24:19,015:INFO:Set up train/test split.
2023-11-26 07:24:19,016:INFO:Set up index.
2023-11-26 07:24:19,016:INFO:Assigning column types.
2023-11-26 07:24:19,018:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-26 07:24:19,018:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,036:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 07:24:19,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,037:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 07:24:19,037:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:24:19,064:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:24:19,064:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,082:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 07:24:19,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,083:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 07:24:19,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,092:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:24:19,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:24:19,099:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-26 07:24:19,099:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,117:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 07:24:19,118:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,126:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,128:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,129:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:24:19,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:24:19,133:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,151:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,151:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,151:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 07:24:19,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,160:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,162:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,162:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:24:19,167:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:24:19,167:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-26 07:24:19,167:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,194:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,196:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,196:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:24:19,200:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:24:19,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,230:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,230:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:24:19,233:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:24:19,234:INFO:Preparing preprocessing pipeline...
2023-11-26 07:24:19,235:INFO:Set up simple imputation.
2023-11-26 07:24:19,244:INFO:Finished creating preprocessing pipeline.
2023-11-26 07:24:19,246:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-26 07:24:19,246:INFO:Creating final display dataframe.
2023-11-26 07:24:19,268:INFO:Setup _display_container:                     Description             Value
0                    Session id              5409
1                        Target            target
2                   Target type            Binary
3           Original data shape         (210, 13)
4        Transformed data shape         (210, 13)
5   Transformed train set shape         (147, 13)
6    Transformed test set shape          (63, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              5199
2023-11-26 07:24:19,270:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,300:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,302:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:24:19,307:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:24:19,307:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,337:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 07:24:19,337:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:24:19,341:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 07:24:19,342:INFO:setup() successfully completed in 0.36s...............
2023-11-26 07:24:19,342:INFO:Initializing compare_models()
2023-11-26 07:24:19,342:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-26 07:24:19,342:INFO:Checking exceptions
2023-11-26 07:24:19,344:INFO:Preparing display monitor
2023-11-26 07:24:19,346:INFO:Initializing Logistic Regression
2023-11-26 07:24:19,346:INFO:Total runtime is 2.5033950805664062e-06 minutes
2023-11-26 07:24:19,346:INFO:SubProcess create_model() called ==================================
2023-11-26 07:24:19,346:INFO:Initializing create_model()
2023-11-26 07:24:19,347:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff72ba0430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:24:19,347:INFO:Checking exceptions
2023-11-26 07:24:19,347:INFO:Importing libraries
2023-11-26 07:24:19,347:INFO:Copying training dataset
2023-11-26 07:24:19,348:INFO:Defining folds
2023-11-26 07:24:19,348:INFO:Declaring metric variables
2023-11-26 07:24:19,348:INFO:Importing untrained model
2023-11-26 07:24:19,348:INFO:Logistic Regression Imported successfully
2023-11-26 07:24:19,349:INFO:Starting cross validation
2023-11-26 07:24:19,349:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:24:19,405:INFO:Calculating mean and std
2023-11-26 07:24:19,405:INFO:Creating metrics dataframe
2023-11-26 07:24:19,407:INFO:Uploading results into container
2023-11-26 07:24:19,407:INFO:Uploading model into container now
2023-11-26 07:24:19,407:INFO:_master_model_container: 1
2023-11-26 07:24:19,408:INFO:_display_container: 2
2023-11-26 07:24:19,408:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5409, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-26 07:24:19,408:INFO:create_model() successfully completed......................................
2023-11-26 07:24:19,448:INFO:SubProcess create_model() end ==================================
2023-11-26 07:24:19,449:INFO:Creating metrics dataframe
2023-11-26 07:24:19,451:INFO:Initializing K Neighbors Classifier
2023-11-26 07:24:19,451:INFO:Total runtime is 0.0017501235008239747 minutes
2023-11-26 07:24:19,451:INFO:SubProcess create_model() called ==================================
2023-11-26 07:24:19,451:INFO:Initializing create_model()
2023-11-26 07:24:19,451:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff72ba0430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:24:19,452:INFO:Checking exceptions
2023-11-26 07:24:19,452:INFO:Importing libraries
2023-11-26 07:24:19,452:INFO:Copying training dataset
2023-11-26 07:24:19,453:INFO:Defining folds
2023-11-26 07:24:19,453:INFO:Declaring metric variables
2023-11-26 07:24:19,453:INFO:Importing untrained model
2023-11-26 07:24:19,454:INFO:K Neighbors Classifier Imported successfully
2023-11-26 07:24:19,454:INFO:Starting cross validation
2023-11-26 07:24:19,454:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:24:19,635:INFO:Calculating mean and std
2023-11-26 07:24:19,635:INFO:Creating metrics dataframe
2023-11-26 07:24:19,637:INFO:Uploading results into container
2023-11-26 07:24:19,637:INFO:Uploading model into container now
2023-11-26 07:24:19,638:INFO:_master_model_container: 2
2023-11-26 07:24:19,638:INFO:_display_container: 2
2023-11-26 07:24:19,638:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-26 07:24:19,638:INFO:create_model() successfully completed......................................
2023-11-26 07:24:19,667:INFO:SubProcess create_model() end ==================================
2023-11-26 07:24:19,668:INFO:Creating metrics dataframe
2023-11-26 07:24:19,670:INFO:Initializing Naive Bayes
2023-11-26 07:24:19,670:INFO:Total runtime is 0.005404782295227051 minutes
2023-11-26 07:24:19,670:INFO:SubProcess create_model() called ==================================
2023-11-26 07:24:19,671:INFO:Initializing create_model()
2023-11-26 07:24:19,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff72ba0430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:24:19,671:INFO:Checking exceptions
2023-11-26 07:24:19,671:INFO:Importing libraries
2023-11-26 07:24:19,671:INFO:Copying training dataset
2023-11-26 07:24:19,672:INFO:Defining folds
2023-11-26 07:24:19,672:INFO:Declaring metric variables
2023-11-26 07:24:19,672:INFO:Importing untrained model
2023-11-26 07:24:19,673:INFO:Naive Bayes Imported successfully
2023-11-26 07:24:19,673:INFO:Starting cross validation
2023-11-26 07:24:19,673:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:24:19,710:INFO:Calculating mean and std
2023-11-26 07:24:19,711:INFO:Creating metrics dataframe
2023-11-26 07:24:19,712:INFO:Uploading results into container
2023-11-26 07:24:19,712:INFO:Uploading model into container now
2023-11-26 07:24:19,713:INFO:_master_model_container: 3
2023-11-26 07:24:19,713:INFO:_display_container: 2
2023-11-26 07:24:19,713:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-26 07:24:19,713:INFO:create_model() successfully completed......................................
2023-11-26 07:24:19,740:INFO:SubProcess create_model() end ==================================
2023-11-26 07:24:19,741:INFO:Creating metrics dataframe
2023-11-26 07:24:19,743:INFO:Initializing Decision Tree Classifier
2023-11-26 07:24:19,743:INFO:Total runtime is 0.006618030865987142 minutes
2023-11-26 07:24:19,743:INFO:SubProcess create_model() called ==================================
2023-11-26 07:24:19,743:INFO:Initializing create_model()
2023-11-26 07:24:19,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff72ba0430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:24:19,744:INFO:Checking exceptions
2023-11-26 07:24:19,744:INFO:Importing libraries
2023-11-26 07:24:19,744:INFO:Copying training dataset
2023-11-26 07:24:19,745:INFO:Defining folds
2023-11-26 07:24:19,745:INFO:Declaring metric variables
2023-11-26 07:24:19,745:INFO:Importing untrained model
2023-11-26 07:24:19,745:INFO:Decision Tree Classifier Imported successfully
2023-11-26 07:24:19,746:INFO:Starting cross validation
2023-11-26 07:24:19,746:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:24:19,786:INFO:Calculating mean and std
2023-11-26 07:24:19,786:INFO:Creating metrics dataframe
2023-11-26 07:24:19,787:INFO:Uploading results into container
2023-11-26 07:24:19,788:INFO:Uploading model into container now
2023-11-26 07:24:19,788:INFO:_master_model_container: 4
2023-11-26 07:24:19,788:INFO:_display_container: 2
2023-11-26 07:24:19,788:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5409, splitter='best')
2023-11-26 07:24:19,789:INFO:create_model() successfully completed......................................
2023-11-26 07:24:19,817:INFO:SubProcess create_model() end ==================================
2023-11-26 07:24:19,817:INFO:Creating metrics dataframe
2023-11-26 07:24:19,819:INFO:Initializing SVM - Linear Kernel
2023-11-26 07:24:19,820:INFO:Total runtime is 0.007896633942921956 minutes
2023-11-26 07:24:19,820:INFO:SubProcess create_model() called ==================================
2023-11-26 07:24:19,820:INFO:Initializing create_model()
2023-11-26 07:24:19,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff72ba0430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:24:19,820:INFO:Checking exceptions
2023-11-26 07:24:19,820:INFO:Importing libraries
2023-11-26 07:24:19,820:INFO:Copying training dataset
2023-11-26 07:24:19,822:INFO:Defining folds
2023-11-26 07:24:19,822:INFO:Declaring metric variables
2023-11-26 07:24:19,822:INFO:Importing untrained model
2023-11-26 07:24:19,822:INFO:SVM - Linear Kernel Imported successfully
2023-11-26 07:24:19,823:INFO:Starting cross validation
2023-11-26 07:24:19,823:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:24:19,829:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 07:24:19,836:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 07:24:19,845:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 07:24:19,851:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 07:24:19,858:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 07:24:19,861:INFO:Calculating mean and std
2023-11-26 07:24:19,861:INFO:Creating metrics dataframe
2023-11-26 07:24:19,862:INFO:Uploading results into container
2023-11-26 07:24:19,863:INFO:Uploading model into container now
2023-11-26 07:24:19,863:INFO:_master_model_container: 5
2023-11-26 07:24:19,863:INFO:_display_container: 2
2023-11-26 07:24:19,863:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5409, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-26 07:24:19,864:INFO:create_model() successfully completed......................................
2023-11-26 07:24:19,891:INFO:SubProcess create_model() end ==================================
2023-11-26 07:24:19,891:INFO:Creating metrics dataframe
2023-11-26 07:24:19,894:INFO:Initializing Ridge Classifier
2023-11-26 07:24:19,894:INFO:Total runtime is 0.00913177728652954 minutes
2023-11-26 07:24:19,894:INFO:SubProcess create_model() called ==================================
2023-11-26 07:24:19,894:INFO:Initializing create_model()
2023-11-26 07:24:19,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff72ba0430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:24:19,894:INFO:Checking exceptions
2023-11-26 07:24:19,894:INFO:Importing libraries
2023-11-26 07:24:19,895:INFO:Copying training dataset
2023-11-26 07:24:19,896:INFO:Defining folds
2023-11-26 07:24:19,896:INFO:Declaring metric variables
2023-11-26 07:24:19,896:INFO:Importing untrained model
2023-11-26 07:24:19,896:INFO:Ridge Classifier Imported successfully
2023-11-26 07:24:19,897:INFO:Starting cross validation
2023-11-26 07:24:19,897:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:24:19,903:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 07:24:19,910:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 07:24:19,917:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 07:24:19,924:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 07:24:19,931:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 07:24:19,933:INFO:Calculating mean and std
2023-11-26 07:24:19,934:INFO:Creating metrics dataframe
2023-11-26 07:24:19,935:INFO:Uploading results into container
2023-11-26 07:24:19,935:INFO:Uploading model into container now
2023-11-26 07:24:19,936:INFO:_master_model_container: 6
2023-11-26 07:24:19,936:INFO:_display_container: 2
2023-11-26 07:24:19,936:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5409, solver='auto',
                tol=0.0001)
2023-11-26 07:24:19,936:INFO:create_model() successfully completed......................................
2023-11-26 07:24:19,965:INFO:SubProcess create_model() end ==================================
2023-11-26 07:24:19,966:INFO:Creating metrics dataframe
2023-11-26 07:24:19,968:INFO:Initializing Quadratic Discriminant Analysis
2023-11-26 07:24:19,968:INFO:Total runtime is 0.010371788342793783 minutes
2023-11-26 07:24:19,968:INFO:SubProcess create_model() called ==================================
2023-11-26 07:24:19,969:INFO:Initializing create_model()
2023-11-26 07:24:19,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff72ba0430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:24:19,969:INFO:Checking exceptions
2023-11-26 07:24:19,969:INFO:Importing libraries
2023-11-26 07:24:19,969:INFO:Copying training dataset
2023-11-26 07:24:19,970:INFO:Defining folds
2023-11-26 07:24:19,970:INFO:Declaring metric variables
2023-11-26 07:24:19,971:INFO:Importing untrained model
2023-11-26 07:24:19,971:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-26 07:24:19,971:INFO:Starting cross validation
2023-11-26 07:24:19,971:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:24:20,008:INFO:Calculating mean and std
2023-11-26 07:24:20,009:INFO:Creating metrics dataframe
2023-11-26 07:24:20,010:INFO:Uploading results into container
2023-11-26 07:24:20,010:INFO:Uploading model into container now
2023-11-26 07:24:20,010:INFO:_master_model_container: 7
2023-11-26 07:24:20,010:INFO:_display_container: 2
2023-11-26 07:24:20,011:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-26 07:24:20,011:INFO:create_model() successfully completed......................................
2023-11-26 07:24:20,036:INFO:SubProcess create_model() end ==================================
2023-11-26 07:24:20,037:INFO:Creating metrics dataframe
2023-11-26 07:24:20,039:INFO:Initializing Ada Boost Classifier
2023-11-26 07:24:20,039:INFO:Total runtime is 0.01155162254969279 minutes
2023-11-26 07:24:20,039:INFO:SubProcess create_model() called ==================================
2023-11-26 07:24:20,039:INFO:Initializing create_model()
2023-11-26 07:24:20,039:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff72ba0430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:24:20,040:INFO:Checking exceptions
2023-11-26 07:24:20,040:INFO:Importing libraries
2023-11-26 07:24:20,040:INFO:Copying training dataset
2023-11-26 07:24:20,041:INFO:Defining folds
2023-11-26 07:24:20,041:INFO:Declaring metric variables
2023-11-26 07:24:20,041:INFO:Importing untrained model
2023-11-26 07:24:20,042:INFO:Ada Boost Classifier Imported successfully
2023-11-26 07:24:20,042:INFO:Starting cross validation
2023-11-26 07:24:20,042:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:24:20,216:INFO:Calculating mean and std
2023-11-26 07:24:20,216:INFO:Creating metrics dataframe
2023-11-26 07:24:20,218:INFO:Uploading results into container
2023-11-26 07:24:20,218:INFO:Uploading model into container now
2023-11-26 07:24:20,218:INFO:_master_model_container: 8
2023-11-26 07:24:20,218:INFO:_display_container: 2
2023-11-26 07:24:20,219:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=5409)
2023-11-26 07:24:20,219:INFO:create_model() successfully completed......................................
2023-11-26 07:24:20,249:INFO:SubProcess create_model() end ==================================
2023-11-26 07:24:20,250:INFO:Creating metrics dataframe
2023-11-26 07:24:20,253:INFO:Initializing Linear Discriminant Analysis
2023-11-26 07:24:20,253:INFO:Total runtime is 0.015116270383199057 minutes
2023-11-26 07:24:20,253:INFO:SubProcess create_model() called ==================================
2023-11-26 07:24:20,253:INFO:Initializing create_model()
2023-11-26 07:24:20,253:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff72ba0430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:24:20,253:INFO:Checking exceptions
2023-11-26 07:24:20,253:INFO:Importing libraries
2023-11-26 07:24:20,254:INFO:Copying training dataset
2023-11-26 07:24:20,255:INFO:Defining folds
2023-11-26 07:24:20,255:INFO:Declaring metric variables
2023-11-26 07:24:20,255:INFO:Importing untrained model
2023-11-26 07:24:20,255:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 07:24:20,256:INFO:Starting cross validation
2023-11-26 07:24:20,256:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:24:20,295:INFO:Calculating mean and std
2023-11-26 07:24:20,295:INFO:Creating metrics dataframe
2023-11-26 07:24:20,297:INFO:Uploading results into container
2023-11-26 07:24:20,297:INFO:Uploading model into container now
2023-11-26 07:24:20,298:INFO:_master_model_container: 9
2023-11-26 07:24:20,298:INFO:_display_container: 2
2023-11-26 07:24:20,298:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:24:20,298:INFO:create_model() successfully completed......................................
2023-11-26 07:24:20,327:INFO:SubProcess create_model() end ==================================
2023-11-26 07:24:20,327:INFO:Creating metrics dataframe
2023-11-26 07:24:20,330:INFO:Initializing Extra Trees Classifier
2023-11-26 07:24:20,330:INFO:Total runtime is 0.016399017969767254 minutes
2023-11-26 07:24:20,330:INFO:SubProcess create_model() called ==================================
2023-11-26 07:24:20,330:INFO:Initializing create_model()
2023-11-26 07:24:20,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff72ba0430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:24:20,330:INFO:Checking exceptions
2023-11-26 07:24:20,331:INFO:Importing libraries
2023-11-26 07:24:20,331:INFO:Copying training dataset
2023-11-26 07:24:20,332:INFO:Defining folds
2023-11-26 07:24:20,332:INFO:Declaring metric variables
2023-11-26 07:24:20,332:INFO:Importing untrained model
2023-11-26 07:24:20,332:INFO:Extra Trees Classifier Imported successfully
2023-11-26 07:24:20,333:INFO:Starting cross validation
2023-11-26 07:24:20,333:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:24:21,026:INFO:Calculating mean and std
2023-11-26 07:24:21,027:INFO:Creating metrics dataframe
2023-11-26 07:24:21,028:INFO:Uploading results into container
2023-11-26 07:24:21,029:INFO:Uploading model into container now
2023-11-26 07:24:21,029:INFO:_master_model_container: 10
2023-11-26 07:24:21,029:INFO:_display_container: 2
2023-11-26 07:24:21,030:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5409, verbose=0, warm_start=False)
2023-11-26 07:24:21,030:INFO:create_model() successfully completed......................................
2023-11-26 07:24:21,061:INFO:SubProcess create_model() end ==================================
2023-11-26 07:24:21,061:INFO:Creating metrics dataframe
2023-11-26 07:24:21,063:INFO:Initializing Light Gradient Boosting Machine
2023-11-26 07:24:21,063:INFO:Total runtime is 0.02862444321314494 minutes
2023-11-26 07:24:21,063:INFO:SubProcess create_model() called ==================================
2023-11-26 07:24:21,064:INFO:Initializing create_model()
2023-11-26 07:24:21,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff72ba0430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:24:21,064:INFO:Checking exceptions
2023-11-26 07:24:21,064:INFO:Importing libraries
2023-11-26 07:24:21,064:INFO:Copying training dataset
2023-11-26 07:24:21,065:INFO:Defining folds
2023-11-26 07:24:21,065:INFO:Declaring metric variables
2023-11-26 07:24:21,066:INFO:Importing untrained model
2023-11-26 07:24:21,066:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-26 07:24:21,066:INFO:Starting cross validation
2023-11-26 07:24:21,067:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:24:21,072:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 07:24:21,072:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000099 seconds.
2023-11-26 07:24:21,072:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 07:24:21,073:INFO:[LightGBM] [Info] Total Bins 489
2023-11-26 07:24:21,073:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 07:24:21,073:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 07:24:21,073:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 07:24:21,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,131:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 07:24:21,134:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001901 seconds.
2023-11-26 07:24:21,134:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 07:24:21,134:INFO:[LightGBM] [Info] Total Bins 488
2023-11-26 07:24:21,135:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 07:24:21,135:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 07:24:21,135:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 07:24:21,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,229:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 07:24:21,229:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.
2023-11-26 07:24:21,229:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 07:24:21,229:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 07:24:21,230:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 07:24:21,230:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 07:24:21,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,294:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 07:24:21,294:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000034 seconds.
2023-11-26 07:24:21,294:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 07:24:21,294:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 07:24:21,295:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 07:24:21,295:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 07:24:21,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,320:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 60
2023-11-26 07:24:21,321:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000068 seconds.
2023-11-26 07:24:21,321:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 07:24:21,321:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 07:24:21,321:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 07:24:21,322:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491525 -> initscore=-0.033902
2023-11-26 07:24:21,322:INFO:[LightGBM] [Info] Start training from score -0.033902
2023-11-26 07:24:21,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 07:24:21,362:INFO:Calculating mean and std
2023-11-26 07:24:21,362:INFO:Creating metrics dataframe
2023-11-26 07:24:21,364:INFO:Uploading results into container
2023-11-26 07:24:21,364:INFO:Uploading model into container now
2023-11-26 07:24:21,364:INFO:_master_model_container: 11
2023-11-26 07:24:21,365:INFO:_display_container: 2
2023-11-26 07:24:21,365:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5409, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-26 07:24:21,365:INFO:create_model() successfully completed......................................
2023-11-26 07:24:21,394:INFO:SubProcess create_model() end ==================================
2023-11-26 07:24:21,394:INFO:Creating metrics dataframe
2023-11-26 07:24:21,397:INFO:Initializing Dummy Classifier
2023-11-26 07:24:21,397:INFO:Total runtime is 0.034181825319925946 minutes
2023-11-26 07:24:21,397:INFO:SubProcess create_model() called ==================================
2023-11-26 07:24:21,397:INFO:Initializing create_model()
2023-11-26 07:24:21,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff72ba0430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:24:21,397:INFO:Checking exceptions
2023-11-26 07:24:21,397:INFO:Importing libraries
2023-11-26 07:24:21,397:INFO:Copying training dataset
2023-11-26 07:24:21,399:INFO:Defining folds
2023-11-26 07:24:21,399:INFO:Declaring metric variables
2023-11-26 07:24:21,399:INFO:Importing untrained model
2023-11-26 07:24:21,399:INFO:Dummy Classifier Imported successfully
2023-11-26 07:24:21,399:INFO:Starting cross validation
2023-11-26 07:24:21,400:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:24:21,407:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 07:24:21,413:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 07:24:21,420:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 07:24:21,426:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 07:24:21,432:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 07:24:21,434:INFO:Calculating mean and std
2023-11-26 07:24:21,434:INFO:Creating metrics dataframe
2023-11-26 07:24:21,435:INFO:Uploading results into container
2023-11-26 07:24:21,435:INFO:Uploading model into container now
2023-11-26 07:24:21,436:INFO:_master_model_container: 12
2023-11-26 07:24:21,436:INFO:_display_container: 2
2023-11-26 07:24:21,436:INFO:DummyClassifier(constant=None, random_state=5409, strategy='prior')
2023-11-26 07:24:21,436:INFO:create_model() successfully completed......................................
2023-11-26 07:24:21,466:INFO:SubProcess create_model() end ==================================
2023-11-26 07:24:21,466:INFO:Creating metrics dataframe
2023-11-26 07:24:21,469:INFO:Initializing create_model()
2023-11-26 07:24:21,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5409, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:24:21,469:INFO:Checking exceptions
2023-11-26 07:24:21,470:INFO:Importing libraries
2023-11-26 07:24:21,470:INFO:Copying training dataset
2023-11-26 07:24:21,471:INFO:Defining folds
2023-11-26 07:24:21,471:INFO:Declaring metric variables
2023-11-26 07:24:21,471:INFO:Importing untrained model
2023-11-26 07:24:21,471:INFO:Declaring custom model
2023-11-26 07:24:21,472:INFO:Logistic Regression Imported successfully
2023-11-26 07:24:21,472:INFO:Cross validation set to False
2023-11-26 07:24:21,472:INFO:Fitting Model
2023-11-26 07:24:21,480:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5409, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-26 07:24:21,480:INFO:create_model() successfully completed......................................
2023-11-26 07:24:21,510:INFO:_master_model_container: 12
2023-11-26 07:24:21,510:INFO:_display_container: 2
2023-11-26 07:24:21,510:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5409, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-26 07:24:21,511:INFO:compare_models() successfully completed......................................
2023-11-26 07:24:21,511:INFO:Initializing create_model()
2023-11-26 07:24:21,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:24:21,511:INFO:Checking exceptions
2023-11-26 07:24:21,512:INFO:Importing libraries
2023-11-26 07:24:21,512:INFO:Copying training dataset
2023-11-26 07:24:21,514:INFO:Defining folds
2023-11-26 07:24:21,514:INFO:Declaring metric variables
2023-11-26 07:24:21,514:INFO:Importing untrained model
2023-11-26 07:24:21,514:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 07:24:21,514:INFO:Starting cross validation
2023-11-26 07:24:21,515:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:24:21,552:INFO:Calculating mean and std
2023-11-26 07:24:21,552:INFO:Creating metrics dataframe
2023-11-26 07:24:21,553:INFO:Finalizing model
2023-11-26 07:24:21,557:INFO:Uploading results into container
2023-11-26 07:24:21,557:INFO:Uploading model into container now
2023-11-26 07:24:21,560:INFO:_master_model_container: 13
2023-11-26 07:24:21,560:INFO:_display_container: 3
2023-11-26 07:24:21,561:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:24:21,561:INFO:create_model() successfully completed......................................
2023-11-26 07:24:21,591:INFO:Initializing tune_model()
2023-11-26 07:24:21,591:INFO:tune_model(estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>)
2023-11-26 07:24:21,591:INFO:Checking exceptions
2023-11-26 07:24:21,592:INFO:Copying training dataset
2023-11-26 07:24:21,593:INFO:Checking base model
2023-11-26 07:24:21,593:INFO:Base model : Linear Discriminant Analysis
2023-11-26 07:24:21,594:INFO:Declaring metric variables
2023-11-26 07:24:21,594:INFO:Defining Hyperparameters
2023-11-26 07:24:21,624:INFO:Tuning with n_jobs=-1
2023-11-26 07:24:21,624:INFO:Initializing RandomizedSearchCV
2023-11-26 07:24:22,925:INFO:best_params: {'actual_estimator__solver': 'lsqr', 'actual_estimator__shrinkage': 0.001}
2023-11-26 07:24:22,926:INFO:Hyperparameter search completed
2023-11-26 07:24:22,926:INFO:SubProcess create_model() called ==================================
2023-11-26 07:24:22,927:INFO:Initializing create_model()
2023-11-26 07:24:22,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffffb2468280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lsqr', 'shrinkage': 0.001})
2023-11-26 07:24:22,927:INFO:Checking exceptions
2023-11-26 07:24:22,928:INFO:Importing libraries
2023-11-26 07:24:22,928:INFO:Copying training dataset
2023-11-26 07:24:22,930:INFO:Defining folds
2023-11-26 07:24:22,930:INFO:Declaring metric variables
2023-11-26 07:24:22,930:INFO:Importing untrained model
2023-11-26 07:24:22,931:INFO:Declaring custom model
2023-11-26 07:24:22,931:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 07:24:22,931:INFO:Starting cross validation
2023-11-26 07:24:22,932:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:24:22,972:INFO:Calculating mean and std
2023-11-26 07:24:22,972:INFO:Creating metrics dataframe
2023-11-26 07:24:22,973:INFO:Finalizing model
2023-11-26 07:24:22,977:INFO:Uploading results into container
2023-11-26 07:24:22,977:INFO:Uploading model into container now
2023-11-26 07:24:22,978:INFO:_master_model_container: 14
2023-11-26 07:24:22,978:INFO:_display_container: 4
2023-11-26 07:24:22,978:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.001, solver='lsqr',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:24:22,978:INFO:create_model() successfully completed......................................
2023-11-26 07:24:23,015:INFO:SubProcess create_model() end ==================================
2023-11-26 07:24:23,016:INFO:choose_better activated
2023-11-26 07:24:23,016:INFO:SubProcess create_model() called ==================================
2023-11-26 07:24:23,016:INFO:Initializing create_model()
2023-11-26 07:24:23,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:24:23,017:INFO:Checking exceptions
2023-11-26 07:24:23,017:INFO:Importing libraries
2023-11-26 07:24:23,017:INFO:Copying training dataset
2023-11-26 07:24:23,019:INFO:Defining folds
2023-11-26 07:24:23,019:INFO:Declaring metric variables
2023-11-26 07:24:23,019:INFO:Importing untrained model
2023-11-26 07:24:23,019:INFO:Declaring custom model
2023-11-26 07:24:23,019:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 07:24:23,019:INFO:Starting cross validation
2023-11-26 07:24:23,020:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 07:24:23,057:INFO:Calculating mean and std
2023-11-26 07:24:23,058:INFO:Creating metrics dataframe
2023-11-26 07:24:23,059:INFO:Finalizing model
2023-11-26 07:24:23,062:INFO:Uploading results into container
2023-11-26 07:24:23,062:INFO:Uploading model into container now
2023-11-26 07:24:23,063:INFO:_master_model_container: 15
2023-11-26 07:24:23,063:INFO:_display_container: 5
2023-11-26 07:24:23,063:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:24:23,063:INFO:create_model() successfully completed......................................
2023-11-26 07:24:23,091:INFO:SubProcess create_model() end ==================================
2023-11-26 07:24:23,091:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.999
2023-11-26 07:24:23,092:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.001, solver='lsqr',
                           store_covariance=False, tol=0.0001) result for AUC is 0.999
2023-11-26 07:24:23,092:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) is best model
2023-11-26 07:24:23,092:INFO:choose_better completed
2023-11-26 07:24:23,092:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-11-26 07:24:23,096:INFO:_master_model_container: 15
2023-11-26 07:24:23,096:INFO:_display_container: 4
2023-11-26 07:24:23,096:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:24:23,096:INFO:tune_model() successfully completed......................................
2023-11-26 07:24:23,122:INFO:Initializing evaluate_model()
2023-11-26 07:24:23,122:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-26 07:24:23,125:INFO:Initializing plot_model()
2023-11-26 07:24:23,125:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, system=True)
2023-11-26 07:24:23,125:INFO:Checking exceptions
2023-11-26 07:24:23,126:INFO:Preloading libraries
2023-11-26 07:24:23,126:INFO:Copying training dataset
2023-11-26 07:24:23,126:INFO:Plot type: pipeline
2023-11-26 07:24:23,160:INFO:Visual Rendered Successfully
2023-11-26 07:24:23,199:INFO:plot_model() successfully completed......................................
2023-11-26 07:24:24,377:INFO:Initializing finalize_model()
2023-11-26 07:24:24,377:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-11-26 07:24:24,378:INFO:Finalizing LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 07:24:24,382:INFO:Initializing create_model()
2023-11-26 07:24:24,382:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 07:24:24,383:INFO:Checking exceptions
2023-11-26 07:24:24,384:INFO:Importing libraries
2023-11-26 07:24:24,384:INFO:Copying training dataset
2023-11-26 07:24:24,385:INFO:Defining folds
2023-11-26 07:24:24,385:INFO:Declaring metric variables
2023-11-26 07:24:24,385:INFO:Importing untrained model
2023-11-26 07:24:24,385:INFO:Declaring custom model
2023-11-26 07:24:24,386:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 07:24:24,387:INFO:Cross validation set to False
2023-11-26 07:24:24,388:INFO:Fitting Model
2023-11-26 07:24:24,401:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 07:24:24,402:INFO:create_model() successfully completed......................................
2023-11-26 07:24:24,446:INFO:_master_model_container: 15
2023-11-26 07:24:24,447:INFO:_display_container: 4
2023-11-26 07:24:24,449:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 07:24:24,450:INFO:finalize_model() successfully completed......................................
2023-11-26 07:24:46,577:INFO:Initializing predict_model()
2023-11-26 07:24:46,580:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff72bf2f70>)
2023-11-26 07:24:46,580:INFO:Checking exceptions
2023-11-26 07:24:46,580:INFO:Preloading libraries
2023-11-26 07:26:40,131:INFO:Initializing predict_model()
2023-11-26 07:26:40,134:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff72e52f70>)
2023-11-26 07:26:40,135:INFO:Checking exceptions
2023-11-26 07:26:40,135:INFO:Preloading libraries
2023-11-26 07:30:58,595:INFO:Initializing predict_model()
2023-11-26 07:30:58,598:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff6ab214c0>)
2023-11-26 07:30:58,599:INFO:Checking exceptions
2023-11-26 07:30:58,599:INFO:Preloading libraries
2023-11-26 07:32:11,100:INFO:Initializing predict_model()
2023-11-26 07:32:11,102:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb01861c0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff6ab21dc0>)
2023-11-26 07:32:11,102:INFO:Checking exceptions
2023-11-26 07:32:11,102:INFO:Preloading libraries
2023-11-26 08:23:21,033:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:21,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:21,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:21,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:44,988:INFO:PyCaret ClassificationExperiment
2023-11-26 08:23:44,990:INFO:Logging name: clf-default-name
2023-11-26 08:23:44,990:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-26 08:23:44,991:INFO:version 3.2.0
2023-11-26 08:23:44,991:INFO:Initializing setup()
2023-11-26 08:23:44,991:INFO:self.USI: 20fa
2023-11-26 08:23:44,991:INFO:self._variable_keys: {'exp_id', 'gpu_param', 'X_test', 'target_param', 'gpu_n_jobs_param', 'X_train', 'y', 'y_test', '_available_plots', 'fix_imbalance', 'exp_name_log', 'data', 'idx', 'fold_shuffle_param', 'log_plots_param', 'logging_param', 'USI', 'pipeline', 'fold_generator', 'html_param', '_ml_usecase', 'X', 'seed', 'y_train', 'is_multiclass', 'n_jobs_param', 'memory', 'fold_groups_param'}
2023-11-26 08:23:44,992:INFO:Checking environment
2023-11-26 08:23:44,992:INFO:python_version: 3.8.18
2023-11-26 08:23:44,992:INFO:python_build: ('default', 'Nov 21 2023 19:36:55')
2023-11-26 08:23:44,992:INFO:machine: aarch64
2023-11-26 08:23:44,995:INFO:platform: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 08:23:44,996:INFO:Memory: svmem(total=8225304576, available=7019307008, percent=14.7, used=996728832, free=3452563456, active=2018291712, inactive=2134749184, buffers=117317632, cached=3658694656, shared=1691648, slab=444379136)
2023-11-26 08:23:44,998:INFO:Physical Core: 12
2023-11-26 08:23:44,998:INFO:Logical Core: 12
2023-11-26 08:23:44,998:INFO:Checking libraries
2023-11-26 08:23:44,999:INFO:System:
2023-11-26 08:23:44,999:INFO:    python: 3.8.18 (default, Nov 21 2023, 19:36:55)  [GCC 12.2.0]
2023-11-26 08:23:45,000:INFO:executable: /usr/local/bin/python
2023-11-26 08:23:45,000:INFO:   machine: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 08:23:45,000:INFO:PyCaret required dependencies:
2023-11-26 08:23:45,020:INFO:                 pip: 23.3.1
2023-11-26 08:23:45,020:INFO:          setuptools: 57.5.0
2023-11-26 08:23:45,021:INFO:             pycaret: 3.2.0
2023-11-26 08:23:45,021:INFO:             IPython: 8.12.3
2023-11-26 08:23:45,021:INFO:          ipywidgets: 8.1.1
2023-11-26 08:23:45,021:INFO:                tqdm: 4.66.1
2023-11-26 08:23:45,021:INFO:               numpy: 1.24.4
2023-11-26 08:23:45,022:INFO:              pandas: 1.5.3
2023-11-26 08:23:45,022:INFO:              jinja2: 3.1.2
2023-11-26 08:23:45,022:INFO:               scipy: 1.10.1
2023-11-26 08:23:45,022:INFO:              joblib: 1.3.2
2023-11-26 08:23:45,022:INFO:             sklearn: 1.2.2
2023-11-26 08:23:45,022:INFO:                pyod: 1.1.2
2023-11-26 08:23:45,022:INFO:            imblearn: 0.11.0
2023-11-26 08:23:45,023:INFO:   category_encoders: 2.6.3
2023-11-26 08:23:45,023:INFO:            lightgbm: 4.1.0
2023-11-26 08:23:45,023:INFO:               numba: 0.58.1
2023-11-26 08:23:45,023:INFO:            requests: 2.31.0
2023-11-26 08:23:45,023:INFO:          matplotlib: 3.6.0
2023-11-26 08:23:45,023:INFO:          scikitplot: 0.3.7
2023-11-26 08:23:45,024:INFO:         yellowbrick: 1.5
2023-11-26 08:23:45,024:INFO:              plotly: 5.18.0
2023-11-26 08:23:45,024:INFO:    plotly-resampler: Not installed
2023-11-26 08:23:45,024:INFO:             kaleido: 0.2.1
2023-11-26 08:23:45,024:INFO:           schemdraw: 0.15
2023-11-26 08:23:45,024:INFO:         statsmodels: 0.14.0
2023-11-26 08:23:45,024:INFO:              sktime: 0.21.1
2023-11-26 08:23:45,025:INFO:               tbats: 1.1.3
2023-11-26 08:23:45,025:INFO:            pmdarima: 2.0.4
2023-11-26 08:23:45,025:INFO:              psutil: 5.9.6
2023-11-26 08:23:45,025:INFO:          markupsafe: 2.1.3
2023-11-26 08:23:45,025:INFO:             pickle5: Not installed
2023-11-26 08:23:45,025:INFO:         cloudpickle: 3.0.0
2023-11-26 08:23:45,025:INFO:         deprecation: 2.1.0
2023-11-26 08:23:45,026:INFO:              xxhash: 3.4.1
2023-11-26 08:23:45,026:INFO:           wurlitzer: 3.0.3
2023-11-26 08:23:45,026:INFO:PyCaret optional dependencies:
2023-11-26 08:23:45,040:INFO:                shap: Not installed
2023-11-26 08:23:45,040:INFO:           interpret: Not installed
2023-11-26 08:23:45,040:INFO:                umap: Not installed
2023-11-26 08:23:45,040:INFO:     ydata_profiling: Not installed
2023-11-26 08:23:45,040:INFO:  explainerdashboard: Not installed
2023-11-26 08:23:45,041:INFO:             autoviz: Not installed
2023-11-26 08:23:45,041:INFO:           fairlearn: Not installed
2023-11-26 08:23:45,041:INFO:          deepchecks: Not installed
2023-11-26 08:23:45,041:INFO:             xgboost: Not installed
2023-11-26 08:23:45,041:INFO:            catboost: Not installed
2023-11-26 08:23:45,041:INFO:              kmodes: Not installed
2023-11-26 08:23:45,041:INFO:             mlxtend: Not installed
2023-11-26 08:23:45,042:INFO:       statsforecast: Not installed
2023-11-26 08:23:45,042:INFO:        tune_sklearn: Not installed
2023-11-26 08:23:45,042:INFO:                 ray: Not installed
2023-11-26 08:23:45,042:INFO:            hyperopt: Not installed
2023-11-26 08:23:45,042:INFO:              optuna: Not installed
2023-11-26 08:23:45,042:INFO:               skopt: Not installed
2023-11-26 08:23:45,042:INFO:              mlflow: Not installed
2023-11-26 08:23:45,043:INFO:              gradio: Not installed
2023-11-26 08:23:45,043:INFO:             fastapi: Not installed
2023-11-26 08:23:45,043:INFO:             uvicorn: Not installed
2023-11-26 08:23:45,043:INFO:              m2cgen: Not installed
2023-11-26 08:23:45,043:INFO:           evidently: Not installed
2023-11-26 08:23:45,043:INFO:               fugue: Not installed
2023-11-26 08:23:45,044:INFO:           streamlit: Not installed
2023-11-26 08:23:45,044:INFO:             prophet: Not installed
2023-11-26 08:23:45,044:INFO:None
2023-11-26 08:23:45,044:INFO:Set up GPU usage.
2023-11-26 08:23:45,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,044:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-26 08:23:45,045:INFO:Set up data.
2023-11-26 08:23:45,051:INFO:Set up folding strategy.
2023-11-26 08:23:45,051:INFO:Set up train/test split.
2023-11-26 08:23:45,053:INFO:Set up index.
2023-11-26 08:23:45,053:INFO:Assigning column types.
2023-11-26 08:23:45,055:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-26 08:23:45,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,076:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 08:23:45,076:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,077:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,077:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 08:23:45,077:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,089:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,092:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:23:45,113:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:23:45,114:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,131:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 08:23:45,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,132:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 08:23:45,132:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:23:45,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:23:45,148:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-26 08:23:45,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,168:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,168:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,168:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 08:23:45,168:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,177:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,179:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:23:45,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:23:45,184:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,203:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,203:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,203:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 08:23:45,203:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,212:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:23:45,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:23:45,219:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-26 08:23:45,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,237:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,237:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,246:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,248:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,248:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:23:45,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:23:45,319:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,337:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,347:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,347:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:23:45,350:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:23:45,351:INFO:Preparing preprocessing pipeline...
2023-11-26 08:23:45,352:INFO:Set up simple imputation.
2023-11-26 08:23:45,360:INFO:Finished creating preprocessing pipeline.
2023-11-26 08:23:45,362:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-26 08:23:45,362:INFO:Creating final display dataframe.
2023-11-26 08:23:45,384:INFO:Setup _display_container:                     Description             Value
0                    Session id              8781
1                        Target            target
2                   Target type            Binary
3           Original data shape         (210, 13)
4        Transformed data shape         (210, 13)
5   Transformed train set shape         (147, 13)
6    Transformed test set shape          (63, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              20fa
2023-11-26 08:23:45,386:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,414:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,416:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:23:45,420:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:23:45,420:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,438:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,439:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,439:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,448:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,450:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:23:45,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:23:45,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:23:45,454:INFO:setup() successfully completed in 0.47s...............
2023-11-26 08:23:59,582:INFO:Initializing compare_models()
2023-11-26 08:23:59,583:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-26 08:23:59,583:INFO:Checking exceptions
2023-11-26 08:23:59,589:INFO:Preparing display monitor
2023-11-26 08:23:59,595:INFO:Initializing Logistic Regression
2023-11-26 08:23:59,596:INFO:Total runtime is 9.083747863769532e-06 minutes
2023-11-26 08:23:59,596:INFO:SubProcess create_model() called ==================================
2023-11-26 08:23:59,597:INFO:Initializing create_model()
2023-11-26 08:23:59,597:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4a5d7f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:23:59,597:INFO:Checking exceptions
2023-11-26 08:23:59,597:INFO:Importing libraries
2023-11-26 08:23:59,598:INFO:Copying training dataset
2023-11-26 08:23:59,601:INFO:Defining folds
2023-11-26 08:23:59,602:INFO:Declaring metric variables
2023-11-26 08:23:59,602:INFO:Importing untrained model
2023-11-26 08:23:59,603:INFO:Logistic Regression Imported successfully
2023-11-26 08:23:59,603:INFO:Starting cross validation
2023-11-26 08:23:59,604:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:23:59,684:INFO:Calculating mean and std
2023-11-26 08:23:59,685:INFO:Creating metrics dataframe
2023-11-26 08:23:59,687:INFO:Uploading results into container
2023-11-26 08:23:59,687:INFO:Uploading model into container now
2023-11-26 08:23:59,687:INFO:_master_model_container: 1
2023-11-26 08:23:59,687:INFO:_display_container: 2
2023-11-26 08:23:59,688:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8781, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-26 08:23:59,688:INFO:create_model() successfully completed......................................
2023-11-26 08:23:59,742:INFO:SubProcess create_model() end ==================================
2023-11-26 08:23:59,742:INFO:Creating metrics dataframe
2023-11-26 08:23:59,744:INFO:Initializing K Neighbors Classifier
2023-11-26 08:23:59,744:INFO:Total runtime is 0.002492189407348633 minutes
2023-11-26 08:23:59,745:INFO:SubProcess create_model() called ==================================
2023-11-26 08:23:59,745:INFO:Initializing create_model()
2023-11-26 08:23:59,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4a5d7f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:23:59,745:INFO:Checking exceptions
2023-11-26 08:23:59,745:INFO:Importing libraries
2023-11-26 08:23:59,745:INFO:Copying training dataset
2023-11-26 08:23:59,747:INFO:Defining folds
2023-11-26 08:23:59,747:INFO:Declaring metric variables
2023-11-26 08:23:59,747:INFO:Importing untrained model
2023-11-26 08:23:59,748:INFO:K Neighbors Classifier Imported successfully
2023-11-26 08:23:59,748:INFO:Starting cross validation
2023-11-26 08:23:59,748:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:23:59,933:INFO:Calculating mean and std
2023-11-26 08:23:59,934:INFO:Creating metrics dataframe
2023-11-26 08:23:59,935:INFO:Uploading results into container
2023-11-26 08:23:59,935:INFO:Uploading model into container now
2023-11-26 08:23:59,936:INFO:_master_model_container: 2
2023-11-26 08:23:59,936:INFO:_display_container: 2
2023-11-26 08:23:59,936:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-26 08:23:59,936:INFO:create_model() successfully completed......................................
2023-11-26 08:23:59,985:INFO:SubProcess create_model() end ==================================
2023-11-26 08:23:59,986:INFO:Creating metrics dataframe
2023-11-26 08:23:59,988:INFO:Initializing Naive Bayes
2023-11-26 08:23:59,988:INFO:Total runtime is 0.006557027498881022 minutes
2023-11-26 08:23:59,989:INFO:SubProcess create_model() called ==================================
2023-11-26 08:23:59,989:INFO:Initializing create_model()
2023-11-26 08:23:59,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4a5d7f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:23:59,989:INFO:Checking exceptions
2023-11-26 08:23:59,989:INFO:Importing libraries
2023-11-26 08:23:59,989:INFO:Copying training dataset
2023-11-26 08:23:59,991:INFO:Defining folds
2023-11-26 08:23:59,991:INFO:Declaring metric variables
2023-11-26 08:23:59,991:INFO:Importing untrained model
2023-11-26 08:23:59,991:INFO:Naive Bayes Imported successfully
2023-11-26 08:23:59,991:INFO:Starting cross validation
2023-11-26 08:23:59,992:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:24:00,031:INFO:Calculating mean and std
2023-11-26 08:24:00,031:INFO:Creating metrics dataframe
2023-11-26 08:24:00,032:INFO:Uploading results into container
2023-11-26 08:24:00,033:INFO:Uploading model into container now
2023-11-26 08:24:00,033:INFO:_master_model_container: 3
2023-11-26 08:24:00,033:INFO:_display_container: 2
2023-11-26 08:24:00,033:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-26 08:24:00,033:INFO:create_model() successfully completed......................................
2023-11-26 08:24:00,081:INFO:SubProcess create_model() end ==================================
2023-11-26 08:24:00,081:INFO:Creating metrics dataframe
2023-11-26 08:24:00,083:INFO:Initializing Decision Tree Classifier
2023-11-26 08:24:00,083:INFO:Total runtime is 0.008134277661641438 minutes
2023-11-26 08:24:00,083:INFO:SubProcess create_model() called ==================================
2023-11-26 08:24:00,083:INFO:Initializing create_model()
2023-11-26 08:24:00,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4a5d7f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:24:00,084:INFO:Checking exceptions
2023-11-26 08:24:00,084:INFO:Importing libraries
2023-11-26 08:24:00,084:INFO:Copying training dataset
2023-11-26 08:24:00,085:INFO:Defining folds
2023-11-26 08:24:00,085:INFO:Declaring metric variables
2023-11-26 08:24:00,085:INFO:Importing untrained model
2023-11-26 08:24:00,086:INFO:Decision Tree Classifier Imported successfully
2023-11-26 08:24:00,086:INFO:Starting cross validation
2023-11-26 08:24:00,086:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:24:00,126:INFO:Calculating mean and std
2023-11-26 08:24:00,127:INFO:Creating metrics dataframe
2023-11-26 08:24:00,128:INFO:Uploading results into container
2023-11-26 08:24:00,129:INFO:Uploading model into container now
2023-11-26 08:24:00,129:INFO:_master_model_container: 4
2023-11-26 08:24:00,129:INFO:_display_container: 2
2023-11-26 08:24:00,129:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8781, splitter='best')
2023-11-26 08:24:00,130:INFO:create_model() successfully completed......................................
2023-11-26 08:24:00,176:INFO:SubProcess create_model() end ==================================
2023-11-26 08:24:00,177:INFO:Creating metrics dataframe
2023-11-26 08:24:00,179:INFO:Initializing SVM - Linear Kernel
2023-11-26 08:24:00,179:INFO:Total runtime is 0.009735119342803954 minutes
2023-11-26 08:24:00,179:INFO:SubProcess create_model() called ==================================
2023-11-26 08:24:00,179:INFO:Initializing create_model()
2023-11-26 08:24:00,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4a5d7f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:24:00,180:INFO:Checking exceptions
2023-11-26 08:24:00,180:INFO:Importing libraries
2023-11-26 08:24:00,180:INFO:Copying training dataset
2023-11-26 08:24:00,181:INFO:Defining folds
2023-11-26 08:24:00,181:INFO:Declaring metric variables
2023-11-26 08:24:00,181:INFO:Importing untrained model
2023-11-26 08:24:00,182:INFO:SVM - Linear Kernel Imported successfully
2023-11-26 08:24:00,182:INFO:Starting cross validation
2023-11-26 08:24:00,182:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:24:00,189:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 08:24:00,196:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 08:24:00,203:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 08:24:00,210:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 08:24:00,218:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 08:24:00,221:INFO:Calculating mean and std
2023-11-26 08:24:00,221:INFO:Creating metrics dataframe
2023-11-26 08:24:00,223:INFO:Uploading results into container
2023-11-26 08:24:00,223:INFO:Uploading model into container now
2023-11-26 08:24:00,223:INFO:_master_model_container: 5
2023-11-26 08:24:00,223:INFO:_display_container: 2
2023-11-26 08:24:00,224:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8781, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-26 08:24:00,224:INFO:create_model() successfully completed......................................
2023-11-26 08:24:00,272:INFO:SubProcess create_model() end ==================================
2023-11-26 08:24:00,272:INFO:Creating metrics dataframe
2023-11-26 08:24:00,274:INFO:Initializing Ridge Classifier
2023-11-26 08:24:00,274:INFO:Total runtime is 0.01132436990737915 minutes
2023-11-26 08:24:00,275:INFO:SubProcess create_model() called ==================================
2023-11-26 08:24:00,275:INFO:Initializing create_model()
2023-11-26 08:24:00,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4a5d7f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:24:00,275:INFO:Checking exceptions
2023-11-26 08:24:00,275:INFO:Importing libraries
2023-11-26 08:24:00,275:INFO:Copying training dataset
2023-11-26 08:24:00,277:INFO:Defining folds
2023-11-26 08:24:00,277:INFO:Declaring metric variables
2023-11-26 08:24:00,277:INFO:Importing untrained model
2023-11-26 08:24:00,277:INFO:Ridge Classifier Imported successfully
2023-11-26 08:24:00,278:INFO:Starting cross validation
2023-11-26 08:24:00,278:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:24:00,285:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 08:24:00,292:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 08:24:00,299:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 08:24:00,306:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 08:24:00,313:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 08:24:00,316:INFO:Calculating mean and std
2023-11-26 08:24:00,316:INFO:Creating metrics dataframe
2023-11-26 08:24:00,318:INFO:Uploading results into container
2023-11-26 08:24:00,318:INFO:Uploading model into container now
2023-11-26 08:24:00,318:INFO:_master_model_container: 6
2023-11-26 08:24:00,318:INFO:_display_container: 2
2023-11-26 08:24:00,319:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8781, solver='auto',
                tol=0.0001)
2023-11-26 08:24:00,319:INFO:create_model() successfully completed......................................
2023-11-26 08:24:00,366:INFO:SubProcess create_model() end ==================================
2023-11-26 08:24:00,366:INFO:Creating metrics dataframe
2023-11-26 08:24:00,369:INFO:Initializing Quadratic Discriminant Analysis
2023-11-26 08:24:00,369:INFO:Total runtime is 0.012901747226715088 minutes
2023-11-26 08:24:00,369:INFO:SubProcess create_model() called ==================================
2023-11-26 08:24:00,369:INFO:Initializing create_model()
2023-11-26 08:24:00,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4a5d7f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:24:00,370:INFO:Checking exceptions
2023-11-26 08:24:00,370:INFO:Importing libraries
2023-11-26 08:24:00,370:INFO:Copying training dataset
2023-11-26 08:24:00,371:INFO:Defining folds
2023-11-26 08:24:00,371:INFO:Declaring metric variables
2023-11-26 08:24:00,371:INFO:Importing untrained model
2023-11-26 08:24:00,372:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-26 08:24:00,372:INFO:Starting cross validation
2023-11-26 08:24:00,372:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:24:00,410:INFO:Calculating mean and std
2023-11-26 08:24:00,411:INFO:Creating metrics dataframe
2023-11-26 08:24:00,412:INFO:Uploading results into container
2023-11-26 08:24:00,412:INFO:Uploading model into container now
2023-11-26 08:24:00,413:INFO:_master_model_container: 7
2023-11-26 08:24:00,413:INFO:_display_container: 2
2023-11-26 08:24:00,413:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-26 08:24:00,413:INFO:create_model() successfully completed......................................
2023-11-26 08:24:00,459:INFO:SubProcess create_model() end ==================================
2023-11-26 08:24:00,460:INFO:Creating metrics dataframe
2023-11-26 08:24:00,462:INFO:Initializing Ada Boost Classifier
2023-11-26 08:24:00,462:INFO:Total runtime is 0.014450188477834065 minutes
2023-11-26 08:24:00,462:INFO:SubProcess create_model() called ==================================
2023-11-26 08:24:00,462:INFO:Initializing create_model()
2023-11-26 08:24:00,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4a5d7f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:24:00,463:INFO:Checking exceptions
2023-11-26 08:24:00,463:INFO:Importing libraries
2023-11-26 08:24:00,463:INFO:Copying training dataset
2023-11-26 08:24:00,464:INFO:Defining folds
2023-11-26 08:24:00,464:INFO:Declaring metric variables
2023-11-26 08:24:00,464:INFO:Importing untrained model
2023-11-26 08:24:00,464:INFO:Ada Boost Classifier Imported successfully
2023-11-26 08:24:00,465:INFO:Starting cross validation
2023-11-26 08:24:00,465:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:24:00,645:INFO:Calculating mean and std
2023-11-26 08:24:00,645:INFO:Creating metrics dataframe
2023-11-26 08:24:00,647:INFO:Uploading results into container
2023-11-26 08:24:00,647:INFO:Uploading model into container now
2023-11-26 08:24:00,647:INFO:_master_model_container: 8
2023-11-26 08:24:00,647:INFO:_display_container: 2
2023-11-26 08:24:00,648:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=8781)
2023-11-26 08:24:00,648:INFO:create_model() successfully completed......................................
2023-11-26 08:24:00,699:INFO:SubProcess create_model() end ==================================
2023-11-26 08:24:00,700:INFO:Creating metrics dataframe
2023-11-26 08:24:00,702:INFO:Initializing Linear Discriminant Analysis
2023-11-26 08:24:00,702:INFO:Total runtime is 0.018451046943664548 minutes
2023-11-26 08:24:00,702:INFO:SubProcess create_model() called ==================================
2023-11-26 08:24:00,702:INFO:Initializing create_model()
2023-11-26 08:24:00,703:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4a5d7f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:24:00,703:INFO:Checking exceptions
2023-11-26 08:24:00,703:INFO:Importing libraries
2023-11-26 08:24:00,703:INFO:Copying training dataset
2023-11-26 08:24:00,704:INFO:Defining folds
2023-11-26 08:24:00,705:INFO:Declaring metric variables
2023-11-26 08:24:00,705:INFO:Importing untrained model
2023-11-26 08:24:00,705:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 08:24:00,705:INFO:Starting cross validation
2023-11-26 08:24:00,706:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:24:00,745:INFO:Calculating mean and std
2023-11-26 08:24:00,745:INFO:Creating metrics dataframe
2023-11-26 08:24:00,747:INFO:Uploading results into container
2023-11-26 08:24:00,747:INFO:Uploading model into container now
2023-11-26 08:24:00,747:INFO:_master_model_container: 9
2023-11-26 08:24:00,747:INFO:_display_container: 2
2023-11-26 08:24:00,748:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 08:24:00,748:INFO:create_model() successfully completed......................................
2023-11-26 08:24:00,795:INFO:SubProcess create_model() end ==================================
2023-11-26 08:24:00,795:INFO:Creating metrics dataframe
2023-11-26 08:24:00,798:INFO:Initializing Extra Trees Classifier
2023-11-26 08:24:00,798:INFO:Total runtime is 0.02004722754160563 minutes
2023-11-26 08:24:00,798:INFO:SubProcess create_model() called ==================================
2023-11-26 08:24:00,798:INFO:Initializing create_model()
2023-11-26 08:24:00,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4a5d7f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:24:00,798:INFO:Checking exceptions
2023-11-26 08:24:00,799:INFO:Importing libraries
2023-11-26 08:24:00,799:INFO:Copying training dataset
2023-11-26 08:24:00,800:INFO:Defining folds
2023-11-26 08:24:00,800:INFO:Declaring metric variables
2023-11-26 08:24:00,800:INFO:Importing untrained model
2023-11-26 08:24:00,800:INFO:Extra Trees Classifier Imported successfully
2023-11-26 08:24:00,801:INFO:Starting cross validation
2023-11-26 08:24:00,801:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:24:01,495:INFO:Calculating mean and std
2023-11-26 08:24:01,495:INFO:Creating metrics dataframe
2023-11-26 08:24:01,497:INFO:Uploading results into container
2023-11-26 08:24:01,497:INFO:Uploading model into container now
2023-11-26 08:24:01,498:INFO:_master_model_container: 10
2023-11-26 08:24:01,498:INFO:_display_container: 2
2023-11-26 08:24:01,498:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=8781, verbose=0, warm_start=False)
2023-11-26 08:24:01,498:INFO:create_model() successfully completed......................................
2023-11-26 08:24:01,547:INFO:SubProcess create_model() end ==================================
2023-11-26 08:24:01,548:INFO:Creating metrics dataframe
2023-11-26 08:24:01,550:INFO:Initializing Light Gradient Boosting Machine
2023-11-26 08:24:01,550:INFO:Total runtime is 0.03258324861526489 minutes
2023-11-26 08:24:01,550:INFO:SubProcess create_model() called ==================================
2023-11-26 08:24:01,550:INFO:Initializing create_model()
2023-11-26 08:24:01,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4a5d7f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:24:01,551:INFO:Checking exceptions
2023-11-26 08:24:01,551:INFO:Importing libraries
2023-11-26 08:24:01,551:INFO:Copying training dataset
2023-11-26 08:24:01,552:INFO:Defining folds
2023-11-26 08:24:01,552:INFO:Declaring metric variables
2023-11-26 08:24:01,552:INFO:Importing untrained model
2023-11-26 08:24:01,553:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-26 08:24:01,553:INFO:Starting cross validation
2023-11-26 08:24:01,553:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:24:01,558:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 08:24:01,559:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000121 seconds.
2023-11-26 08:24:01,559:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 08:24:01,559:INFO:[LightGBM] [Info] Total Bins 485
2023-11-26 08:24:01,559:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 08:24:01,560:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 08:24:01,560:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 08:24:01,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,626:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 08:24:01,626:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.
2023-11-26 08:24:01,626:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 08:24:01,626:INFO:[LightGBM] [Info] Total Bins 487
2023-11-26 08:24:01,627:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 08:24:01,627:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 08:24:01,627:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 08:24:01,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,707:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 60
2023-11-26 08:24:01,707:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.
2023-11-26 08:24:01,707:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 08:24:01,707:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 08:24:01,708:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 08:24:01,708:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491525 -> initscore=-0.033902
2023-11-26 08:24:01,708:INFO:[LightGBM] [Info] Start training from score -0.033902
2023-11-26 08:24:01,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,802:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 08:24:01,803:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.
2023-11-26 08:24:01,803:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 08:24:01,803:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 08:24:01,803:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 08:24:01,804:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 08:24:01,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,870:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 08:24:01,870:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000076 seconds.
2023-11-26 08:24:01,871:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 08:24:01,871:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 08:24:01,871:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 08:24:01,871:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 08:24:01,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:24:01,926:INFO:Calculating mean and std
2023-11-26 08:24:01,926:INFO:Creating metrics dataframe
2023-11-26 08:24:01,928:INFO:Uploading results into container
2023-11-26 08:24:01,928:INFO:Uploading model into container now
2023-11-26 08:24:01,929:INFO:_master_model_container: 11
2023-11-26 08:24:01,929:INFO:_display_container: 2
2023-11-26 08:24:01,929:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8781, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-26 08:24:01,929:INFO:create_model() successfully completed......................................
2023-11-26 08:24:01,978:INFO:SubProcess create_model() end ==================================
2023-11-26 08:24:01,978:INFO:Creating metrics dataframe
2023-11-26 08:24:01,980:INFO:Initializing Dummy Classifier
2023-11-26 08:24:01,980:INFO:Total runtime is 0.0397579550743103 minutes
2023-11-26 08:24:01,981:INFO:SubProcess create_model() called ==================================
2023-11-26 08:24:01,981:INFO:Initializing create_model()
2023-11-26 08:24:01,981:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4a5d7f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:24:01,981:INFO:Checking exceptions
2023-11-26 08:24:01,981:INFO:Importing libraries
2023-11-26 08:24:01,981:INFO:Copying training dataset
2023-11-26 08:24:01,983:INFO:Defining folds
2023-11-26 08:24:01,983:INFO:Declaring metric variables
2023-11-26 08:24:01,983:INFO:Importing untrained model
2023-11-26 08:24:01,983:INFO:Dummy Classifier Imported successfully
2023-11-26 08:24:01,983:INFO:Starting cross validation
2023-11-26 08:24:01,984:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:24:01,990:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:24:01,997:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:24:02,003:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:24:02,010:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:24:02,016:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:24:02,018:INFO:Calculating mean and std
2023-11-26 08:24:02,018:INFO:Creating metrics dataframe
2023-11-26 08:24:02,019:INFO:Uploading results into container
2023-11-26 08:24:02,019:INFO:Uploading model into container now
2023-11-26 08:24:02,020:INFO:_master_model_container: 12
2023-11-26 08:24:02,020:INFO:_display_container: 2
2023-11-26 08:24:02,020:INFO:DummyClassifier(constant=None, random_state=8781, strategy='prior')
2023-11-26 08:24:02,020:INFO:create_model() successfully completed......................................
2023-11-26 08:24:02,070:INFO:SubProcess create_model() end ==================================
2023-11-26 08:24:02,070:INFO:Creating metrics dataframe
2023-11-26 08:24:02,073:INFO:Initializing create_model()
2023-11-26 08:24:02,073:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8781, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:24:02,073:INFO:Checking exceptions
2023-11-26 08:24:02,074:INFO:Importing libraries
2023-11-26 08:24:02,074:INFO:Copying training dataset
2023-11-26 08:24:02,075:INFO:Defining folds
2023-11-26 08:24:02,075:INFO:Declaring metric variables
2023-11-26 08:24:02,075:INFO:Importing untrained model
2023-11-26 08:24:02,076:INFO:Declaring custom model
2023-11-26 08:24:02,076:INFO:Ridge Classifier Imported successfully
2023-11-26 08:24:02,076:INFO:Cross validation set to False
2023-11-26 08:24:02,076:INFO:Fitting Model
2023-11-26 08:24:02,080:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8781, solver='auto',
                tol=0.0001)
2023-11-26 08:24:02,080:INFO:create_model() successfully completed......................................
2023-11-26 08:24:02,129:INFO:_master_model_container: 12
2023-11-26 08:24:02,130:INFO:_display_container: 2
2023-11-26 08:24:02,130:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8781, solver='auto',
                tol=0.0001)
2023-11-26 08:24:02,130:INFO:compare_models() successfully completed......................................
2023-11-26 08:24:43,061:INFO:Initializing create_model()
2023-11-26 08:24:43,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:24:43,065:INFO:Checking exceptions
2023-11-26 08:24:43,076:INFO:Importing libraries
2023-11-26 08:24:43,077:INFO:Copying training dataset
2023-11-26 08:24:43,081:INFO:Defining folds
2023-11-26 08:24:43,082:INFO:Declaring metric variables
2023-11-26 08:24:43,082:INFO:Importing untrained model
2023-11-26 08:24:43,083:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 08:24:43,083:INFO:Starting cross validation
2023-11-26 08:24:43,085:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:24:43,141:INFO:Calculating mean and std
2023-11-26 08:24:43,142:INFO:Creating metrics dataframe
2023-11-26 08:24:43,143:INFO:Finalizing model
2023-11-26 08:24:43,147:INFO:Uploading results into container
2023-11-26 08:24:43,148:INFO:Uploading model into container now
2023-11-26 08:24:43,152:INFO:_master_model_container: 13
2023-11-26 08:24:43,152:INFO:_display_container: 3
2023-11-26 08:24:43,153:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 08:24:43,153:INFO:create_model() successfully completed......................................
2023-11-26 08:24:57,375:INFO:Initializing tune_model()
2023-11-26 08:24:57,376:INFO:tune_model(estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>)
2023-11-26 08:24:57,376:INFO:Checking exceptions
2023-11-26 08:24:57,380:INFO:Copying training dataset
2023-11-26 08:24:57,383:INFO:Checking base model
2023-11-26 08:24:57,384:INFO:Base model : Linear Discriminant Analysis
2023-11-26 08:24:57,384:INFO:Declaring metric variables
2023-11-26 08:24:57,385:INFO:Defining Hyperparameters
2023-11-26 08:24:57,463:INFO:Tuning with n_jobs=-1
2023-11-26 08:24:57,463:INFO:Initializing RandomizedSearchCV
2023-11-26 08:24:58,845:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
5 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 571, in fit
    self._validate_params()
  File "/usr/local/lib/python3.8/site-packages/sklearn/base.py", line 600, in _validate_params
    validate_parameter_constraints(
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'shrinkage' parameter of LinearDiscriminantAnalysis must be a str among {'auto'}, a float in the range [0, 1] or None. Got 'empirical' instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-11-26 08:24:58,848:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.99333333        nan 0.99809524 0.99809524 0.99809524 0.99904762
 1.         1.         0.99904762 0.99904762]
  warnings.warn(

2023-11-26 08:24:58,849:INFO:best_params: {'actual_estimator__solver': 'eigen', 'actual_estimator__shrinkage': 0.1}
2023-11-26 08:24:58,849:INFO:Hyperparameter search completed
2023-11-26 08:24:58,850:INFO:SubProcess create_model() called ==================================
2023-11-26 08:24:58,851:INFO:Initializing create_model()
2023-11-26 08:24:58,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff8f4c7be0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'eigen', 'shrinkage': 0.1})
2023-11-26 08:24:58,851:INFO:Checking exceptions
2023-11-26 08:24:58,851:INFO:Importing libraries
2023-11-26 08:24:58,851:INFO:Copying training dataset
2023-11-26 08:24:58,855:INFO:Defining folds
2023-11-26 08:24:58,855:INFO:Declaring metric variables
2023-11-26 08:24:58,855:INFO:Importing untrained model
2023-11-26 08:24:58,855:INFO:Declaring custom model
2023-11-26 08:24:58,856:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 08:24:58,856:INFO:Starting cross validation
2023-11-26 08:24:58,856:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:24:58,932:INFO:Calculating mean and std
2023-11-26 08:24:58,932:INFO:Creating metrics dataframe
2023-11-26 08:24:58,936:INFO:Finalizing model
2023-11-26 08:24:58,947:INFO:Uploading results into container
2023-11-26 08:24:58,948:INFO:Uploading model into container now
2023-11-26 08:24:58,948:INFO:_master_model_container: 14
2023-11-26 08:24:58,949:INFO:_display_container: 4
2023-11-26 08:24:58,949:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001)
2023-11-26 08:24:58,949:INFO:create_model() successfully completed......................................
2023-11-26 08:24:59,022:INFO:SubProcess create_model() end ==================================
2023-11-26 08:24:59,023:INFO:choose_better activated
2023-11-26 08:24:59,023:INFO:SubProcess create_model() called ==================================
2023-11-26 08:24:59,023:INFO:Initializing create_model()
2023-11-26 08:24:59,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:24:59,024:INFO:Checking exceptions
2023-11-26 08:24:59,024:INFO:Importing libraries
2023-11-26 08:24:59,024:INFO:Copying training dataset
2023-11-26 08:24:59,026:INFO:Defining folds
2023-11-26 08:24:59,026:INFO:Declaring metric variables
2023-11-26 08:24:59,026:INFO:Importing untrained model
2023-11-26 08:24:59,026:INFO:Declaring custom model
2023-11-26 08:24:59,026:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 08:24:59,027:INFO:Starting cross validation
2023-11-26 08:24:59,027:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:24:59,065:INFO:Calculating mean and std
2023-11-26 08:24:59,065:INFO:Creating metrics dataframe
2023-11-26 08:24:59,066:INFO:Finalizing model
2023-11-26 08:24:59,070:INFO:Uploading results into container
2023-11-26 08:24:59,070:INFO:Uploading model into container now
2023-11-26 08:24:59,070:INFO:_master_model_container: 15
2023-11-26 08:24:59,071:INFO:_display_container: 5
2023-11-26 08:24:59,071:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 08:24:59,071:INFO:create_model() successfully completed......................................
2023-11-26 08:24:59,119:INFO:SubProcess create_model() end ==================================
2023-11-26 08:24:59,119:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9981
2023-11-26 08:24:59,119:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001) result for AUC is 1.0
2023-11-26 08:24:59,120:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001) is best model
2023-11-26 08:24:59,120:INFO:choose_better completed
2023-11-26 08:24:59,124:INFO:_master_model_container: 15
2023-11-26 08:24:59,124:INFO:_display_container: 4
2023-11-26 08:24:59,124:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001)
2023-11-26 08:24:59,124:INFO:tune_model() successfully completed......................................
2023-11-26 08:25:07,866:INFO:Initializing evaluate_model()
2023-11-26 08:25:07,867:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-26 08:25:07,873:INFO:Initializing plot_model()
2023-11-26 08:25:07,873:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, system=True)
2023-11-26 08:25:07,873:INFO:Checking exceptions
2023-11-26 08:25:07,874:INFO:Preloading libraries
2023-11-26 08:25:07,874:INFO:Copying training dataset
2023-11-26 08:25:07,874:INFO:Plot type: pipeline
2023-11-26 08:25:07,915:INFO:Visual Rendered Successfully
2023-11-26 08:25:08,005:INFO:plot_model() successfully completed......................................
2023-11-26 08:25:15,885:INFO:Initializing finalize_model()
2023-11-26 08:25:15,887:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-11-26 08:25:15,888:INFO:Finalizing LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001)
2023-11-26 08:25:15,893:INFO:Initializing create_model()
2023-11-26 08:25:15,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='eigen',
                           store_covariance=False, tol=0.0001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:25:15,894:INFO:Checking exceptions
2023-11-26 08:25:15,896:INFO:Importing libraries
2023-11-26 08:25:15,897:INFO:Copying training dataset
2023-11-26 08:25:15,897:INFO:Defining folds
2023-11-26 08:25:15,897:INFO:Declaring metric variables
2023-11-26 08:25:15,898:INFO:Importing untrained model
2023-11-26 08:25:15,898:INFO:Declaring custom model
2023-11-26 08:25:15,899:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 08:25:15,901:INFO:Cross validation set to False
2023-11-26 08:25:15,901:INFO:Fitting Model
2023-11-26 08:25:15,916:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 08:25:15,916:INFO:create_model() successfully completed......................................
2023-11-26 08:25:15,996:INFO:_master_model_container: 15
2023-11-26 08:25:15,996:INFO:_display_container: 4
2023-11-26 08:25:15,998:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 08:25:15,998:INFO:finalize_model() successfully completed......................................
2023-11-26 08:25:28,683:INFO:Initializing predict_model()
2023-11-26 08:25:28,685:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff5465f9d0>)
2023-11-26 08:25:28,686:INFO:Checking exceptions
2023-11-26 08:25:28,686:INFO:Preloading libraries
2023-11-26 08:27:10,842:INFO:Initializing predict_model()
2023-11-26 08:27:10,847:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff527b30d0>)
2023-11-26 08:27:10,848:INFO:Checking exceptions
2023-11-26 08:27:10,848:INFO:Preloading libraries
2023-11-26 08:28:11,271:INFO:Initializing predict_model()
2023-11-26 08:28:11,272:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff52753af0>)
2023-11-26 08:28:11,272:INFO:Checking exceptions
2023-11-26 08:28:11,272:INFO:Preloading libraries
2023-11-26 08:28:15,321:INFO:Initializing predict_model()
2023-11-26 08:28:15,321:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff5465f9d0>)
2023-11-26 08:28:15,322:INFO:Checking exceptions
2023-11-26 08:28:15,322:INFO:Preloading libraries
2023-11-26 08:37:11,470:INFO:Initializing predict_model()
2023-11-26 08:37:11,472:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff527b30d0>)
2023-11-26 08:37:11,473:INFO:Checking exceptions
2023-11-26 08:37:11,473:INFO:Preloading libraries
2023-11-26 08:42:15,466:INFO:Initializing predict_model()
2023-11-26 08:42:15,469:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff5465f9d0>)
2023-11-26 08:42:15,470:INFO:Checking exceptions
2023-11-26 08:42:15,470:INFO:Preloading libraries
2023-11-26 08:42:15,475:INFO:Set up data.
2023-11-26 08:42:15,493:INFO:Set up index.
2023-11-26 08:42:15,528:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-11-26 08:42:15,530:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:42:15,532:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:43:10,959:INFO:Initializing predict_model()
2023-11-26 08:43:10,960:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff5465f9d0>)
2023-11-26 08:43:10,961:INFO:Checking exceptions
2023-11-26 08:43:10,961:INFO:Preloading libraries
2023-11-26 08:43:10,962:INFO:Set up data.
2023-11-26 08:43:10,970:INFO:Set up index.
2023-11-26 08:43:10,979:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-11-26 08:43:10,981:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:43:10,982:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:43:21,809:INFO:Initializing predict_model()
2023-11-26 08:43:21,811:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff5465f9d0>)
2023-11-26 08:43:21,814:INFO:Checking exceptions
2023-11-26 08:43:21,815:INFO:Preloading libraries
2023-11-26 08:43:21,816:INFO:Set up data.
2023-11-26 08:43:21,826:INFO:Set up index.
2023-11-26 08:43:21,837:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-11-26 08:43:21,839:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:43:21,840:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:43:37,697:INFO:Initializing predict_model()
2023-11-26 08:43:37,698:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff5465f9d0>)
2023-11-26 08:43:37,699:INFO:Checking exceptions
2023-11-26 08:43:37,699:INFO:Preloading libraries
2023-11-26 08:43:37,700:INFO:Set up data.
2023-11-26 08:43:37,703:INFO:Set up index.
2023-11-26 08:43:37,709:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-11-26 08:43:37,710:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:43:37,711:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:45:56,034:INFO:Initializing predict_model()
2023-11-26 08:45:56,037:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff5465f9d0>)
2023-11-26 08:45:56,037:INFO:Checking exceptions
2023-11-26 08:45:56,038:INFO:Preloading libraries
2023-11-26 08:45:56,041:INFO:Set up data.
2023-11-26 08:45:56,052:INFO:Set up index.
2023-11-26 08:45:56,065:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-11-26 08:45:56,067:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:45:56,068:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:58:44,799:INFO:Initializing predict_model()
2023-11-26 08:58:44,837:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff5465f9d0>)
2023-11-26 08:58:44,837:INFO:Checking exceptions
2023-11-26 08:58:44,838:INFO:Preloading libraries
2023-11-26 08:58:44,842:INFO:Set up data.
2023-11-26 08:58:44,866:INFO:Set up index.
2023-11-26 08:58:44,882:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-11-26 08:58:44,884:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:58:44,885:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:58:51,527:INFO:Initializing predict_model()
2023-11-26 08:58:51,528:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff8f4c7f40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff5465f9d0>)
2023-11-26 08:58:51,528:INFO:Checking exceptions
2023-11-26 08:58:51,528:INFO:Preloading libraries
2023-11-26 08:58:51,529:INFO:Set up data.
2023-11-26 08:58:51,538:INFO:Set up index.
2023-11-26 08:58:51,548:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-11-26 08:58:51,550:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:58:51,551:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:59:45,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,450:INFO:PyCaret ClassificationExperiment
2023-11-26 08:59:45,451:INFO:Logging name: clf-default-name
2023-11-26 08:59:45,451:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-26 08:59:45,451:INFO:version 3.2.0
2023-11-26 08:59:45,451:INFO:Initializing setup()
2023-11-26 08:59:45,451:INFO:self.USI: 4735
2023-11-26 08:59:45,451:INFO:self._variable_keys: {'_ml_usecase', 'exp_id', 'log_plots_param', 'data', 'idx', '_available_plots', 'exp_name_log', 'fix_imbalance', 'html_param', 'USI', 'seed', 'logging_param', 'n_jobs_param', 'X_test', 'X', 'target_param', 'is_multiclass', 'X_train', 'gpu_param', 'y_train', 'fold_shuffle_param', 'gpu_n_jobs_param', 'y_test', 'fold_generator', 'fold_groups_param', 'y', 'pipeline', 'memory'}
2023-11-26 08:59:45,451:INFO:Checking environment
2023-11-26 08:59:45,451:INFO:python_version: 3.8.18
2023-11-26 08:59:45,451:INFO:python_build: ('default', 'Nov 21 2023 19:36:55')
2023-11-26 08:59:45,452:INFO:machine: aarch64
2023-11-26 08:59:45,452:INFO:platform: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 08:59:45,453:INFO:Memory: svmem(total=8225304576, available=7073771520, percent=14.0, used=942092288, free=3506696192, active=2019295232, inactive=2082516992, buffers=117362688, cached=3659153408, shared=1863680, slab=445325312)
2023-11-26 08:59:45,453:INFO:Physical Core: 12
2023-11-26 08:59:45,453:INFO:Logical Core: 12
2023-11-26 08:59:45,453:INFO:Checking libraries
2023-11-26 08:59:45,453:INFO:System:
2023-11-26 08:59:45,454:INFO:    python: 3.8.18 (default, Nov 21 2023, 19:36:55)  [GCC 12.2.0]
2023-11-26 08:59:45,454:INFO:executable: /usr/local/bin/python
2023-11-26 08:59:45,454:INFO:   machine: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 08:59:45,454:INFO:PyCaret required dependencies:
2023-11-26 08:59:45,465:INFO:                 pip: 23.3.1
2023-11-26 08:59:45,465:INFO:          setuptools: 57.5.0
2023-11-26 08:59:45,466:INFO:             pycaret: 3.2.0
2023-11-26 08:59:45,466:INFO:             IPython: 8.12.3
2023-11-26 08:59:45,466:INFO:          ipywidgets: 8.1.1
2023-11-26 08:59:45,466:INFO:                tqdm: 4.66.1
2023-11-26 08:59:45,466:INFO:               numpy: 1.24.4
2023-11-26 08:59:45,466:INFO:              pandas: 1.5.3
2023-11-26 08:59:45,466:INFO:              jinja2: 3.1.2
2023-11-26 08:59:45,466:INFO:               scipy: 1.10.1
2023-11-26 08:59:45,467:INFO:              joblib: 1.3.2
2023-11-26 08:59:45,467:INFO:             sklearn: 1.2.2
2023-11-26 08:59:45,467:INFO:                pyod: 1.1.2
2023-11-26 08:59:45,467:INFO:            imblearn: 0.11.0
2023-11-26 08:59:45,467:INFO:   category_encoders: 2.6.3
2023-11-26 08:59:45,467:INFO:            lightgbm: 4.1.0
2023-11-26 08:59:45,467:INFO:               numba: 0.58.1
2023-11-26 08:59:45,467:INFO:            requests: 2.31.0
2023-11-26 08:59:45,467:INFO:          matplotlib: 3.6.0
2023-11-26 08:59:45,468:INFO:          scikitplot: 0.3.7
2023-11-26 08:59:45,468:INFO:         yellowbrick: 1.5
2023-11-26 08:59:45,468:INFO:              plotly: 5.18.0
2023-11-26 08:59:45,468:INFO:    plotly-resampler: Not installed
2023-11-26 08:59:45,468:INFO:             kaleido: 0.2.1
2023-11-26 08:59:45,468:INFO:           schemdraw: 0.15
2023-11-26 08:59:45,468:INFO:         statsmodels: 0.14.0
2023-11-26 08:59:45,468:INFO:              sktime: 0.21.1
2023-11-26 08:59:45,468:INFO:               tbats: 1.1.3
2023-11-26 08:59:45,468:INFO:            pmdarima: 2.0.4
2023-11-26 08:59:45,468:INFO:              psutil: 5.9.6
2023-11-26 08:59:45,469:INFO:          markupsafe: 2.1.3
2023-11-26 08:59:45,469:INFO:             pickle5: Not installed
2023-11-26 08:59:45,469:INFO:         cloudpickle: 3.0.0
2023-11-26 08:59:45,469:INFO:         deprecation: 2.1.0
2023-11-26 08:59:45,469:INFO:              xxhash: 3.4.1
2023-11-26 08:59:45,469:INFO:           wurlitzer: 3.0.3
2023-11-26 08:59:45,469:INFO:PyCaret optional dependencies:
2023-11-26 08:59:45,480:INFO:                shap: Not installed
2023-11-26 08:59:45,480:INFO:           interpret: Not installed
2023-11-26 08:59:45,481:INFO:                umap: Not installed
2023-11-26 08:59:45,481:INFO:     ydata_profiling: Not installed
2023-11-26 08:59:45,481:INFO:  explainerdashboard: Not installed
2023-11-26 08:59:45,481:INFO:             autoviz: Not installed
2023-11-26 08:59:45,481:INFO:           fairlearn: Not installed
2023-11-26 08:59:45,481:INFO:          deepchecks: Not installed
2023-11-26 08:59:45,481:INFO:             xgboost: Not installed
2023-11-26 08:59:45,481:INFO:            catboost: Not installed
2023-11-26 08:59:45,481:INFO:              kmodes: Not installed
2023-11-26 08:59:45,482:INFO:             mlxtend: Not installed
2023-11-26 08:59:45,482:INFO:       statsforecast: Not installed
2023-11-26 08:59:45,482:INFO:        tune_sklearn: Not installed
2023-11-26 08:59:45,482:INFO:                 ray: Not installed
2023-11-26 08:59:45,482:INFO:            hyperopt: Not installed
2023-11-26 08:59:45,482:INFO:              optuna: Not installed
2023-11-26 08:59:45,482:INFO:               skopt: Not installed
2023-11-26 08:59:45,482:INFO:              mlflow: Not installed
2023-11-26 08:59:45,482:INFO:              gradio: Not installed
2023-11-26 08:59:45,482:INFO:             fastapi: Not installed
2023-11-26 08:59:45,483:INFO:             uvicorn: Not installed
2023-11-26 08:59:45,483:INFO:              m2cgen: Not installed
2023-11-26 08:59:45,483:INFO:           evidently: Not installed
2023-11-26 08:59:45,483:INFO:               fugue: Not installed
2023-11-26 08:59:45,483:INFO:           streamlit: Not installed
2023-11-26 08:59:45,483:INFO:             prophet: Not installed
2023-11-26 08:59:45,483:INFO:None
2023-11-26 08:59:45,483:INFO:Set up GPU usage.
2023-11-26 08:59:45,483:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,483:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-26 08:59:45,484:INFO:Set up data.
2023-11-26 08:59:45,488:INFO:Set up folding strategy.
2023-11-26 08:59:45,488:INFO:Set up train/test split.
2023-11-26 08:59:45,490:INFO:Set up index.
2023-11-26 08:59:45,490:INFO:Assigning column types.
2023-11-26 08:59:45,491:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-26 08:59:45,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,509:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 08:59:45,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,510:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,511:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 08:59:45,511:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,521:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,523:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,524:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:59:45,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:59:45,543:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,562:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 08:59:45,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,562:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 08:59:45,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,572:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,574:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:59:45,579:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:59:45,580:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-26 08:59:45,580:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,597:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,598:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 08:59:45,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,607:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,609:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,609:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:59:45,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:59:45,614:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,633:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 08:59:45,633:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,644:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,644:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:59:45,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:59:45,649:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-26 08:59:45,649:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,668:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,677:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,679:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:59:45,683:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:59:45,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,702:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,702:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,713:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,714:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:59:45,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:59:45,719:INFO:Preparing preprocessing pipeline...
2023-11-26 08:59:45,720:INFO:Set up simple imputation.
2023-11-26 08:59:45,729:INFO:Finished creating preprocessing pipeline.
2023-11-26 08:59:45,731:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-26 08:59:45,731:INFO:Creating final display dataframe.
2023-11-26 08:59:45,754:INFO:Setup _display_container:                     Description             Value
0                    Session id              8234
1                        Target            target
2                   Target type            Binary
3           Original data shape         (210, 13)
4        Transformed data shape         (210, 13)
5   Transformed train set shape         (147, 13)
6    Transformed test set shape          (63, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              4735
2023-11-26 08:59:45,756:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,774:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,784:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:59:45,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:59:45,792:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,811:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,812:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,823:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:45,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:59:45,828:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 08:59:45,829:INFO:setup() successfully completed in 0.38s...............
2023-11-26 08:59:45,829:INFO:Initializing compare_models()
2023-11-26 08:59:45,829:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-26 08:59:45,829:INFO:Checking exceptions
2023-11-26 08:59:45,831:INFO:Preparing display monitor
2023-11-26 08:59:45,833:INFO:Initializing Logistic Regression
2023-11-26 08:59:45,833:INFO:Total runtime is 2.5828679402669272e-06 minutes
2023-11-26 08:59:45,834:INFO:SubProcess create_model() called ==================================
2023-11-26 08:59:45,834:INFO:Initializing create_model()
2023-11-26 08:59:45,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff754199d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:59:45,834:INFO:Checking exceptions
2023-11-26 08:59:45,834:INFO:Importing libraries
2023-11-26 08:59:45,834:INFO:Copying training dataset
2023-11-26 08:59:45,836:INFO:Defining folds
2023-11-26 08:59:45,836:INFO:Declaring metric variables
2023-11-26 08:59:45,836:INFO:Importing untrained model
2023-11-26 08:59:45,836:INFO:Logistic Regression Imported successfully
2023-11-26 08:59:45,836:INFO:Starting cross validation
2023-11-26 08:59:45,837:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:59:45,895:INFO:Calculating mean and std
2023-11-26 08:59:45,895:INFO:Creating metrics dataframe
2023-11-26 08:59:45,897:INFO:Uploading results into container
2023-11-26 08:59:45,897:INFO:Uploading model into container now
2023-11-26 08:59:45,898:INFO:_master_model_container: 1
2023-11-26 08:59:45,898:INFO:_display_container: 2
2023-11-26 08:59:45,898:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8234, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-26 08:59:45,899:INFO:create_model() successfully completed......................................
2023-11-26 08:59:45,938:INFO:SubProcess create_model() end ==================================
2023-11-26 08:59:45,939:INFO:Creating metrics dataframe
2023-11-26 08:59:45,941:INFO:Initializing K Neighbors Classifier
2023-11-26 08:59:45,941:INFO:Total runtime is 0.0017931540807088215 minutes
2023-11-26 08:59:45,941:INFO:SubProcess create_model() called ==================================
2023-11-26 08:59:45,941:INFO:Initializing create_model()
2023-11-26 08:59:45,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff754199d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:59:45,941:INFO:Checking exceptions
2023-11-26 08:59:45,942:INFO:Importing libraries
2023-11-26 08:59:45,942:INFO:Copying training dataset
2023-11-26 08:59:45,943:INFO:Defining folds
2023-11-26 08:59:45,943:INFO:Declaring metric variables
2023-11-26 08:59:45,943:INFO:Importing untrained model
2023-11-26 08:59:45,944:INFO:K Neighbors Classifier Imported successfully
2023-11-26 08:59:45,944:INFO:Starting cross validation
2023-11-26 08:59:45,944:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:59:46,129:INFO:Calculating mean and std
2023-11-26 08:59:46,129:INFO:Creating metrics dataframe
2023-11-26 08:59:46,131:INFO:Uploading results into container
2023-11-26 08:59:46,131:INFO:Uploading model into container now
2023-11-26 08:59:46,132:INFO:_master_model_container: 2
2023-11-26 08:59:46,132:INFO:_display_container: 2
2023-11-26 08:59:46,132:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-26 08:59:46,132:INFO:create_model() successfully completed......................................
2023-11-26 08:59:46,165:INFO:SubProcess create_model() end ==================================
2023-11-26 08:59:46,166:INFO:Creating metrics dataframe
2023-11-26 08:59:46,168:INFO:Initializing Naive Bayes
2023-11-26 08:59:46,168:INFO:Total runtime is 0.005579717953999837 minutes
2023-11-26 08:59:46,168:INFO:SubProcess create_model() called ==================================
2023-11-26 08:59:46,168:INFO:Initializing create_model()
2023-11-26 08:59:46,169:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff754199d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:59:46,169:INFO:Checking exceptions
2023-11-26 08:59:46,169:INFO:Importing libraries
2023-11-26 08:59:46,169:INFO:Copying training dataset
2023-11-26 08:59:46,170:INFO:Defining folds
2023-11-26 08:59:46,170:INFO:Declaring metric variables
2023-11-26 08:59:46,170:INFO:Importing untrained model
2023-11-26 08:59:46,171:INFO:Naive Bayes Imported successfully
2023-11-26 08:59:46,171:INFO:Starting cross validation
2023-11-26 08:59:46,171:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:59:46,207:INFO:Calculating mean and std
2023-11-26 08:59:46,208:INFO:Creating metrics dataframe
2023-11-26 08:59:46,209:INFO:Uploading results into container
2023-11-26 08:59:46,209:INFO:Uploading model into container now
2023-11-26 08:59:46,210:INFO:_master_model_container: 3
2023-11-26 08:59:46,210:INFO:_display_container: 2
2023-11-26 08:59:46,210:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-26 08:59:46,210:INFO:create_model() successfully completed......................................
2023-11-26 08:59:46,237:INFO:SubProcess create_model() end ==================================
2023-11-26 08:59:46,237:INFO:Creating metrics dataframe
2023-11-26 08:59:46,239:INFO:Initializing Decision Tree Classifier
2023-11-26 08:59:46,239:INFO:Total runtime is 0.006769506136576334 minutes
2023-11-26 08:59:46,240:INFO:SubProcess create_model() called ==================================
2023-11-26 08:59:46,240:INFO:Initializing create_model()
2023-11-26 08:59:46,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff754199d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:59:46,240:INFO:Checking exceptions
2023-11-26 08:59:46,241:INFO:Importing libraries
2023-11-26 08:59:46,241:INFO:Copying training dataset
2023-11-26 08:59:46,242:INFO:Defining folds
2023-11-26 08:59:46,242:INFO:Declaring metric variables
2023-11-26 08:59:46,243:INFO:Importing untrained model
2023-11-26 08:59:46,243:INFO:Decision Tree Classifier Imported successfully
2023-11-26 08:59:46,243:INFO:Starting cross validation
2023-11-26 08:59:46,244:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:59:46,282:INFO:Calculating mean and std
2023-11-26 08:59:46,282:INFO:Creating metrics dataframe
2023-11-26 08:59:46,283:INFO:Uploading results into container
2023-11-26 08:59:46,284:INFO:Uploading model into container now
2023-11-26 08:59:46,284:INFO:_master_model_container: 4
2023-11-26 08:59:46,284:INFO:_display_container: 2
2023-11-26 08:59:46,284:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8234, splitter='best')
2023-11-26 08:59:46,284:INFO:create_model() successfully completed......................................
2023-11-26 08:59:46,311:INFO:SubProcess create_model() end ==================================
2023-11-26 08:59:46,312:INFO:Creating metrics dataframe
2023-11-26 08:59:46,314:INFO:Initializing SVM - Linear Kernel
2023-11-26 08:59:46,314:INFO:Total runtime is 0.008012839158376058 minutes
2023-11-26 08:59:46,314:INFO:SubProcess create_model() called ==================================
2023-11-26 08:59:46,314:INFO:Initializing create_model()
2023-11-26 08:59:46,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff754199d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:59:46,315:INFO:Checking exceptions
2023-11-26 08:59:46,315:INFO:Importing libraries
2023-11-26 08:59:46,315:INFO:Copying training dataset
2023-11-26 08:59:46,316:INFO:Defining folds
2023-11-26 08:59:46,316:INFO:Declaring metric variables
2023-11-26 08:59:46,316:INFO:Importing untrained model
2023-11-26 08:59:46,317:INFO:SVM - Linear Kernel Imported successfully
2023-11-26 08:59:46,317:INFO:Starting cross validation
2023-11-26 08:59:46,317:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:59:46,323:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 08:59:46,330:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 08:59:46,337:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 08:59:46,344:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 08:59:46,351:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 08:59:46,354:INFO:Calculating mean and std
2023-11-26 08:59:46,354:INFO:Creating metrics dataframe
2023-11-26 08:59:46,355:INFO:Uploading results into container
2023-11-26 08:59:46,356:INFO:Uploading model into container now
2023-11-26 08:59:46,356:INFO:_master_model_container: 5
2023-11-26 08:59:46,356:INFO:_display_container: 2
2023-11-26 08:59:46,356:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8234, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-26 08:59:46,356:INFO:create_model() successfully completed......................................
2023-11-26 08:59:46,383:INFO:SubProcess create_model() end ==================================
2023-11-26 08:59:46,383:INFO:Creating metrics dataframe
2023-11-26 08:59:46,385:INFO:Initializing Ridge Classifier
2023-11-26 08:59:46,385:INFO:Total runtime is 0.009202086925506591 minutes
2023-11-26 08:59:46,386:INFO:SubProcess create_model() called ==================================
2023-11-26 08:59:46,386:INFO:Initializing create_model()
2023-11-26 08:59:46,386:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff754199d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:59:46,386:INFO:Checking exceptions
2023-11-26 08:59:46,386:INFO:Importing libraries
2023-11-26 08:59:46,386:INFO:Copying training dataset
2023-11-26 08:59:46,387:INFO:Defining folds
2023-11-26 08:59:46,387:INFO:Declaring metric variables
2023-11-26 08:59:46,388:INFO:Importing untrained model
2023-11-26 08:59:46,388:INFO:Ridge Classifier Imported successfully
2023-11-26 08:59:46,388:INFO:Starting cross validation
2023-11-26 08:59:46,388:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:59:46,394:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 08:59:46,401:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 08:59:46,408:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 08:59:46,415:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 08:59:46,422:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 08:59:46,425:INFO:Calculating mean and std
2023-11-26 08:59:46,425:INFO:Creating metrics dataframe
2023-11-26 08:59:46,427:INFO:Uploading results into container
2023-11-26 08:59:46,427:INFO:Uploading model into container now
2023-11-26 08:59:46,427:INFO:_master_model_container: 6
2023-11-26 08:59:46,427:INFO:_display_container: 2
2023-11-26 08:59:46,427:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8234, solver='auto',
                tol=0.0001)
2023-11-26 08:59:46,428:INFO:create_model() successfully completed......................................
2023-11-26 08:59:46,454:INFO:SubProcess create_model() end ==================================
2023-11-26 08:59:46,454:INFO:Creating metrics dataframe
2023-11-26 08:59:46,456:INFO:Initializing Quadratic Discriminant Analysis
2023-11-26 08:59:46,456:INFO:Total runtime is 0.010387738545735676 minutes
2023-11-26 08:59:46,457:INFO:SubProcess create_model() called ==================================
2023-11-26 08:59:46,457:INFO:Initializing create_model()
2023-11-26 08:59:46,457:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff754199d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:59:46,457:INFO:Checking exceptions
2023-11-26 08:59:46,457:INFO:Importing libraries
2023-11-26 08:59:46,457:INFO:Copying training dataset
2023-11-26 08:59:46,458:INFO:Defining folds
2023-11-26 08:59:46,459:INFO:Declaring metric variables
2023-11-26 08:59:46,459:INFO:Importing untrained model
2023-11-26 08:59:46,459:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-26 08:59:46,459:INFO:Starting cross validation
2023-11-26 08:59:46,460:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:59:46,497:INFO:Calculating mean and std
2023-11-26 08:59:46,498:INFO:Creating metrics dataframe
2023-11-26 08:59:46,499:INFO:Uploading results into container
2023-11-26 08:59:46,499:INFO:Uploading model into container now
2023-11-26 08:59:46,499:INFO:_master_model_container: 7
2023-11-26 08:59:46,499:INFO:_display_container: 2
2023-11-26 08:59:46,500:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-26 08:59:46,500:INFO:create_model() successfully completed......................................
2023-11-26 08:59:46,525:INFO:SubProcess create_model() end ==================================
2023-11-26 08:59:46,526:INFO:Creating metrics dataframe
2023-11-26 08:59:46,528:INFO:Initializing Ada Boost Classifier
2023-11-26 08:59:46,528:INFO:Total runtime is 0.011579847335815428 minutes
2023-11-26 08:59:46,528:INFO:SubProcess create_model() called ==================================
2023-11-26 08:59:46,528:INFO:Initializing create_model()
2023-11-26 08:59:46,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff754199d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:59:46,529:INFO:Checking exceptions
2023-11-26 08:59:46,529:INFO:Importing libraries
2023-11-26 08:59:46,529:INFO:Copying training dataset
2023-11-26 08:59:46,530:INFO:Defining folds
2023-11-26 08:59:46,530:INFO:Declaring metric variables
2023-11-26 08:59:46,531:INFO:Importing untrained model
2023-11-26 08:59:46,531:INFO:Ada Boost Classifier Imported successfully
2023-11-26 08:59:46,531:INFO:Starting cross validation
2023-11-26 08:59:46,531:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:59:46,707:INFO:Calculating mean and std
2023-11-26 08:59:46,708:INFO:Creating metrics dataframe
2023-11-26 08:59:46,709:INFO:Uploading results into container
2023-11-26 08:59:46,710:INFO:Uploading model into container now
2023-11-26 08:59:46,710:INFO:_master_model_container: 8
2023-11-26 08:59:46,710:INFO:_display_container: 2
2023-11-26 08:59:46,710:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=8234)
2023-11-26 08:59:46,710:INFO:create_model() successfully completed......................................
2023-11-26 08:59:46,738:INFO:SubProcess create_model() end ==================================
2023-11-26 08:59:46,738:INFO:Creating metrics dataframe
2023-11-26 08:59:46,740:INFO:Initializing Linear Discriminant Analysis
2023-11-26 08:59:46,740:INFO:Total runtime is 0.015117331345876056 minutes
2023-11-26 08:59:46,740:INFO:SubProcess create_model() called ==================================
2023-11-26 08:59:46,741:INFO:Initializing create_model()
2023-11-26 08:59:46,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff754199d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:59:46,741:INFO:Checking exceptions
2023-11-26 08:59:46,741:INFO:Importing libraries
2023-11-26 08:59:46,741:INFO:Copying training dataset
2023-11-26 08:59:46,742:INFO:Defining folds
2023-11-26 08:59:46,742:INFO:Declaring metric variables
2023-11-26 08:59:46,743:INFO:Importing untrained model
2023-11-26 08:59:46,743:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 08:59:46,743:INFO:Starting cross validation
2023-11-26 08:59:46,743:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:59:46,781:INFO:Calculating mean and std
2023-11-26 08:59:46,781:INFO:Creating metrics dataframe
2023-11-26 08:59:46,783:INFO:Uploading results into container
2023-11-26 08:59:46,783:INFO:Uploading model into container now
2023-11-26 08:59:46,783:INFO:_master_model_container: 9
2023-11-26 08:59:46,783:INFO:_display_container: 2
2023-11-26 08:59:46,784:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 08:59:46,784:INFO:create_model() successfully completed......................................
2023-11-26 08:59:46,815:INFO:SubProcess create_model() end ==================================
2023-11-26 08:59:46,816:INFO:Creating metrics dataframe
2023-11-26 08:59:46,818:INFO:Initializing Extra Trees Classifier
2023-11-26 08:59:46,818:INFO:Total runtime is 0.016417340437571207 minutes
2023-11-26 08:59:46,818:INFO:SubProcess create_model() called ==================================
2023-11-26 08:59:46,819:INFO:Initializing create_model()
2023-11-26 08:59:46,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff754199d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:59:46,819:INFO:Checking exceptions
2023-11-26 08:59:46,819:INFO:Importing libraries
2023-11-26 08:59:46,819:INFO:Copying training dataset
2023-11-26 08:59:46,820:INFO:Defining folds
2023-11-26 08:59:46,820:INFO:Declaring metric variables
2023-11-26 08:59:46,821:INFO:Importing untrained model
2023-11-26 08:59:46,821:INFO:Extra Trees Classifier Imported successfully
2023-11-26 08:59:46,821:INFO:Starting cross validation
2023-11-26 08:59:46,821:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:59:47,519:INFO:Calculating mean and std
2023-11-26 08:59:47,520:INFO:Creating metrics dataframe
2023-11-26 08:59:47,522:INFO:Uploading results into container
2023-11-26 08:59:47,522:INFO:Uploading model into container now
2023-11-26 08:59:47,523:INFO:_master_model_container: 10
2023-11-26 08:59:47,523:INFO:_display_container: 2
2023-11-26 08:59:47,523:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=8234, verbose=0, warm_start=False)
2023-11-26 08:59:47,523:INFO:create_model() successfully completed......................................
2023-11-26 08:59:47,555:INFO:SubProcess create_model() end ==================================
2023-11-26 08:59:47,555:INFO:Creating metrics dataframe
2023-11-26 08:59:47,558:INFO:Initializing Light Gradient Boosting Machine
2023-11-26 08:59:47,558:INFO:Total runtime is 0.028747137387593588 minutes
2023-11-26 08:59:47,558:INFO:SubProcess create_model() called ==================================
2023-11-26 08:59:47,558:INFO:Initializing create_model()
2023-11-26 08:59:47,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff754199d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:59:47,559:INFO:Checking exceptions
2023-11-26 08:59:47,559:INFO:Importing libraries
2023-11-26 08:59:47,559:INFO:Copying training dataset
2023-11-26 08:59:47,560:INFO:Defining folds
2023-11-26 08:59:47,560:INFO:Declaring metric variables
2023-11-26 08:59:47,560:INFO:Importing untrained model
2023-11-26 08:59:47,561:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-26 08:59:47,561:INFO:Starting cross validation
2023-11-26 08:59:47,561:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:59:47,566:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 08:59:47,567:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000056 seconds.
2023-11-26 08:59:47,567:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-26 08:59:47,567:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-26 08:59:47,567:INFO:[LightGBM] [Info] Total Bins 488
2023-11-26 08:59:47,567:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 08:59:47,568:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 08:59:47,568:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 08:59:47,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,617:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 08:59:47,617:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.
2023-11-26 08:59:47,617:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 08:59:47,618:INFO:[LightGBM] [Info] Total Bins 488
2023-11-26 08:59:47,618:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 08:59:47,618:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 08:59:47,618:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 08:59:47,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,736:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 08:59:47,737:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000089 seconds.
2023-11-26 08:59:47,737:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 08:59:47,737:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 08:59:47,737:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 08:59:47,737:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 08:59:47,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,811:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 08:59:47,813:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000261 seconds.
2023-11-26 08:59:47,814:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-26 08:59:47,814:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-26 08:59:47,814:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 08:59:47,814:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 08:59:47,815:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 08:59:47,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,903:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 60
2023-11-26 08:59:47,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.
2023-11-26 08:59:47,903:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 08:59:47,903:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 08:59:47,904:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 08:59:47,904:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491525 -> initscore=-0.033902
2023-11-26 08:59:47,904:INFO:[LightGBM] [Info] Start training from score -0.033902
2023-11-26 08:59:47,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 08:59:47,954:INFO:Calculating mean and std
2023-11-26 08:59:47,954:INFO:Creating metrics dataframe
2023-11-26 08:59:47,956:INFO:Uploading results into container
2023-11-26 08:59:47,956:INFO:Uploading model into container now
2023-11-26 08:59:47,956:INFO:_master_model_container: 11
2023-11-26 08:59:47,956:INFO:_display_container: 2
2023-11-26 08:59:47,957:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8234, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-26 08:59:47,957:INFO:create_model() successfully completed......................................
2023-11-26 08:59:47,989:INFO:SubProcess create_model() end ==================================
2023-11-26 08:59:47,989:INFO:Creating metrics dataframe
2023-11-26 08:59:47,991:INFO:Initializing Dummy Classifier
2023-11-26 08:59:47,991:INFO:Total runtime is 0.03596947590510051 minutes
2023-11-26 08:59:47,992:INFO:SubProcess create_model() called ==================================
2023-11-26 08:59:47,992:INFO:Initializing create_model()
2023-11-26 08:59:47,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff754199d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:59:47,992:INFO:Checking exceptions
2023-11-26 08:59:47,992:INFO:Importing libraries
2023-11-26 08:59:47,992:INFO:Copying training dataset
2023-11-26 08:59:47,993:INFO:Defining folds
2023-11-26 08:59:47,994:INFO:Declaring metric variables
2023-11-26 08:59:47,994:INFO:Importing untrained model
2023-11-26 08:59:47,994:INFO:Dummy Classifier Imported successfully
2023-11-26 08:59:47,994:INFO:Starting cross validation
2023-11-26 08:59:47,995:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:59:48,002:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:59:48,008:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:59:48,014:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:59:48,021:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:59:48,027:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 08:59:48,029:INFO:Calculating mean and std
2023-11-26 08:59:48,029:INFO:Creating metrics dataframe
2023-11-26 08:59:48,030:INFO:Uploading results into container
2023-11-26 08:59:48,030:INFO:Uploading model into container now
2023-11-26 08:59:48,031:INFO:_master_model_container: 12
2023-11-26 08:59:48,031:INFO:_display_container: 2
2023-11-26 08:59:48,031:INFO:DummyClassifier(constant=None, random_state=8234, strategy='prior')
2023-11-26 08:59:48,031:INFO:create_model() successfully completed......................................
2023-11-26 08:59:48,057:INFO:SubProcess create_model() end ==================================
2023-11-26 08:59:48,057:INFO:Creating metrics dataframe
2023-11-26 08:59:48,060:INFO:Initializing create_model()
2023-11-26 08:59:48,060:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:59:48,060:INFO:Checking exceptions
2023-11-26 08:59:48,060:INFO:Importing libraries
2023-11-26 08:59:48,061:INFO:Copying training dataset
2023-11-26 08:59:48,062:INFO:Defining folds
2023-11-26 08:59:48,062:INFO:Declaring metric variables
2023-11-26 08:59:48,062:INFO:Importing untrained model
2023-11-26 08:59:48,062:INFO:Declaring custom model
2023-11-26 08:59:48,062:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-26 08:59:48,063:INFO:Cross validation set to False
2023-11-26 08:59:48,063:INFO:Fitting Model
2023-11-26 08:59:48,066:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-26 08:59:48,066:INFO:create_model() successfully completed......................................
2023-11-26 08:59:48,098:INFO:_master_model_container: 12
2023-11-26 08:59:48,098:INFO:_display_container: 2
2023-11-26 08:59:48,098:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-26 08:59:48,098:INFO:compare_models() successfully completed......................................
2023-11-26 08:59:48,098:INFO:Initializing create_model()
2023-11-26 08:59:48,098:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:59:48,099:INFO:Checking exceptions
2023-11-26 08:59:48,099:INFO:Importing libraries
2023-11-26 08:59:48,099:INFO:Copying training dataset
2023-11-26 08:59:48,101:INFO:Defining folds
2023-11-26 08:59:48,101:INFO:Declaring metric variables
2023-11-26 08:59:48,101:INFO:Importing untrained model
2023-11-26 08:59:48,101:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 08:59:48,101:INFO:Starting cross validation
2023-11-26 08:59:48,102:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:59:48,139:INFO:Calculating mean and std
2023-11-26 08:59:48,140:INFO:Creating metrics dataframe
2023-11-26 08:59:48,140:INFO:Finalizing model
2023-11-26 08:59:48,144:INFO:Uploading results into container
2023-11-26 08:59:48,144:INFO:Uploading model into container now
2023-11-26 08:59:48,148:INFO:_master_model_container: 13
2023-11-26 08:59:48,148:INFO:_display_container: 3
2023-11-26 08:59:48,148:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 08:59:48,148:INFO:create_model() successfully completed......................................
2023-11-26 08:59:48,176:INFO:Initializing tune_model()
2023-11-26 08:59:48,176:INFO:tune_model(estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>)
2023-11-26 08:59:48,176:INFO:Checking exceptions
2023-11-26 08:59:48,177:INFO:Copying training dataset
2023-11-26 08:59:48,178:INFO:Checking base model
2023-11-26 08:59:48,178:INFO:Base model : Linear Discriminant Analysis
2023-11-26 08:59:48,179:INFO:Declaring metric variables
2023-11-26 08:59:48,179:INFO:Defining Hyperparameters
2023-11-26 08:59:48,206:INFO:Tuning with n_jobs=-1
2023-11-26 08:59:48,206:INFO:Initializing RandomizedSearchCV
2023-11-26 08:59:49,506:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
5 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
5 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 571, in fit
    self._validate_params()
  File "/usr/local/lib/python3.8/site-packages/sklearn/base.py", line 600, in _validate_params
    validate_parameter_constraints(
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'shrinkage' parameter of LinearDiscriminantAnalysis must be a str among {'auto'}, a float in the range [0, 1] or None. Got 'empirical' instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-11-26 08:59:49,509:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.99149206 1.         1.         1.         1.
 1.         1.         0.99809524 0.99809524]
  warnings.warn(

2023-11-26 08:59:49,511:INFO:best_params: {'actual_estimator__solver': 'eigen', 'actual_estimator__shrinkage': 0.0001}
2023-11-26 08:59:49,511:INFO:Hyperparameter search completed
2023-11-26 08:59:49,511:INFO:SubProcess create_model() called ==================================
2023-11-26 08:59:49,512:INFO:Initializing create_model()
2023-11-26 08:59:49,512:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff754199d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'eigen', 'shrinkage': 0.0001})
2023-11-26 08:59:49,512:INFO:Checking exceptions
2023-11-26 08:59:49,512:INFO:Importing libraries
2023-11-26 08:59:49,513:INFO:Copying training dataset
2023-11-26 08:59:49,515:INFO:Defining folds
2023-11-26 08:59:49,516:INFO:Declaring metric variables
2023-11-26 08:59:49,516:INFO:Importing untrained model
2023-11-26 08:59:49,516:INFO:Declaring custom model
2023-11-26 08:59:49,517:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 08:59:49,517:INFO:Starting cross validation
2023-11-26 08:59:49,518:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:59:49,575:INFO:Calculating mean and std
2023-11-26 08:59:49,576:INFO:Creating metrics dataframe
2023-11-26 08:59:49,579:INFO:Finalizing model
2023-11-26 08:59:49,591:INFO:Uploading results into container
2023-11-26 08:59:49,592:INFO:Uploading model into container now
2023-11-26 08:59:49,593:INFO:_master_model_container: 14
2023-11-26 08:59:49,593:INFO:_display_container: 4
2023-11-26 08:59:49,594:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.0001, solver='eigen',
                           store_covariance=False, tol=0.0001)
2023-11-26 08:59:49,594:INFO:create_model() successfully completed......................................
2023-11-26 08:59:49,643:INFO:SubProcess create_model() end ==================================
2023-11-26 08:59:49,643:INFO:choose_better activated
2023-11-26 08:59:49,643:INFO:SubProcess create_model() called ==================================
2023-11-26 08:59:49,644:INFO:Initializing create_model()
2023-11-26 08:59:49,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:59:49,644:INFO:Checking exceptions
2023-11-26 08:59:49,644:INFO:Importing libraries
2023-11-26 08:59:49,645:INFO:Copying training dataset
2023-11-26 08:59:49,646:INFO:Defining folds
2023-11-26 08:59:49,646:INFO:Declaring metric variables
2023-11-26 08:59:49,646:INFO:Importing untrained model
2023-11-26 08:59:49,646:INFO:Declaring custom model
2023-11-26 08:59:49,647:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 08:59:49,647:INFO:Starting cross validation
2023-11-26 08:59:49,647:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 08:59:49,686:INFO:Calculating mean and std
2023-11-26 08:59:49,687:INFO:Creating metrics dataframe
2023-11-26 08:59:49,687:INFO:Finalizing model
2023-11-26 08:59:49,691:INFO:Uploading results into container
2023-11-26 08:59:49,691:INFO:Uploading model into container now
2023-11-26 08:59:49,691:INFO:_master_model_container: 15
2023-11-26 08:59:49,692:INFO:_display_container: 5
2023-11-26 08:59:49,692:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 08:59:49,692:INFO:create_model() successfully completed......................................
2023-11-26 08:59:49,721:INFO:SubProcess create_model() end ==================================
2023-11-26 08:59:49,721:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 1.0
2023-11-26 08:59:49,722:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.0001, solver='eigen',
                           store_covariance=False, tol=0.0001) result for AUC is 1.0
2023-11-26 08:59:49,722:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) is best model
2023-11-26 08:59:49,722:INFO:choose_better completed
2023-11-26 08:59:49,722:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-11-26 08:59:49,726:INFO:_master_model_container: 15
2023-11-26 08:59:49,726:INFO:_display_container: 4
2023-11-26 08:59:49,726:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 08:59:49,726:INFO:tune_model() successfully completed......................................
2023-11-26 08:59:49,751:INFO:Initializing evaluate_model()
2023-11-26 08:59:49,752:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-26 08:59:49,754:INFO:Initializing plot_model()
2023-11-26 08:59:49,754:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, system=True)
2023-11-26 08:59:49,755:INFO:Checking exceptions
2023-11-26 08:59:49,755:INFO:Preloading libraries
2023-11-26 08:59:49,755:INFO:Copying training dataset
2023-11-26 08:59:49,755:INFO:Plot type: pipeline
2023-11-26 08:59:49,794:INFO:Visual Rendered Successfully
2023-11-26 08:59:49,854:INFO:plot_model() successfully completed......................................
2023-11-26 08:59:49,861:INFO:Initializing finalize_model()
2023-11-26 08:59:49,865:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-11-26 08:59:49,872:INFO:Finalizing LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 08:59:49,880:INFO:Initializing create_model()
2023-11-26 08:59:49,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffffb2938fd0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 08:59:49,881:INFO:Checking exceptions
2023-11-26 08:59:49,881:INFO:Importing libraries
2023-11-26 08:59:49,881:INFO:Copying training dataset
2023-11-26 08:59:49,882:INFO:Defining folds
2023-11-26 08:59:49,882:INFO:Declaring metric variables
2023-11-26 08:59:49,882:INFO:Importing untrained model
2023-11-26 08:59:49,882:INFO:Declaring custom model
2023-11-26 08:59:49,882:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 08:59:49,883:INFO:Cross validation set to False
2023-11-26 08:59:49,883:INFO:Fitting Model
2023-11-26 08:59:49,890:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 08:59:49,890:INFO:create_model() successfully completed......................................
2023-11-26 08:59:49,921:INFO:_master_model_container: 15
2023-11-26 08:59:49,922:INFO:_display_container: 4
2023-11-26 08:59:49,923:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 08:59:49,924:INFO:finalize_model() successfully completed......................................
2023-11-26 08:59:59,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:59,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:59,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 08:59:59,693:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,092:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,094:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,374:INFO:PyCaret ClassificationExperiment
2023-11-26 09:01:17,374:INFO:Logging name: clf-default-name
2023-11-26 09:01:17,374:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-26 09:01:17,374:INFO:version 3.2.0
2023-11-26 09:01:17,374:INFO:Initializing setup()
2023-11-26 09:01:17,374:INFO:self.USI: 7e78
2023-11-26 09:01:17,374:INFO:self._variable_keys: {'memory', 'y_test', 'fold_groups_param', '_available_plots', 'gpu_param', 'n_jobs_param', 'data', 'target_param', 'idx', 'y_train', 'is_multiclass', 'fix_imbalance', 'X_test', 'exp_id', 'fold_shuffle_param', 'y', 'fold_generator', 'gpu_n_jobs_param', '_ml_usecase', 'X_train', 'seed', 'html_param', 'pipeline', 'X', 'exp_name_log', 'logging_param', 'log_plots_param', 'USI'}
2023-11-26 09:01:17,375:INFO:Checking environment
2023-11-26 09:01:17,375:INFO:python_version: 3.8.18
2023-11-26 09:01:17,375:INFO:python_build: ('default', 'Nov 21 2023 19:36:55')
2023-11-26 09:01:17,375:INFO:machine: aarch64
2023-11-26 09:01:17,376:INFO:platform: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 09:01:17,376:INFO:Memory: svmem(total=8225304576, available=7058939904, percent=14.2, used=956915712, free=3491835904, active=2019606528, inactive=2087694336, buffers=117379072, cached=3659173888, shared=1871872, slab=444571648)
2023-11-26 09:01:17,377:INFO:Physical Core: 12
2023-11-26 09:01:17,377:INFO:Logical Core: 12
2023-11-26 09:01:17,377:INFO:Checking libraries
2023-11-26 09:01:17,377:INFO:System:
2023-11-26 09:01:17,377:INFO:    python: 3.8.18 (default, Nov 21 2023, 19:36:55)  [GCC 12.2.0]
2023-11-26 09:01:17,377:INFO:executable: /usr/local/bin/python
2023-11-26 09:01:17,377:INFO:   machine: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 09:01:17,377:INFO:PyCaret required dependencies:
2023-11-26 09:01:17,388:INFO:                 pip: 23.3.1
2023-11-26 09:01:17,388:INFO:          setuptools: 57.5.0
2023-11-26 09:01:17,389:INFO:             pycaret: 3.2.0
2023-11-26 09:01:17,389:INFO:             IPython: 8.12.3
2023-11-26 09:01:17,389:INFO:          ipywidgets: 8.1.1
2023-11-26 09:01:17,389:INFO:                tqdm: 4.66.1
2023-11-26 09:01:17,389:INFO:               numpy: 1.24.4
2023-11-26 09:01:17,389:INFO:              pandas: 1.5.3
2023-11-26 09:01:17,389:INFO:              jinja2: 3.1.2
2023-11-26 09:01:17,389:INFO:               scipy: 1.10.1
2023-11-26 09:01:17,389:INFO:              joblib: 1.3.2
2023-11-26 09:01:17,389:INFO:             sklearn: 1.2.2
2023-11-26 09:01:17,389:INFO:                pyod: 1.1.2
2023-11-26 09:01:17,390:INFO:            imblearn: 0.11.0
2023-11-26 09:01:17,390:INFO:   category_encoders: 2.6.3
2023-11-26 09:01:17,390:INFO:            lightgbm: 4.1.0
2023-11-26 09:01:17,390:INFO:               numba: 0.58.1
2023-11-26 09:01:17,390:INFO:            requests: 2.31.0
2023-11-26 09:01:17,390:INFO:          matplotlib: 3.6.0
2023-11-26 09:01:17,390:INFO:          scikitplot: 0.3.7
2023-11-26 09:01:17,390:INFO:         yellowbrick: 1.5
2023-11-26 09:01:17,390:INFO:              plotly: 5.18.0
2023-11-26 09:01:17,390:INFO:    plotly-resampler: Not installed
2023-11-26 09:01:17,390:INFO:             kaleido: 0.2.1
2023-11-26 09:01:17,390:INFO:           schemdraw: 0.15
2023-11-26 09:01:17,391:INFO:         statsmodels: 0.14.0
2023-11-26 09:01:17,391:INFO:              sktime: 0.21.1
2023-11-26 09:01:17,391:INFO:               tbats: 1.1.3
2023-11-26 09:01:17,391:INFO:            pmdarima: 2.0.4
2023-11-26 09:01:17,391:INFO:              psutil: 5.9.6
2023-11-26 09:01:17,391:INFO:          markupsafe: 2.1.3
2023-11-26 09:01:17,391:INFO:             pickle5: Not installed
2023-11-26 09:01:17,391:INFO:         cloudpickle: 3.0.0
2023-11-26 09:01:17,391:INFO:         deprecation: 2.1.0
2023-11-26 09:01:17,391:INFO:              xxhash: 3.4.1
2023-11-26 09:01:17,391:INFO:           wurlitzer: 3.0.3
2023-11-26 09:01:17,391:INFO:PyCaret optional dependencies:
2023-11-26 09:01:17,400:INFO:                shap: Not installed
2023-11-26 09:01:17,400:INFO:           interpret: Not installed
2023-11-26 09:01:17,400:INFO:                umap: Not installed
2023-11-26 09:01:17,401:INFO:     ydata_profiling: Not installed
2023-11-26 09:01:17,401:INFO:  explainerdashboard: Not installed
2023-11-26 09:01:17,401:INFO:             autoviz: Not installed
2023-11-26 09:01:17,401:INFO:           fairlearn: Not installed
2023-11-26 09:01:17,401:INFO:          deepchecks: Not installed
2023-11-26 09:01:17,401:INFO:             xgboost: Not installed
2023-11-26 09:01:17,401:INFO:            catboost: Not installed
2023-11-26 09:01:17,401:INFO:              kmodes: Not installed
2023-11-26 09:01:17,401:INFO:             mlxtend: Not installed
2023-11-26 09:01:17,401:INFO:       statsforecast: Not installed
2023-11-26 09:01:17,401:INFO:        tune_sklearn: Not installed
2023-11-26 09:01:17,401:INFO:                 ray: Not installed
2023-11-26 09:01:17,402:INFO:            hyperopt: Not installed
2023-11-26 09:01:17,402:INFO:              optuna: Not installed
2023-11-26 09:01:17,402:INFO:               skopt: Not installed
2023-11-26 09:01:17,402:INFO:              mlflow: Not installed
2023-11-26 09:01:17,402:INFO:              gradio: Not installed
2023-11-26 09:01:17,402:INFO:             fastapi: Not installed
2023-11-26 09:01:17,402:INFO:             uvicorn: Not installed
2023-11-26 09:01:17,402:INFO:              m2cgen: Not installed
2023-11-26 09:01:17,402:INFO:           evidently: Not installed
2023-11-26 09:01:17,402:INFO:               fugue: Not installed
2023-11-26 09:01:17,402:INFO:           streamlit: Not installed
2023-11-26 09:01:17,402:INFO:             prophet: Not installed
2023-11-26 09:01:17,402:INFO:None
2023-11-26 09:01:17,403:INFO:Set up GPU usage.
2023-11-26 09:01:17,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,403:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-26 09:01:17,403:INFO:Set up data.
2023-11-26 09:01:17,406:INFO:Set up folding strategy.
2023-11-26 09:01:17,406:INFO:Set up train/test split.
2023-11-26 09:01:17,408:INFO:Set up index.
2023-11-26 09:01:17,408:INFO:Assigning column types.
2023-11-26 09:01:17,409:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-26 09:01:17,409:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,427:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 09:01:17,428:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,428:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,429:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:01:17,429:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,439:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,441:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:01:17,458:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:01:17,459:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,477:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 09:01:17,477:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,477:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,478:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:01:17,478:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,488:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:01:17,493:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:01:17,493:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-26 09:01:17,494:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,514:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,514:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,514:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:01:17,515:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,524:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,526:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:01:17,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:01:17,531:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,549:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,550:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:01:17,550:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,559:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,560:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:01:17,564:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:01:17,565:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-26 09:01:17,565:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,582:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,582:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,583:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:01:17,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:01:17,598:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,616:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,616:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,616:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,627:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,627:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:01:17,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:01:17,633:INFO:Preparing preprocessing pipeline...
2023-11-26 09:01:17,634:INFO:Set up simple imputation.
2023-11-26 09:01:17,643:INFO:Finished creating preprocessing pipeline.
2023-11-26 09:01:17,645:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-26 09:01:17,645:INFO:Creating final display dataframe.
2023-11-26 09:01:17,672:INFO:Setup _display_container:                     Description             Value
0                    Session id              4206
1                        Target            target
2                   Target type            Binary
3           Original data shape         (210, 13)
4        Transformed data shape         (210, 13)
5   Transformed train set shape         (147, 13)
6    Transformed test set shape          (63, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              7e78
2023-11-26 09:01:17,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,703:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,704:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,705:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:01:17,709:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:01:17,709:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,727:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,727:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,728:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,737:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:01:17,739:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:01:17,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:01:17,745:INFO:setup() successfully completed in 0.37s...............
2023-11-26 09:01:17,745:INFO:Initializing compare_models()
2023-11-26 09:01:17,745:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-26 09:01:17,745:INFO:Checking exceptions
2023-11-26 09:01:17,747:INFO:Preparing display monitor
2023-11-26 09:01:17,748:INFO:Initializing Logistic Regression
2023-11-26 09:01:17,749:INFO:Total runtime is 3.1034151713053387e-06 minutes
2023-11-26 09:01:17,749:INFO:SubProcess create_model() called ==================================
2023-11-26 09:01:17,749:INFO:Initializing create_model()
2023-11-26 09:01:17,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4b9d2b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:01:17,749:INFO:Checking exceptions
2023-11-26 09:01:17,749:INFO:Importing libraries
2023-11-26 09:01:17,749:INFO:Copying training dataset
2023-11-26 09:01:17,751:INFO:Defining folds
2023-11-26 09:01:17,751:INFO:Declaring metric variables
2023-11-26 09:01:17,751:INFO:Importing untrained model
2023-11-26 09:01:17,751:INFO:Logistic Regression Imported successfully
2023-11-26 09:01:17,751:INFO:Starting cross validation
2023-11-26 09:01:17,752:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:01:17,812:INFO:Calculating mean and std
2023-11-26 09:01:17,812:INFO:Creating metrics dataframe
2023-11-26 09:01:17,814:INFO:Uploading results into container
2023-11-26 09:01:17,814:INFO:Uploading model into container now
2023-11-26 09:01:17,814:INFO:_master_model_container: 1
2023-11-26 09:01:17,815:INFO:_display_container: 2
2023-11-26 09:01:17,815:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4206, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-26 09:01:17,815:INFO:create_model() successfully completed......................................
2023-11-26 09:01:17,852:INFO:SubProcess create_model() end ==================================
2023-11-26 09:01:17,852:INFO:Creating metrics dataframe
2023-11-26 09:01:17,855:INFO:Initializing K Neighbors Classifier
2023-11-26 09:01:17,855:INFO:Total runtime is 0.0017748435338338215 minutes
2023-11-26 09:01:17,855:INFO:SubProcess create_model() called ==================================
2023-11-26 09:01:17,855:INFO:Initializing create_model()
2023-11-26 09:01:17,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4b9d2b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:01:17,856:INFO:Checking exceptions
2023-11-26 09:01:17,856:INFO:Importing libraries
2023-11-26 09:01:17,856:INFO:Copying training dataset
2023-11-26 09:01:17,857:INFO:Defining folds
2023-11-26 09:01:17,858:INFO:Declaring metric variables
2023-11-26 09:01:17,858:INFO:Importing untrained model
2023-11-26 09:01:17,858:INFO:K Neighbors Classifier Imported successfully
2023-11-26 09:01:17,858:INFO:Starting cross validation
2023-11-26 09:01:17,859:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:01:18,039:INFO:Calculating mean and std
2023-11-26 09:01:18,039:INFO:Creating metrics dataframe
2023-11-26 09:01:18,041:INFO:Uploading results into container
2023-11-26 09:01:18,041:INFO:Uploading model into container now
2023-11-26 09:01:18,041:INFO:_master_model_container: 2
2023-11-26 09:01:18,041:INFO:_display_container: 2
2023-11-26 09:01:18,042:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-26 09:01:18,042:INFO:create_model() successfully completed......................................
2023-11-26 09:01:18,071:INFO:SubProcess create_model() end ==================================
2023-11-26 09:01:18,071:INFO:Creating metrics dataframe
2023-11-26 09:01:18,074:INFO:Initializing Naive Bayes
2023-11-26 09:01:18,074:INFO:Total runtime is 0.005422910054524739 minutes
2023-11-26 09:01:18,074:INFO:SubProcess create_model() called ==================================
2023-11-26 09:01:18,074:INFO:Initializing create_model()
2023-11-26 09:01:18,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4b9d2b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:01:18,075:INFO:Checking exceptions
2023-11-26 09:01:18,075:INFO:Importing libraries
2023-11-26 09:01:18,075:INFO:Copying training dataset
2023-11-26 09:01:18,076:INFO:Defining folds
2023-11-26 09:01:18,076:INFO:Declaring metric variables
2023-11-26 09:01:18,076:INFO:Importing untrained model
2023-11-26 09:01:18,077:INFO:Naive Bayes Imported successfully
2023-11-26 09:01:18,077:INFO:Starting cross validation
2023-11-26 09:01:18,077:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:01:18,114:INFO:Calculating mean and std
2023-11-26 09:01:18,115:INFO:Creating metrics dataframe
2023-11-26 09:01:18,116:INFO:Uploading results into container
2023-11-26 09:01:18,116:INFO:Uploading model into container now
2023-11-26 09:01:18,117:INFO:_master_model_container: 3
2023-11-26 09:01:18,117:INFO:_display_container: 2
2023-11-26 09:01:18,117:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-26 09:01:18,117:INFO:create_model() successfully completed......................................
2023-11-26 09:01:18,143:INFO:SubProcess create_model() end ==================================
2023-11-26 09:01:18,143:INFO:Creating metrics dataframe
2023-11-26 09:01:18,146:INFO:Initializing Decision Tree Classifier
2023-11-26 09:01:18,146:INFO:Total runtime is 0.006620176633199056 minutes
2023-11-26 09:01:18,146:INFO:SubProcess create_model() called ==================================
2023-11-26 09:01:18,146:INFO:Initializing create_model()
2023-11-26 09:01:18,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4b9d2b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:01:18,146:INFO:Checking exceptions
2023-11-26 09:01:18,146:INFO:Importing libraries
2023-11-26 09:01:18,146:INFO:Copying training dataset
2023-11-26 09:01:18,148:INFO:Defining folds
2023-11-26 09:01:18,148:INFO:Declaring metric variables
2023-11-26 09:01:18,148:INFO:Importing untrained model
2023-11-26 09:01:18,148:INFO:Decision Tree Classifier Imported successfully
2023-11-26 09:01:18,148:INFO:Starting cross validation
2023-11-26 09:01:18,149:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:01:18,188:INFO:Calculating mean and std
2023-11-26 09:01:18,188:INFO:Creating metrics dataframe
2023-11-26 09:01:18,189:INFO:Uploading results into container
2023-11-26 09:01:18,190:INFO:Uploading model into container now
2023-11-26 09:01:18,190:INFO:_master_model_container: 4
2023-11-26 09:01:18,190:INFO:_display_container: 2
2023-11-26 09:01:18,190:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4206, splitter='best')
2023-11-26 09:01:18,190:INFO:create_model() successfully completed......................................
2023-11-26 09:01:18,217:INFO:SubProcess create_model() end ==================================
2023-11-26 09:01:18,218:INFO:Creating metrics dataframe
2023-11-26 09:01:18,220:INFO:Initializing SVM - Linear Kernel
2023-11-26 09:01:18,220:INFO:Total runtime is 0.00785768429438273 minutes
2023-11-26 09:01:18,220:INFO:SubProcess create_model() called ==================================
2023-11-26 09:01:18,220:INFO:Initializing create_model()
2023-11-26 09:01:18,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4b9d2b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:01:18,221:INFO:Checking exceptions
2023-11-26 09:01:18,221:INFO:Importing libraries
2023-11-26 09:01:18,221:INFO:Copying training dataset
2023-11-26 09:01:18,222:INFO:Defining folds
2023-11-26 09:01:18,222:INFO:Declaring metric variables
2023-11-26 09:01:18,222:INFO:Importing untrained model
2023-11-26 09:01:18,223:INFO:SVM - Linear Kernel Imported successfully
2023-11-26 09:01:18,223:INFO:Starting cross validation
2023-11-26 09:01:18,223:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:01:18,230:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:01:18,236:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:01:18,243:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:01:18,250:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:01:18,256:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:01:18,259:INFO:Calculating mean and std
2023-11-26 09:01:18,259:INFO:Creating metrics dataframe
2023-11-26 09:01:18,261:INFO:Uploading results into container
2023-11-26 09:01:18,261:INFO:Uploading model into container now
2023-11-26 09:01:18,261:INFO:_master_model_container: 5
2023-11-26 09:01:18,261:INFO:_display_container: 2
2023-11-26 09:01:18,262:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4206, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-26 09:01:18,262:INFO:create_model() successfully completed......................................
2023-11-26 09:01:18,289:INFO:SubProcess create_model() end ==================================
2023-11-26 09:01:18,289:INFO:Creating metrics dataframe
2023-11-26 09:01:18,291:INFO:Initializing Ridge Classifier
2023-11-26 09:01:18,291:INFO:Total runtime is 0.009046610196431477 minutes
2023-11-26 09:01:18,291:INFO:SubProcess create_model() called ==================================
2023-11-26 09:01:18,292:INFO:Initializing create_model()
2023-11-26 09:01:18,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4b9d2b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:01:18,292:INFO:Checking exceptions
2023-11-26 09:01:18,292:INFO:Importing libraries
2023-11-26 09:01:18,292:INFO:Copying training dataset
2023-11-26 09:01:18,293:INFO:Defining folds
2023-11-26 09:01:18,293:INFO:Declaring metric variables
2023-11-26 09:01:18,294:INFO:Importing untrained model
2023-11-26 09:01:18,294:INFO:Ridge Classifier Imported successfully
2023-11-26 09:01:18,294:INFO:Starting cross validation
2023-11-26 09:01:18,294:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:01:18,301:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:01:18,308:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:01:18,315:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:01:18,321:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:01:18,328:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:01:18,331:INFO:Calculating mean and std
2023-11-26 09:01:18,331:INFO:Creating metrics dataframe
2023-11-26 09:01:18,333:INFO:Uploading results into container
2023-11-26 09:01:18,333:INFO:Uploading model into container now
2023-11-26 09:01:18,333:INFO:_master_model_container: 6
2023-11-26 09:01:18,333:INFO:_display_container: 2
2023-11-26 09:01:18,334:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4206, solver='auto',
                tol=0.0001)
2023-11-26 09:01:18,334:INFO:create_model() successfully completed......................................
2023-11-26 09:01:18,359:INFO:SubProcess create_model() end ==================================
2023-11-26 09:01:18,360:INFO:Creating metrics dataframe
2023-11-26 09:01:18,362:INFO:Initializing Quadratic Discriminant Analysis
2023-11-26 09:01:18,362:INFO:Total runtime is 0.010223066806793212 minutes
2023-11-26 09:01:18,362:INFO:SubProcess create_model() called ==================================
2023-11-26 09:01:18,362:INFO:Initializing create_model()
2023-11-26 09:01:18,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4b9d2b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:01:18,362:INFO:Checking exceptions
2023-11-26 09:01:18,363:INFO:Importing libraries
2023-11-26 09:01:18,363:INFO:Copying training dataset
2023-11-26 09:01:18,364:INFO:Defining folds
2023-11-26 09:01:18,364:INFO:Declaring metric variables
2023-11-26 09:01:18,364:INFO:Importing untrained model
2023-11-26 09:01:18,364:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-26 09:01:18,365:INFO:Starting cross validation
2023-11-26 09:01:18,365:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:01:18,402:INFO:Calculating mean and std
2023-11-26 09:01:18,402:INFO:Creating metrics dataframe
2023-11-26 09:01:18,404:INFO:Uploading results into container
2023-11-26 09:01:18,404:INFO:Uploading model into container now
2023-11-26 09:01:18,404:INFO:_master_model_container: 7
2023-11-26 09:01:18,404:INFO:_display_container: 2
2023-11-26 09:01:18,404:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-26 09:01:18,405:INFO:create_model() successfully completed......................................
2023-11-26 09:01:18,431:INFO:SubProcess create_model() end ==================================
2023-11-26 09:01:18,431:INFO:Creating metrics dataframe
2023-11-26 09:01:18,433:INFO:Initializing Ada Boost Classifier
2023-11-26 09:01:18,433:INFO:Total runtime is 0.01141547362009684 minutes
2023-11-26 09:01:18,434:INFO:SubProcess create_model() called ==================================
2023-11-26 09:01:18,434:INFO:Initializing create_model()
2023-11-26 09:01:18,434:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4b9d2b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:01:18,434:INFO:Checking exceptions
2023-11-26 09:01:18,434:INFO:Importing libraries
2023-11-26 09:01:18,434:INFO:Copying training dataset
2023-11-26 09:01:18,436:INFO:Defining folds
2023-11-26 09:01:18,436:INFO:Declaring metric variables
2023-11-26 09:01:18,436:INFO:Importing untrained model
2023-11-26 09:01:18,436:INFO:Ada Boost Classifier Imported successfully
2023-11-26 09:01:18,436:INFO:Starting cross validation
2023-11-26 09:01:18,437:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:01:18,610:INFO:Calculating mean and std
2023-11-26 09:01:18,610:INFO:Creating metrics dataframe
2023-11-26 09:01:18,611:INFO:Uploading results into container
2023-11-26 09:01:18,612:INFO:Uploading model into container now
2023-11-26 09:01:18,612:INFO:_master_model_container: 8
2023-11-26 09:01:18,612:INFO:_display_container: 2
2023-11-26 09:01:18,612:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=4206)
2023-11-26 09:01:18,612:INFO:create_model() successfully completed......................................
2023-11-26 09:01:18,641:INFO:SubProcess create_model() end ==================================
2023-11-26 09:01:18,641:INFO:Creating metrics dataframe
2023-11-26 09:01:18,643:INFO:Initializing Linear Discriminant Analysis
2023-11-26 09:01:18,643:INFO:Total runtime is 0.01491504907608032 minutes
2023-11-26 09:01:18,644:INFO:SubProcess create_model() called ==================================
2023-11-26 09:01:18,644:INFO:Initializing create_model()
2023-11-26 09:01:18,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4b9d2b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:01:18,644:INFO:Checking exceptions
2023-11-26 09:01:18,644:INFO:Importing libraries
2023-11-26 09:01:18,644:INFO:Copying training dataset
2023-11-26 09:01:18,645:INFO:Defining folds
2023-11-26 09:01:18,645:INFO:Declaring metric variables
2023-11-26 09:01:18,646:INFO:Importing untrained model
2023-11-26 09:01:18,646:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:01:18,646:INFO:Starting cross validation
2023-11-26 09:01:18,646:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:01:18,685:INFO:Calculating mean and std
2023-11-26 09:01:18,686:INFO:Creating metrics dataframe
2023-11-26 09:01:18,687:INFO:Uploading results into container
2023-11-26 09:01:18,688:INFO:Uploading model into container now
2023-11-26 09:01:18,688:INFO:_master_model_container: 9
2023-11-26 09:01:18,688:INFO:_display_container: 2
2023-11-26 09:01:18,688:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:01:18,688:INFO:create_model() successfully completed......................................
2023-11-26 09:01:18,716:INFO:SubProcess create_model() end ==================================
2023-11-26 09:01:18,716:INFO:Creating metrics dataframe
2023-11-26 09:01:18,718:INFO:Initializing Extra Trees Classifier
2023-11-26 09:01:18,718:INFO:Total runtime is 0.01616537570953369 minutes
2023-11-26 09:01:18,719:INFO:SubProcess create_model() called ==================================
2023-11-26 09:01:18,719:INFO:Initializing create_model()
2023-11-26 09:01:18,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4b9d2b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:01:18,719:INFO:Checking exceptions
2023-11-26 09:01:18,719:INFO:Importing libraries
2023-11-26 09:01:18,719:INFO:Copying training dataset
2023-11-26 09:01:18,721:INFO:Defining folds
2023-11-26 09:01:18,721:INFO:Declaring metric variables
2023-11-26 09:01:18,721:INFO:Importing untrained model
2023-11-26 09:01:18,721:INFO:Extra Trees Classifier Imported successfully
2023-11-26 09:01:18,721:INFO:Starting cross validation
2023-11-26 09:01:18,722:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:01:19,406:INFO:Calculating mean and std
2023-11-26 09:01:19,407:INFO:Creating metrics dataframe
2023-11-26 09:01:19,408:INFO:Uploading results into container
2023-11-26 09:01:19,409:INFO:Uploading model into container now
2023-11-26 09:01:19,409:INFO:_master_model_container: 10
2023-11-26 09:01:19,409:INFO:_display_container: 2
2023-11-26 09:01:19,410:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=4206, verbose=0, warm_start=False)
2023-11-26 09:01:19,410:INFO:create_model() successfully completed......................................
2023-11-26 09:01:19,438:INFO:SubProcess create_model() end ==================================
2023-11-26 09:01:19,438:INFO:Creating metrics dataframe
2023-11-26 09:01:19,441:INFO:Initializing Light Gradient Boosting Machine
2023-11-26 09:01:19,441:INFO:Total runtime is 0.02820491393407186 minutes
2023-11-26 09:01:19,441:INFO:SubProcess create_model() called ==================================
2023-11-26 09:01:19,441:INFO:Initializing create_model()
2023-11-26 09:01:19,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4b9d2b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:01:19,441:INFO:Checking exceptions
2023-11-26 09:01:19,442:INFO:Importing libraries
2023-11-26 09:01:19,442:INFO:Copying training dataset
2023-11-26 09:01:19,443:INFO:Defining folds
2023-11-26 09:01:19,443:INFO:Declaring metric variables
2023-11-26 09:01:19,443:INFO:Importing untrained model
2023-11-26 09:01:19,443:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-26 09:01:19,444:INFO:Starting cross validation
2023-11-26 09:01:19,444:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:01:19,449:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 09:01:19,450:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.
2023-11-26 09:01:19,450:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:01:19,450:INFO:[LightGBM] [Info] Total Bins 490
2023-11-26 09:01:19,451:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 09:01:19,451:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 09:01:19,451:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 09:01:19,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,495:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,501:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,518:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 09:01:19,518:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.
2023-11-26 09:01:19,518:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:01:19,518:INFO:[LightGBM] [Info] Total Bins 488
2023-11-26 09:01:19,519:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 09:01:19,519:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 09:01:19,519:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 09:01:19,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,637:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 60
2023-11-26 09:01:19,638:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000043 seconds.
2023-11-26 09:01:19,638:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:01:19,638:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 09:01:19,638:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 09:01:19,639:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491525 -> initscore=-0.033902
2023-11-26 09:01:19,639:INFO:[LightGBM] [Info] Start training from score -0.033902
2023-11-26 09:01:19,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,754:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 09:01:19,754:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.
2023-11-26 09:01:19,754:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:01:19,755:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 09:01:19,755:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 09:01:19,756:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 09:01:19,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,860:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 09:01:19,860:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.
2023-11-26 09:01:19,861:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:01:19,861:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 09:01:19,861:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 09:01:19,862:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 09:01:19,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:01:19,944:INFO:Calculating mean and std
2023-11-26 09:01:19,944:INFO:Creating metrics dataframe
2023-11-26 09:01:19,946:INFO:Uploading results into container
2023-11-26 09:01:19,946:INFO:Uploading model into container now
2023-11-26 09:01:19,946:INFO:_master_model_container: 11
2023-11-26 09:01:19,946:INFO:_display_container: 2
2023-11-26 09:01:19,947:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4206, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-26 09:01:19,947:INFO:create_model() successfully completed......................................
2023-11-26 09:01:19,975:INFO:SubProcess create_model() end ==================================
2023-11-26 09:01:19,976:INFO:Creating metrics dataframe
2023-11-26 09:01:19,978:INFO:Initializing Dummy Classifier
2023-11-26 09:01:19,978:INFO:Total runtime is 0.03715851704279582 minutes
2023-11-26 09:01:19,978:INFO:SubProcess create_model() called ==================================
2023-11-26 09:01:19,978:INFO:Initializing create_model()
2023-11-26 09:01:19,978:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff4b9d2b50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:01:19,979:INFO:Checking exceptions
2023-11-26 09:01:19,979:INFO:Importing libraries
2023-11-26 09:01:19,979:INFO:Copying training dataset
2023-11-26 09:01:19,980:INFO:Defining folds
2023-11-26 09:01:19,980:INFO:Declaring metric variables
2023-11-26 09:01:19,980:INFO:Importing untrained model
2023-11-26 09:01:19,980:INFO:Dummy Classifier Imported successfully
2023-11-26 09:01:19,981:INFO:Starting cross validation
2023-11-26 09:01:19,981:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:01:19,988:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:01:19,994:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:01:20,001:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:01:20,007:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:01:20,013:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:01:20,015:INFO:Calculating mean and std
2023-11-26 09:01:20,015:INFO:Creating metrics dataframe
2023-11-26 09:01:20,016:INFO:Uploading results into container
2023-11-26 09:01:20,017:INFO:Uploading model into container now
2023-11-26 09:01:20,017:INFO:_master_model_container: 12
2023-11-26 09:01:20,017:INFO:_display_container: 2
2023-11-26 09:01:20,017:INFO:DummyClassifier(constant=None, random_state=4206, strategy='prior')
2023-11-26 09:01:20,017:INFO:create_model() successfully completed......................................
2023-11-26 09:01:20,047:INFO:SubProcess create_model() end ==================================
2023-11-26 09:01:20,048:INFO:Creating metrics dataframe
2023-11-26 09:01:20,051:INFO:Initializing create_model()
2023-11-26 09:01:20,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4206, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:01:20,051:INFO:Checking exceptions
2023-11-26 09:01:20,051:INFO:Importing libraries
2023-11-26 09:01:20,052:INFO:Copying training dataset
2023-11-26 09:01:20,053:INFO:Defining folds
2023-11-26 09:01:20,053:INFO:Declaring metric variables
2023-11-26 09:01:20,053:INFO:Importing untrained model
2023-11-26 09:01:20,053:INFO:Declaring custom model
2023-11-26 09:01:20,053:INFO:Ridge Classifier Imported successfully
2023-11-26 09:01:20,054:INFO:Cross validation set to False
2023-11-26 09:01:20,054:INFO:Fitting Model
2023-11-26 09:01:20,058:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4206, solver='auto',
                tol=0.0001)
2023-11-26 09:01:20,058:INFO:create_model() successfully completed......................................
2023-11-26 09:01:20,091:INFO:_master_model_container: 12
2023-11-26 09:01:20,091:INFO:_display_container: 2
2023-11-26 09:01:20,092:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4206, solver='auto',
                tol=0.0001)
2023-11-26 09:01:20,092:INFO:compare_models() successfully completed......................................
2023-11-26 09:01:20,092:INFO:Initializing create_model()
2023-11-26 09:01:20,092:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:01:20,092:INFO:Checking exceptions
2023-11-26 09:01:20,093:INFO:Importing libraries
2023-11-26 09:01:20,093:INFO:Copying training dataset
2023-11-26 09:01:20,094:INFO:Defining folds
2023-11-26 09:01:20,094:INFO:Declaring metric variables
2023-11-26 09:01:20,094:INFO:Importing untrained model
2023-11-26 09:01:20,095:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:01:20,095:INFO:Starting cross validation
2023-11-26 09:01:20,095:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:01:20,132:INFO:Calculating mean and std
2023-11-26 09:01:20,133:INFO:Creating metrics dataframe
2023-11-26 09:01:20,134:INFO:Finalizing model
2023-11-26 09:01:20,138:INFO:Uploading results into container
2023-11-26 09:01:20,138:INFO:Uploading model into container now
2023-11-26 09:01:20,142:INFO:_master_model_container: 13
2023-11-26 09:01:20,142:INFO:_display_container: 3
2023-11-26 09:01:20,142:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:01:20,142:INFO:create_model() successfully completed......................................
2023-11-26 09:01:20,171:INFO:Initializing tune_model()
2023-11-26 09:01:20,171:INFO:tune_model(estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>)
2023-11-26 09:01:20,171:INFO:Checking exceptions
2023-11-26 09:01:20,172:INFO:Copying training dataset
2023-11-26 09:01:20,173:INFO:Checking base model
2023-11-26 09:01:20,174:INFO:Base model : Linear Discriminant Analysis
2023-11-26 09:01:20,174:INFO:Declaring metric variables
2023-11-26 09:01:20,174:INFO:Defining Hyperparameters
2023-11-26 09:01:20,201:INFO:Tuning with n_jobs=-1
2023-11-26 09:01:20,201:INFO:Initializing RandomizedSearchCV
2023-11-26 09:01:21,396:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
10 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 571, in fit
    self._validate_params()
  File "/usr/local/lib/python3.8/site-packages/sklearn/base.py", line 600, in _validate_params
    validate_parameter_constraints(
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'shrinkage' parameter of LinearDiscriminantAnalysis must be a str among {'auto'}, a float in the range [0, 1] or None. Got 'empirical' instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-11-26 09:01:21,398:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.98869841 0.99904762        nan 0.99714286 0.99714286
 0.99714286 0.99714286 0.99904762 0.99714286]
  warnings.warn(

2023-11-26 09:01:21,398:INFO:best_params: {'actual_estimator__solver': 'lsqr', 'actual_estimator__shrinkage': 'auto'}
2023-11-26 09:01:21,399:INFO:Hyperparameter search completed
2023-11-26 09:01:21,399:INFO:SubProcess create_model() called ==================================
2023-11-26 09:01:21,400:INFO:Initializing create_model()
2023-11-26 09:01:21,400:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff88cbd820>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lsqr', 'shrinkage': 'auto'})
2023-11-26 09:01:21,400:INFO:Checking exceptions
2023-11-26 09:01:21,400:INFO:Importing libraries
2023-11-26 09:01:21,400:INFO:Copying training dataset
2023-11-26 09:01:21,403:INFO:Defining folds
2023-11-26 09:01:21,403:INFO:Declaring metric variables
2023-11-26 09:01:21,403:INFO:Importing untrained model
2023-11-26 09:01:21,404:INFO:Declaring custom model
2023-11-26 09:01:21,404:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:01:21,404:INFO:Starting cross validation
2023-11-26 09:01:21,405:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:01:21,446:INFO:Calculating mean and std
2023-11-26 09:01:21,446:INFO:Creating metrics dataframe
2023-11-26 09:01:21,447:INFO:Finalizing model
2023-11-26 09:01:21,451:INFO:Uploading results into container
2023-11-26 09:01:21,452:INFO:Uploading model into container now
2023-11-26 09:01:21,452:INFO:_master_model_container: 14
2023-11-26 09:01:21,452:INFO:_display_container: 4
2023-11-26 09:01:21,452:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:01:21,453:INFO:create_model() successfully completed......................................
2023-11-26 09:01:21,494:INFO:SubProcess create_model() end ==================================
2023-11-26 09:01:21,494:INFO:choose_better activated
2023-11-26 09:01:21,495:INFO:SubProcess create_model() called ==================================
2023-11-26 09:01:21,495:INFO:Initializing create_model()
2023-11-26 09:01:21,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:01:21,495:INFO:Checking exceptions
2023-11-26 09:01:21,496:INFO:Importing libraries
2023-11-26 09:01:21,496:INFO:Copying training dataset
2023-11-26 09:01:21,498:INFO:Defining folds
2023-11-26 09:01:21,498:INFO:Declaring metric variables
2023-11-26 09:01:21,498:INFO:Importing untrained model
2023-11-26 09:01:21,498:INFO:Declaring custom model
2023-11-26 09:01:21,498:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:01:21,498:INFO:Starting cross validation
2023-11-26 09:01:21,499:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:01:21,536:INFO:Calculating mean and std
2023-11-26 09:01:21,536:INFO:Creating metrics dataframe
2023-11-26 09:01:21,537:INFO:Finalizing model
2023-11-26 09:01:21,541:INFO:Uploading results into container
2023-11-26 09:01:21,541:INFO:Uploading model into container now
2023-11-26 09:01:21,542:INFO:_master_model_container: 15
2023-11-26 09:01:21,542:INFO:_display_container: 5
2023-11-26 09:01:21,542:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:01:21,542:INFO:create_model() successfully completed......................................
2023-11-26 09:01:21,569:INFO:SubProcess create_model() end ==================================
2023-11-26 09:01:21,569:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9971
2023-11-26 09:01:21,569:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001) result for AUC is 0.999
2023-11-26 09:01:21,570:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001) is best model
2023-11-26 09:01:21,570:INFO:choose_better completed
2023-11-26 09:01:21,573:INFO:_master_model_container: 15
2023-11-26 09:01:21,574:INFO:_display_container: 4
2023-11-26 09:01:21,574:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:01:21,574:INFO:tune_model() successfully completed......................................
2023-11-26 09:01:21,600:INFO:Initializing evaluate_model()
2023-11-26 09:01:21,600:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-26 09:01:21,603:INFO:Initializing plot_model()
2023-11-26 09:01:21,603:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, system=True)
2023-11-26 09:01:21,603:INFO:Checking exceptions
2023-11-26 09:01:21,604:INFO:Preloading libraries
2023-11-26 09:01:21,604:INFO:Copying training dataset
2023-11-26 09:01:21,604:INFO:Plot type: pipeline
2023-11-26 09:01:21,639:INFO:Visual Rendered Successfully
2023-11-26 09:01:21,690:INFO:plot_model() successfully completed......................................
2023-11-26 09:01:21,694:INFO:Initializing finalize_model()
2023-11-26 09:01:21,694:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-11-26 09:01:21,695:INFO:Finalizing LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:01:21,698:INFO:Initializing create_model()
2023-11-26 09:01:21,698:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='lsqr',
                           store_covariance=False, tol=0.0001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:01:21,698:INFO:Checking exceptions
2023-11-26 09:01:21,699:INFO:Importing libraries
2023-11-26 09:01:21,700:INFO:Copying training dataset
2023-11-26 09:01:21,700:INFO:Defining folds
2023-11-26 09:01:21,700:INFO:Declaring metric variables
2023-11-26 09:01:21,700:INFO:Importing untrained model
2023-11-26 09:01:21,700:INFO:Declaring custom model
2023-11-26 09:01:21,701:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:01:21,702:INFO:Cross validation set to False
2023-11-26 09:01:21,702:INFO:Fitting Model
2023-11-26 09:01:21,719:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage='auto', solver='lsqr',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 09:01:21,720:INFO:create_model() successfully completed......................................
2023-11-26 09:01:21,754:INFO:_master_model_container: 15
2023-11-26 09:01:21,754:INFO:_display_container: 4
2023-11-26 09:01:21,756:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage='auto', solver='lsqr',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 09:01:21,756:INFO:finalize_model() successfully completed......................................
2023-11-26 09:01:22,274:INFO:Initializing predict_model()
2023-11-26 09:01:22,274:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff88dc3550>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage='auto', solver='lsqr',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff40c953a0>)
2023-11-26 09:01:22,275:INFO:Checking exceptions
2023-11-26 09:01:22,275:INFO:Preloading libraries
2023-11-26 09:01:22,275:INFO:Set up data.
2023-11-26 09:01:22,282:INFO:Set up index.
2023-11-26 09:01:22,301:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-11-26 09:01:22,303:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:01:22,305:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:02:02,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:02,871:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:02,871:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:02,871:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,163:INFO:PyCaret ClassificationExperiment
2023-11-26 09:02:03,163:INFO:Logging name: clf-default-name
2023-11-26 09:02:03,163:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-26 09:02:03,163:INFO:version 3.2.0
2023-11-26 09:02:03,163:INFO:Initializing setup()
2023-11-26 09:02:03,163:INFO:self.USI: 6be7
2023-11-26 09:02:03,163:INFO:self._variable_keys: {'fold_generator', 'log_plots_param', 'y_train', 'fold_groups_param', 'gpu_n_jobs_param', 'exp_name_log', 'html_param', 'data', 'idx', 'y', 'X_test', 'X_train', 'pipeline', 'exp_id', 'n_jobs_param', 'seed', 'y_test', '_available_plots', 'fix_imbalance', 'is_multiclass', 'target_param', 'X', 'fold_shuffle_param', '_ml_usecase', 'gpu_param', 'memory', 'USI', 'logging_param'}
2023-11-26 09:02:03,163:INFO:Checking environment
2023-11-26 09:02:03,163:INFO:python_version: 3.8.18
2023-11-26 09:02:03,164:INFO:python_build: ('default', 'Nov 21 2023 19:36:55')
2023-11-26 09:02:03,164:INFO:machine: aarch64
2023-11-26 09:02:03,165:INFO:platform: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 09:02:03,165:INFO:Memory: svmem(total=8225304576, available=7065047040, percent=14.1, used=950804480, free=3497799680, active=2020286464, inactive=2082893824, buffers=117387264, cached=3659313152, shared=1875968, slab=445784064)
2023-11-26 09:02:03,166:INFO:Physical Core: 12
2023-11-26 09:02:03,166:INFO:Logical Core: 12
2023-11-26 09:02:03,166:INFO:Checking libraries
2023-11-26 09:02:03,166:INFO:System:
2023-11-26 09:02:03,166:INFO:    python: 3.8.18 (default, Nov 21 2023, 19:36:55)  [GCC 12.2.0]
2023-11-26 09:02:03,166:INFO:executable: /usr/local/bin/python
2023-11-26 09:02:03,166:INFO:   machine: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 09:02:03,166:INFO:PyCaret required dependencies:
2023-11-26 09:02:03,176:INFO:                 pip: 23.3.1
2023-11-26 09:02:03,176:INFO:          setuptools: 57.5.0
2023-11-26 09:02:03,176:INFO:             pycaret: 3.2.0
2023-11-26 09:02:03,177:INFO:             IPython: 8.12.3
2023-11-26 09:02:03,177:INFO:          ipywidgets: 8.1.1
2023-11-26 09:02:03,177:INFO:                tqdm: 4.66.1
2023-11-26 09:02:03,177:INFO:               numpy: 1.24.4
2023-11-26 09:02:03,177:INFO:              pandas: 1.5.3
2023-11-26 09:02:03,177:INFO:              jinja2: 3.1.2
2023-11-26 09:02:03,177:INFO:               scipy: 1.10.1
2023-11-26 09:02:03,177:INFO:              joblib: 1.3.2
2023-11-26 09:02:03,177:INFO:             sklearn: 1.2.2
2023-11-26 09:02:03,178:INFO:                pyod: 1.1.2
2023-11-26 09:02:03,178:INFO:            imblearn: 0.11.0
2023-11-26 09:02:03,178:INFO:   category_encoders: 2.6.3
2023-11-26 09:02:03,178:INFO:            lightgbm: 4.1.0
2023-11-26 09:02:03,178:INFO:               numba: 0.58.1
2023-11-26 09:02:03,178:INFO:            requests: 2.31.0
2023-11-26 09:02:03,178:INFO:          matplotlib: 3.6.0
2023-11-26 09:02:03,178:INFO:          scikitplot: 0.3.7
2023-11-26 09:02:03,178:INFO:         yellowbrick: 1.5
2023-11-26 09:02:03,179:INFO:              plotly: 5.18.0
2023-11-26 09:02:03,179:INFO:    plotly-resampler: Not installed
2023-11-26 09:02:03,179:INFO:             kaleido: 0.2.1
2023-11-26 09:02:03,179:INFO:           schemdraw: 0.15
2023-11-26 09:02:03,179:INFO:         statsmodels: 0.14.0
2023-11-26 09:02:03,179:INFO:              sktime: 0.21.1
2023-11-26 09:02:03,179:INFO:               tbats: 1.1.3
2023-11-26 09:02:03,180:INFO:            pmdarima: 2.0.4
2023-11-26 09:02:03,180:INFO:              psutil: 5.9.6
2023-11-26 09:02:03,180:INFO:          markupsafe: 2.1.3
2023-11-26 09:02:03,180:INFO:             pickle5: Not installed
2023-11-26 09:02:03,180:INFO:         cloudpickle: 3.0.0
2023-11-26 09:02:03,180:INFO:         deprecation: 2.1.0
2023-11-26 09:02:03,180:INFO:              xxhash: 3.4.1
2023-11-26 09:02:03,180:INFO:           wurlitzer: 3.0.3
2023-11-26 09:02:03,180:INFO:PyCaret optional dependencies:
2023-11-26 09:02:03,191:INFO:                shap: Not installed
2023-11-26 09:02:03,191:INFO:           interpret: Not installed
2023-11-26 09:02:03,191:INFO:                umap: Not installed
2023-11-26 09:02:03,192:INFO:     ydata_profiling: Not installed
2023-11-26 09:02:03,192:INFO:  explainerdashboard: Not installed
2023-11-26 09:02:03,192:INFO:             autoviz: Not installed
2023-11-26 09:02:03,192:INFO:           fairlearn: Not installed
2023-11-26 09:02:03,192:INFO:          deepchecks: Not installed
2023-11-26 09:02:03,192:INFO:             xgboost: Not installed
2023-11-26 09:02:03,192:INFO:            catboost: Not installed
2023-11-26 09:02:03,192:INFO:              kmodes: Not installed
2023-11-26 09:02:03,192:INFO:             mlxtend: Not installed
2023-11-26 09:02:03,192:INFO:       statsforecast: Not installed
2023-11-26 09:02:03,193:INFO:        tune_sklearn: Not installed
2023-11-26 09:02:03,193:INFO:                 ray: Not installed
2023-11-26 09:02:03,193:INFO:            hyperopt: Not installed
2023-11-26 09:02:03,193:INFO:              optuna: Not installed
2023-11-26 09:02:03,193:INFO:               skopt: Not installed
2023-11-26 09:02:03,193:INFO:              mlflow: Not installed
2023-11-26 09:02:03,193:INFO:              gradio: Not installed
2023-11-26 09:02:03,193:INFO:             fastapi: Not installed
2023-11-26 09:02:03,193:INFO:             uvicorn: Not installed
2023-11-26 09:02:03,193:INFO:              m2cgen: Not installed
2023-11-26 09:02:03,194:INFO:           evidently: Not installed
2023-11-26 09:02:03,194:INFO:               fugue: Not installed
2023-11-26 09:02:03,194:INFO:           streamlit: Not installed
2023-11-26 09:02:03,194:INFO:             prophet: Not installed
2023-11-26 09:02:03,194:INFO:None
2023-11-26 09:02:03,194:INFO:Set up GPU usage.
2023-11-26 09:02:03,194:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,194:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-26 09:02:03,194:INFO:Set up data.
2023-11-26 09:02:03,198:INFO:Set up folding strategy.
2023-11-26 09:02:03,198:INFO:Set up train/test split.
2023-11-26 09:02:03,199:INFO:Set up index.
2023-11-26 09:02:03,200:INFO:Assigning column types.
2023-11-26 09:02:03,201:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-26 09:02:03,201:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,218:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 09:02:03,218:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:02:03,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,229:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,231:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:02:03,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:02:03,248:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,265:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 09:02:03,265:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,265:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,266:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:02:03,266:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,275:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,277:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:02:03,282:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:02:03,283:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-26 09:02:03,283:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,301:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:02:03,301:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,310:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,312:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:02:03,316:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:02:03,317:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,335:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:02:03,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,344:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,346:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,347:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:02:03,350:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:02:03,351:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-26 09:02:03,351:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,368:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,369:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,377:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,379:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:02:03,384:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:02:03,384:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,403:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,412:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,414:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,414:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:02:03,418:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:02:03,419:INFO:Preparing preprocessing pipeline...
2023-11-26 09:02:03,420:INFO:Set up simple imputation.
2023-11-26 09:02:03,429:INFO:Finished creating preprocessing pipeline.
2023-11-26 09:02:03,431:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-26 09:02:03,431:INFO:Creating final display dataframe.
2023-11-26 09:02:03,454:INFO:Setup _display_container:                     Description             Value
0                    Session id              6425
1                        Target            target
2                   Target type            Binary
3           Original data shape         (210, 13)
4        Transformed data shape         (210, 13)
5   Transformed train set shape         (147, 13)
6    Transformed test set shape          (63, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              6be7
2023-11-26 09:02:03,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,473:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,474:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,474:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,484:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:02:03,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:02:03,491:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,509:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,510:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,510:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,518:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,520:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:02:03,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:02:03,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:02:03,526:INFO:setup() successfully completed in 0.37s...............
2023-11-26 09:02:03,526:INFO:Initializing compare_models()
2023-11-26 09:02:03,526:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-26 09:02:03,526:INFO:Checking exceptions
2023-11-26 09:02:03,528:INFO:Preparing display monitor
2023-11-26 09:02:03,530:INFO:Initializing Logistic Regression
2023-11-26 09:02:03,530:INFO:Total runtime is 3.1630198160807294e-06 minutes
2023-11-26 09:02:03,530:INFO:SubProcess create_model() called ==================================
2023-11-26 09:02:03,530:INFO:Initializing create_model()
2023-11-26 09:02:03,530:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5297bb50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:02:03,531:INFO:Checking exceptions
2023-11-26 09:02:03,531:INFO:Importing libraries
2023-11-26 09:02:03,531:INFO:Copying training dataset
2023-11-26 09:02:03,532:INFO:Defining folds
2023-11-26 09:02:03,532:INFO:Declaring metric variables
2023-11-26 09:02:03,532:INFO:Importing untrained model
2023-11-26 09:02:03,533:INFO:Logistic Regression Imported successfully
2023-11-26 09:02:03,533:INFO:Starting cross validation
2023-11-26 09:02:03,533:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:02:03,591:INFO:Calculating mean and std
2023-11-26 09:02:03,591:INFO:Creating metrics dataframe
2023-11-26 09:02:03,593:INFO:Uploading results into container
2023-11-26 09:02:03,593:INFO:Uploading model into container now
2023-11-26 09:02:03,593:INFO:_master_model_container: 1
2023-11-26 09:02:03,593:INFO:_display_container: 2
2023-11-26 09:02:03,594:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6425, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-26 09:02:03,594:INFO:create_model() successfully completed......................................
2023-11-26 09:02:03,632:INFO:SubProcess create_model() end ==================================
2023-11-26 09:02:03,632:INFO:Creating metrics dataframe
2023-11-26 09:02:03,635:INFO:Initializing K Neighbors Classifier
2023-11-26 09:02:03,635:INFO:Total runtime is 0.0017522732416788737 minutes
2023-11-26 09:02:03,635:INFO:SubProcess create_model() called ==================================
2023-11-26 09:02:03,635:INFO:Initializing create_model()
2023-11-26 09:02:03,635:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5297bb50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:02:03,636:INFO:Checking exceptions
2023-11-26 09:02:03,636:INFO:Importing libraries
2023-11-26 09:02:03,636:INFO:Copying training dataset
2023-11-26 09:02:03,637:INFO:Defining folds
2023-11-26 09:02:03,637:INFO:Declaring metric variables
2023-11-26 09:02:03,637:INFO:Importing untrained model
2023-11-26 09:02:03,638:INFO:K Neighbors Classifier Imported successfully
2023-11-26 09:02:03,638:INFO:Starting cross validation
2023-11-26 09:02:03,638:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:02:03,819:INFO:Calculating mean and std
2023-11-26 09:02:03,819:INFO:Creating metrics dataframe
2023-11-26 09:02:03,821:INFO:Uploading results into container
2023-11-26 09:02:03,821:INFO:Uploading model into container now
2023-11-26 09:02:03,822:INFO:_master_model_container: 2
2023-11-26 09:02:03,822:INFO:_display_container: 2
2023-11-26 09:02:03,822:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-26 09:02:03,822:INFO:create_model() successfully completed......................................
2023-11-26 09:02:03,853:INFO:SubProcess create_model() end ==================================
2023-11-26 09:02:03,853:INFO:Creating metrics dataframe
2023-11-26 09:02:03,855:INFO:Initializing Naive Bayes
2023-11-26 09:02:03,856:INFO:Total runtime is 0.005430773893992106 minutes
2023-11-26 09:02:03,856:INFO:SubProcess create_model() called ==================================
2023-11-26 09:02:03,856:INFO:Initializing create_model()
2023-11-26 09:02:03,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5297bb50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:02:03,856:INFO:Checking exceptions
2023-11-26 09:02:03,856:INFO:Importing libraries
2023-11-26 09:02:03,857:INFO:Copying training dataset
2023-11-26 09:02:03,858:INFO:Defining folds
2023-11-26 09:02:03,858:INFO:Declaring metric variables
2023-11-26 09:02:03,858:INFO:Importing untrained model
2023-11-26 09:02:03,858:INFO:Naive Bayes Imported successfully
2023-11-26 09:02:03,858:INFO:Starting cross validation
2023-11-26 09:02:03,859:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:02:03,896:INFO:Calculating mean and std
2023-11-26 09:02:03,897:INFO:Creating metrics dataframe
2023-11-26 09:02:03,898:INFO:Uploading results into container
2023-11-26 09:02:03,898:INFO:Uploading model into container now
2023-11-26 09:02:03,899:INFO:_master_model_container: 3
2023-11-26 09:02:03,899:INFO:_display_container: 2
2023-11-26 09:02:03,899:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-26 09:02:03,899:INFO:create_model() successfully completed......................................
2023-11-26 09:02:03,927:INFO:SubProcess create_model() end ==================================
2023-11-26 09:02:03,927:INFO:Creating metrics dataframe
2023-11-26 09:02:03,930:INFO:Initializing Decision Tree Classifier
2023-11-26 09:02:03,930:INFO:Total runtime is 0.0066675464312235515 minutes
2023-11-26 09:02:03,930:INFO:SubProcess create_model() called ==================================
2023-11-26 09:02:03,930:INFO:Initializing create_model()
2023-11-26 09:02:03,930:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5297bb50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:02:03,930:INFO:Checking exceptions
2023-11-26 09:02:03,931:INFO:Importing libraries
2023-11-26 09:02:03,931:INFO:Copying training dataset
2023-11-26 09:02:03,932:INFO:Defining folds
2023-11-26 09:02:03,932:INFO:Declaring metric variables
2023-11-26 09:02:03,932:INFO:Importing untrained model
2023-11-26 09:02:03,932:INFO:Decision Tree Classifier Imported successfully
2023-11-26 09:02:03,933:INFO:Starting cross validation
2023-11-26 09:02:03,933:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:02:03,971:INFO:Calculating mean and std
2023-11-26 09:02:03,972:INFO:Creating metrics dataframe
2023-11-26 09:02:03,973:INFO:Uploading results into container
2023-11-26 09:02:03,973:INFO:Uploading model into container now
2023-11-26 09:02:03,973:INFO:_master_model_container: 4
2023-11-26 09:02:03,974:INFO:_display_container: 2
2023-11-26 09:02:03,974:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=6425, splitter='best')
2023-11-26 09:02:03,974:INFO:create_model() successfully completed......................................
2023-11-26 09:02:04,005:INFO:SubProcess create_model() end ==================================
2023-11-26 09:02:04,005:INFO:Creating metrics dataframe
2023-11-26 09:02:04,007:INFO:Initializing SVM - Linear Kernel
2023-11-26 09:02:04,008:INFO:Total runtime is 0.007963411013285319 minutes
2023-11-26 09:02:04,008:INFO:SubProcess create_model() called ==================================
2023-11-26 09:02:04,008:INFO:Initializing create_model()
2023-11-26 09:02:04,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5297bb50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:02:04,008:INFO:Checking exceptions
2023-11-26 09:02:04,008:INFO:Importing libraries
2023-11-26 09:02:04,008:INFO:Copying training dataset
2023-11-26 09:02:04,010:INFO:Defining folds
2023-11-26 09:02:04,010:INFO:Declaring metric variables
2023-11-26 09:02:04,010:INFO:Importing untrained model
2023-11-26 09:02:04,010:INFO:SVM - Linear Kernel Imported successfully
2023-11-26 09:02:04,010:INFO:Starting cross validation
2023-11-26 09:02:04,011:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:02:04,018:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:02:04,025:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:02:04,032:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:02:04,039:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:02:04,046:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:02:04,048:INFO:Calculating mean and std
2023-11-26 09:02:04,049:INFO:Creating metrics dataframe
2023-11-26 09:02:04,050:INFO:Uploading results into container
2023-11-26 09:02:04,050:INFO:Uploading model into container now
2023-11-26 09:02:04,050:INFO:_master_model_container: 5
2023-11-26 09:02:04,051:INFO:_display_container: 2
2023-11-26 09:02:04,051:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6425, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-26 09:02:04,051:INFO:create_model() successfully completed......................................
2023-11-26 09:02:04,078:INFO:SubProcess create_model() end ==================================
2023-11-26 09:02:04,079:INFO:Creating metrics dataframe
2023-11-26 09:02:04,081:INFO:Initializing Ridge Classifier
2023-11-26 09:02:04,081:INFO:Total runtime is 0.009182616074879964 minutes
2023-11-26 09:02:04,081:INFO:SubProcess create_model() called ==================================
2023-11-26 09:02:04,081:INFO:Initializing create_model()
2023-11-26 09:02:04,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5297bb50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:02:04,081:INFO:Checking exceptions
2023-11-26 09:02:04,081:INFO:Importing libraries
2023-11-26 09:02:04,082:INFO:Copying training dataset
2023-11-26 09:02:04,083:INFO:Defining folds
2023-11-26 09:02:04,083:INFO:Declaring metric variables
2023-11-26 09:02:04,083:INFO:Importing untrained model
2023-11-26 09:02:04,083:INFO:Ridge Classifier Imported successfully
2023-11-26 09:02:04,083:INFO:Starting cross validation
2023-11-26 09:02:04,084:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:02:04,090:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:02:04,098:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:02:04,105:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:02:04,112:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:02:04,119:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:02:04,122:INFO:Calculating mean and std
2023-11-26 09:02:04,122:INFO:Creating metrics dataframe
2023-11-26 09:02:04,124:INFO:Uploading results into container
2023-11-26 09:02:04,124:INFO:Uploading model into container now
2023-11-26 09:02:04,124:INFO:_master_model_container: 6
2023-11-26 09:02:04,124:INFO:_display_container: 2
2023-11-26 09:02:04,125:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6425, solver='auto',
                tol=0.0001)
2023-11-26 09:02:04,125:INFO:create_model() successfully completed......................................
2023-11-26 09:02:04,154:INFO:SubProcess create_model() end ==================================
2023-11-26 09:02:04,154:INFO:Creating metrics dataframe
2023-11-26 09:02:04,157:INFO:Initializing Quadratic Discriminant Analysis
2023-11-26 09:02:04,157:INFO:Total runtime is 0.010450239976247153 minutes
2023-11-26 09:02:04,157:INFO:SubProcess create_model() called ==================================
2023-11-26 09:02:04,157:INFO:Initializing create_model()
2023-11-26 09:02:04,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5297bb50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:02:04,157:INFO:Checking exceptions
2023-11-26 09:02:04,158:INFO:Importing libraries
2023-11-26 09:02:04,158:INFO:Copying training dataset
2023-11-26 09:02:04,159:INFO:Defining folds
2023-11-26 09:02:04,159:INFO:Declaring metric variables
2023-11-26 09:02:04,159:INFO:Importing untrained model
2023-11-26 09:02:04,159:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-26 09:02:04,160:INFO:Starting cross validation
2023-11-26 09:02:04,160:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:02:04,197:INFO:Calculating mean and std
2023-11-26 09:02:04,198:INFO:Creating metrics dataframe
2023-11-26 09:02:04,199:INFO:Uploading results into container
2023-11-26 09:02:04,199:INFO:Uploading model into container now
2023-11-26 09:02:04,200:INFO:_master_model_container: 7
2023-11-26 09:02:04,200:INFO:_display_container: 2
2023-11-26 09:02:04,200:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-26 09:02:04,200:INFO:create_model() successfully completed......................................
2023-11-26 09:02:04,229:INFO:SubProcess create_model() end ==================================
2023-11-26 09:02:04,230:INFO:Creating metrics dataframe
2023-11-26 09:02:04,232:INFO:Initializing Ada Boost Classifier
2023-11-26 09:02:04,232:INFO:Total runtime is 0.011700006326039633 minutes
2023-11-26 09:02:04,232:INFO:SubProcess create_model() called ==================================
2023-11-26 09:02:04,232:INFO:Initializing create_model()
2023-11-26 09:02:04,232:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5297bb50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:02:04,232:INFO:Checking exceptions
2023-11-26 09:02:04,232:INFO:Importing libraries
2023-11-26 09:02:04,233:INFO:Copying training dataset
2023-11-26 09:02:04,234:INFO:Defining folds
2023-11-26 09:02:04,234:INFO:Declaring metric variables
2023-11-26 09:02:04,234:INFO:Importing untrained model
2023-11-26 09:02:04,235:INFO:Ada Boost Classifier Imported successfully
2023-11-26 09:02:04,235:INFO:Starting cross validation
2023-11-26 09:02:04,235:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:02:04,408:INFO:Calculating mean and std
2023-11-26 09:02:04,409:INFO:Creating metrics dataframe
2023-11-26 09:02:04,410:INFO:Uploading results into container
2023-11-26 09:02:04,410:INFO:Uploading model into container now
2023-11-26 09:02:04,411:INFO:_master_model_container: 8
2023-11-26 09:02:04,411:INFO:_display_container: 2
2023-11-26 09:02:04,411:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=6425)
2023-11-26 09:02:04,411:INFO:create_model() successfully completed......................................
2023-11-26 09:02:04,439:INFO:SubProcess create_model() end ==================================
2023-11-26 09:02:04,439:INFO:Creating metrics dataframe
2023-11-26 09:02:04,441:INFO:Initializing Linear Discriminant Analysis
2023-11-26 09:02:04,442:INFO:Total runtime is 0.015198111534118654 minutes
2023-11-26 09:02:04,442:INFO:SubProcess create_model() called ==================================
2023-11-26 09:02:04,442:INFO:Initializing create_model()
2023-11-26 09:02:04,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5297bb50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:02:04,442:INFO:Checking exceptions
2023-11-26 09:02:04,442:INFO:Importing libraries
2023-11-26 09:02:04,443:INFO:Copying training dataset
2023-11-26 09:02:04,444:INFO:Defining folds
2023-11-26 09:02:04,444:INFO:Declaring metric variables
2023-11-26 09:02:04,444:INFO:Importing untrained model
2023-11-26 09:02:04,444:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:02:04,445:INFO:Starting cross validation
2023-11-26 09:02:04,445:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:02:04,483:INFO:Calculating mean and std
2023-11-26 09:02:04,484:INFO:Creating metrics dataframe
2023-11-26 09:02:04,485:INFO:Uploading results into container
2023-11-26 09:02:04,485:INFO:Uploading model into container now
2023-11-26 09:02:04,485:INFO:_master_model_container: 9
2023-11-26 09:02:04,486:INFO:_display_container: 2
2023-11-26 09:02:04,486:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:02:04,486:INFO:create_model() successfully completed......................................
2023-11-26 09:02:04,514:INFO:SubProcess create_model() end ==================================
2023-11-26 09:02:04,514:INFO:Creating metrics dataframe
2023-11-26 09:02:04,516:INFO:Initializing Extra Trees Classifier
2023-11-26 09:02:04,516:INFO:Total runtime is 0.016439358393351238 minutes
2023-11-26 09:02:04,516:INFO:SubProcess create_model() called ==================================
2023-11-26 09:02:04,517:INFO:Initializing create_model()
2023-11-26 09:02:04,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5297bb50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:02:04,517:INFO:Checking exceptions
2023-11-26 09:02:04,517:INFO:Importing libraries
2023-11-26 09:02:04,517:INFO:Copying training dataset
2023-11-26 09:02:04,518:INFO:Defining folds
2023-11-26 09:02:04,518:INFO:Declaring metric variables
2023-11-26 09:02:04,519:INFO:Importing untrained model
2023-11-26 09:02:04,519:INFO:Extra Trees Classifier Imported successfully
2023-11-26 09:02:04,519:INFO:Starting cross validation
2023-11-26 09:02:04,519:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:02:05,205:INFO:Calculating mean and std
2023-11-26 09:02:05,205:INFO:Creating metrics dataframe
2023-11-26 09:02:05,207:INFO:Uploading results into container
2023-11-26 09:02:05,207:INFO:Uploading model into container now
2023-11-26 09:02:05,207:INFO:_master_model_container: 10
2023-11-26 09:02:05,207:INFO:_display_container: 2
2023-11-26 09:02:05,208:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=6425, verbose=0, warm_start=False)
2023-11-26 09:02:05,208:INFO:create_model() successfully completed......................................
2023-11-26 09:02:05,240:INFO:SubProcess create_model() end ==================================
2023-11-26 09:02:05,241:INFO:Creating metrics dataframe
2023-11-26 09:02:05,243:INFO:Initializing Light Gradient Boosting Machine
2023-11-26 09:02:05,243:INFO:Total runtime is 0.028553601106007895 minutes
2023-11-26 09:02:05,243:INFO:SubProcess create_model() called ==================================
2023-11-26 09:02:05,243:INFO:Initializing create_model()
2023-11-26 09:02:05,244:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5297bb50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:02:05,244:INFO:Checking exceptions
2023-11-26 09:02:05,244:INFO:Importing libraries
2023-11-26 09:02:05,244:INFO:Copying training dataset
2023-11-26 09:02:05,245:INFO:Defining folds
2023-11-26 09:02:05,245:INFO:Declaring metric variables
2023-11-26 09:02:05,245:INFO:Importing untrained model
2023-11-26 09:02:05,246:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-26 09:02:05,246:INFO:Starting cross validation
2023-11-26 09:02:05,246:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:02:05,251:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 09:02:05,251:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000090 seconds.
2023-11-26 09:02:05,252:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:02:05,252:INFO:[LightGBM] [Info] Total Bins 485
2023-11-26 09:02:05,252:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 09:02:05,252:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 09:02:05,253:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 09:02:05,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,300:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 09:02:05,301:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000073 seconds.
2023-11-26 09:02:05,301:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:02:05,301:INFO:[LightGBM] [Info] Total Bins 490
2023-11-26 09:02:05,301:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 09:02:05,302:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 09:02:05,302:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 09:02:05,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,378:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 09:02:05,379:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000650 seconds.
2023-11-26 09:02:05,379:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:02:05,379:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 09:02:05,379:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 09:02:05,380:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 09:02:05,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,451:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 09:02:05,451:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000035 seconds.
2023-11-26 09:02:05,452:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:02:05,452:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 09:02:05,452:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 09:02:05,452:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 09:02:05,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,464:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,484:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,489:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,491:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,505:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,508:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,511:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,528:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 60
2023-11-26 09:02:05,528:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000035 seconds.
2023-11-26 09:02:05,528:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:02:05,528:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 09:02:05,529:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 09:02:05,529:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491525 -> initscore=-0.033902
2023-11-26 09:02:05,529:INFO:[LightGBM] [Info] Start training from score -0.033902
2023-11-26 09:02:05,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,623:INFO:Calculating mean and std
2023-11-26 09:02:05,624:INFO:Creating metrics dataframe
2023-11-26 09:02:05,625:INFO:Uploading results into container
2023-11-26 09:02:05,626:INFO:Uploading model into container now
2023-11-26 09:02:05,626:INFO:_master_model_container: 11
2023-11-26 09:02:05,626:INFO:_display_container: 2
2023-11-26 09:02:05,626:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6425, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-26 09:02:05,626:INFO:create_model() successfully completed......................................
2023-11-26 09:02:05,657:INFO:SubProcess create_model() end ==================================
2023-11-26 09:02:05,657:INFO:Creating metrics dataframe
2023-11-26 09:02:05,659:INFO:Initializing Dummy Classifier
2023-11-26 09:02:05,659:INFO:Total runtime is 0.03549313545227051 minutes
2023-11-26 09:02:05,660:INFO:SubProcess create_model() called ==================================
2023-11-26 09:02:05,660:INFO:Initializing create_model()
2023-11-26 09:02:05,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5297bb50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:02:05,660:INFO:Checking exceptions
2023-11-26 09:02:05,660:INFO:Importing libraries
2023-11-26 09:02:05,660:INFO:Copying training dataset
2023-11-26 09:02:05,661:INFO:Defining folds
2023-11-26 09:02:05,661:INFO:Declaring metric variables
2023-11-26 09:02:05,661:INFO:Importing untrained model
2023-11-26 09:02:05,662:INFO:Dummy Classifier Imported successfully
2023-11-26 09:02:05,662:INFO:Starting cross validation
2023-11-26 09:02:05,662:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:02:05,669:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:02:05,675:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:02:05,682:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:02:05,688:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:02:05,694:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:02:05,696:INFO:Calculating mean and std
2023-11-26 09:02:05,696:INFO:Creating metrics dataframe
2023-11-26 09:02:05,697:INFO:Uploading results into container
2023-11-26 09:02:05,697:INFO:Uploading model into container now
2023-11-26 09:02:05,698:INFO:_master_model_container: 12
2023-11-26 09:02:05,698:INFO:_display_container: 2
2023-11-26 09:02:05,698:INFO:DummyClassifier(constant=None, random_state=6425, strategy='prior')
2023-11-26 09:02:05,698:INFO:create_model() successfully completed......................................
2023-11-26 09:02:05,724:INFO:SubProcess create_model() end ==================================
2023-11-26 09:02:05,724:INFO:Creating metrics dataframe
2023-11-26 09:02:05,727:INFO:Initializing create_model()
2023-11-26 09:02:05,728:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6425, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:02:05,728:INFO:Checking exceptions
2023-11-26 09:02:05,728:INFO:Importing libraries
2023-11-26 09:02:05,728:INFO:Copying training dataset
2023-11-26 09:02:05,729:INFO:Defining folds
2023-11-26 09:02:05,729:INFO:Declaring metric variables
2023-11-26 09:02:05,730:INFO:Importing untrained model
2023-11-26 09:02:05,730:INFO:Declaring custom model
2023-11-26 09:02:05,730:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-26 09:02:05,730:INFO:Cross validation set to False
2023-11-26 09:02:05,730:INFO:Fitting Model
2023-11-26 09:02:05,734:INFO:[LightGBM] [Info] Number of positive: 73, number of negative: 74
2023-11-26 09:02:05,734:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.
2023-11-26 09:02:05,734:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:02:05,734:INFO:[LightGBM] [Info] Total Bins 607
2023-11-26 09:02:05,735:INFO:[LightGBM] [Info] Number of data points in the train set: 147, number of used features: 12
2023-11-26 09:02:05,735:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496599 -> initscore=-0.013606
2023-11-26 09:02:05,735:INFO:[LightGBM] [Info] Start training from score -0.013606
2023-11-26 09:02:05,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:02:05,795:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6425, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-26 09:02:05,796:INFO:create_model() successfully completed......................................
2023-11-26 09:02:05,832:INFO:_master_model_container: 12
2023-11-26 09:02:05,832:INFO:_display_container: 2
2023-11-26 09:02:05,832:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6425, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-26 09:02:05,833:INFO:compare_models() successfully completed......................................
2023-11-26 09:02:05,833:INFO:Initializing create_model()
2023-11-26 09:02:05,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:02:05,833:INFO:Checking exceptions
2023-11-26 09:02:05,833:INFO:Importing libraries
2023-11-26 09:02:05,834:INFO:Copying training dataset
2023-11-26 09:02:05,835:INFO:Defining folds
2023-11-26 09:02:05,835:INFO:Declaring metric variables
2023-11-26 09:02:05,835:INFO:Importing untrained model
2023-11-26 09:02:05,836:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:02:05,836:INFO:Starting cross validation
2023-11-26 09:02:05,836:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:02:05,877:INFO:Calculating mean and std
2023-11-26 09:02:05,877:INFO:Creating metrics dataframe
2023-11-26 09:02:05,878:INFO:Finalizing model
2023-11-26 09:02:05,882:INFO:Uploading results into container
2023-11-26 09:02:05,882:INFO:Uploading model into container now
2023-11-26 09:02:05,886:INFO:_master_model_container: 13
2023-11-26 09:02:05,886:INFO:_display_container: 3
2023-11-26 09:02:05,886:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:02:05,886:INFO:create_model() successfully completed......................................
2023-11-26 09:02:05,916:INFO:Initializing tune_model()
2023-11-26 09:02:05,917:INFO:tune_model(estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>)
2023-11-26 09:02:05,917:INFO:Checking exceptions
2023-11-26 09:02:05,918:INFO:Copying training dataset
2023-11-26 09:02:05,919:INFO:Checking base model
2023-11-26 09:02:05,919:INFO:Base model : Linear Discriminant Analysis
2023-11-26 09:02:05,919:INFO:Declaring metric variables
2023-11-26 09:02:05,920:INFO:Defining Hyperparameters
2023-11-26 09:02:05,946:INFO:Tuning with n_jobs=-1
2023-11-26 09:02:05,946:INFO:Initializing RandomizedSearchCV
2023-11-26 09:02:07,229:INFO:best_params: {'actual_estimator__solver': 'lsqr', 'actual_estimator__shrinkage': 0.0001}
2023-11-26 09:02:07,229:INFO:Hyperparameter search completed
2023-11-26 09:02:07,230:INFO:SubProcess create_model() called ==================================
2023-11-26 09:02:07,231:INFO:Initializing create_model()
2023-11-26 09:02:07,231:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff5288f700>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lsqr', 'shrinkage': 0.0001})
2023-11-26 09:02:07,231:INFO:Checking exceptions
2023-11-26 09:02:07,231:INFO:Importing libraries
2023-11-26 09:02:07,231:INFO:Copying training dataset
2023-11-26 09:02:07,235:INFO:Defining folds
2023-11-26 09:02:07,235:INFO:Declaring metric variables
2023-11-26 09:02:07,235:INFO:Importing untrained model
2023-11-26 09:02:07,235:INFO:Declaring custom model
2023-11-26 09:02:07,236:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:02:07,236:INFO:Starting cross validation
2023-11-26 09:02:07,237:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:02:07,277:INFO:Calculating mean and std
2023-11-26 09:02:07,277:INFO:Creating metrics dataframe
2023-11-26 09:02:07,279:INFO:Finalizing model
2023-11-26 09:02:07,282:INFO:Uploading results into container
2023-11-26 09:02:07,283:INFO:Uploading model into container now
2023-11-26 09:02:07,283:INFO:_master_model_container: 14
2023-11-26 09:02:07,283:INFO:_display_container: 4
2023-11-26 09:02:07,283:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.0001, solver='lsqr',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:02:07,284:INFO:create_model() successfully completed......................................
2023-11-26 09:02:07,321:INFO:SubProcess create_model() end ==================================
2023-11-26 09:02:07,321:INFO:choose_better activated
2023-11-26 09:02:07,322:INFO:SubProcess create_model() called ==================================
2023-11-26 09:02:07,322:INFO:Initializing create_model()
2023-11-26 09:02:07,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:02:07,322:INFO:Checking exceptions
2023-11-26 09:02:07,323:INFO:Importing libraries
2023-11-26 09:02:07,323:INFO:Copying training dataset
2023-11-26 09:02:07,324:INFO:Defining folds
2023-11-26 09:02:07,325:INFO:Declaring metric variables
2023-11-26 09:02:07,325:INFO:Importing untrained model
2023-11-26 09:02:07,325:INFO:Declaring custom model
2023-11-26 09:02:07,325:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:02:07,325:INFO:Starting cross validation
2023-11-26 09:02:07,326:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:02:07,363:INFO:Calculating mean and std
2023-11-26 09:02:07,363:INFO:Creating metrics dataframe
2023-11-26 09:02:07,364:INFO:Finalizing model
2023-11-26 09:02:07,368:INFO:Uploading results into container
2023-11-26 09:02:07,368:INFO:Uploading model into container now
2023-11-26 09:02:07,368:INFO:_master_model_container: 15
2023-11-26 09:02:07,368:INFO:_display_container: 5
2023-11-26 09:02:07,369:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:02:07,369:INFO:create_model() successfully completed......................................
2023-11-26 09:02:07,395:INFO:SubProcess create_model() end ==================================
2023-11-26 09:02:07,395:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 1.0
2023-11-26 09:02:07,395:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.0001, solver='lsqr',
                           store_covariance=False, tol=0.0001) result for AUC is 1.0
2023-11-26 09:02:07,396:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) is best model
2023-11-26 09:02:07,396:INFO:choose_better completed
2023-11-26 09:02:07,396:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-11-26 09:02:07,399:INFO:_master_model_container: 15
2023-11-26 09:02:07,399:INFO:_display_container: 4
2023-11-26 09:02:07,400:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:02:07,400:INFO:tune_model() successfully completed......................................
2023-11-26 09:02:07,427:INFO:Initializing evaluate_model()
2023-11-26 09:02:07,427:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-26 09:02:07,429:INFO:Initializing plot_model()
2023-11-26 09:02:07,430:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, system=True)
2023-11-26 09:02:07,430:INFO:Checking exceptions
2023-11-26 09:02:07,430:INFO:Preloading libraries
2023-11-26 09:02:07,430:INFO:Copying training dataset
2023-11-26 09:02:07,431:INFO:Plot type: pipeline
2023-11-26 09:02:07,465:INFO:Visual Rendered Successfully
2023-11-26 09:02:07,508:INFO:plot_model() successfully completed......................................
2023-11-26 09:02:07,515:INFO:Initializing finalize_model()
2023-11-26 09:02:07,516:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-11-26 09:02:07,519:INFO:Finalizing LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:02:07,527:INFO:Initializing create_model()
2023-11-26 09:02:07,527:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:02:07,527:INFO:Checking exceptions
2023-11-26 09:02:07,528:INFO:Importing libraries
2023-11-26 09:02:07,528:INFO:Copying training dataset
2023-11-26 09:02:07,528:INFO:Defining folds
2023-11-26 09:02:07,529:INFO:Declaring metric variables
2023-11-26 09:02:07,529:INFO:Importing untrained model
2023-11-26 09:02:07,529:INFO:Declaring custom model
2023-11-26 09:02:07,530:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:02:07,531:INFO:Cross validation set to False
2023-11-26 09:02:07,531:INFO:Fitting Model
2023-11-26 09:02:07,550:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 09:02:07,552:INFO:create_model() successfully completed......................................
2023-11-26 09:02:07,583:INFO:_master_model_container: 15
2023-11-26 09:02:07,583:INFO:_display_container: 4
2023-11-26 09:02:07,585:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 09:02:07,585:INFO:finalize_model() successfully completed......................................
2023-11-26 09:02:08,091:INFO:Initializing predict_model()
2023-11-26 09:02:08,093:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff567f5f70>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=None, solver='svd',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff484f29d0>)
2023-11-26 09:02:08,093:INFO:Checking exceptions
2023-11-26 09:02:08,093:INFO:Preloading libraries
2023-11-26 09:02:08,094:INFO:Set up data.
2023-11-26 09:02:08,100:INFO:Set up index.
2023-11-26 09:02:08,109:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-11-26 09:02:08,112:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:02:08,114:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:03:47,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:47,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:47,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:47,685:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:47,966:INFO:PyCaret ClassificationExperiment
2023-11-26 09:03:47,966:INFO:Logging name: clf-default-name
2023-11-26 09:03:47,966:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-26 09:03:47,966:INFO:version 3.2.0
2023-11-26 09:03:47,966:INFO:Initializing setup()
2023-11-26 09:03:47,966:INFO:self.USI: f202
2023-11-26 09:03:47,966:INFO:self._variable_keys: {'is_multiclass', 'pipeline', 'gpu_n_jobs_param', 'data', '_available_plots', 'y_test', 'X_train', 'n_jobs_param', 'log_plots_param', 'y_train', 'target_param', 'exp_id', 'logging_param', 'fold_shuffle_param', 'idx', 'html_param', 'X', 'USI', 'gpu_param', 'fold_groups_param', 'exp_name_log', 'fix_imbalance', '_ml_usecase', 'fold_generator', 'memory', 'seed', 'y', 'X_test'}
2023-11-26 09:03:47,966:INFO:Checking environment
2023-11-26 09:03:47,966:INFO:python_version: 3.8.18
2023-11-26 09:03:47,966:INFO:python_build: ('default', 'Nov 21 2023 19:36:55')
2023-11-26 09:03:47,966:INFO:machine: aarch64
2023-11-26 09:03:47,968:INFO:platform: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 09:03:47,968:INFO:Memory: svmem(total=8225304576, available=7060488192, percent=14.2, used=955355136, free=3493191680, active=2020306944, inactive=2087006208, buffers=117395456, cached=3659362304, shared=1884160, slab=444968960)
2023-11-26 09:03:47,969:INFO:Physical Core: 12
2023-11-26 09:03:47,969:INFO:Logical Core: 12
2023-11-26 09:03:47,969:INFO:Checking libraries
2023-11-26 09:03:47,969:INFO:System:
2023-11-26 09:03:47,969:INFO:    python: 3.8.18 (default, Nov 21 2023, 19:36:55)  [GCC 12.2.0]
2023-11-26 09:03:47,969:INFO:executable: /usr/local/bin/python
2023-11-26 09:03:47,969:INFO:   machine: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 09:03:47,970:INFO:PyCaret required dependencies:
2023-11-26 09:03:47,979:INFO:                 pip: 23.3.1
2023-11-26 09:03:47,979:INFO:          setuptools: 57.5.0
2023-11-26 09:03:47,980:INFO:             pycaret: 3.2.0
2023-11-26 09:03:47,980:INFO:             IPython: 8.12.3
2023-11-26 09:03:47,980:INFO:          ipywidgets: 8.1.1
2023-11-26 09:03:47,980:INFO:                tqdm: 4.66.1
2023-11-26 09:03:47,980:INFO:               numpy: 1.24.4
2023-11-26 09:03:47,980:INFO:              pandas: 1.5.3
2023-11-26 09:03:47,980:INFO:              jinja2: 3.1.2
2023-11-26 09:03:47,980:INFO:               scipy: 1.10.1
2023-11-26 09:03:47,980:INFO:              joblib: 1.3.2
2023-11-26 09:03:47,980:INFO:             sklearn: 1.2.2
2023-11-26 09:03:47,980:INFO:                pyod: 1.1.2
2023-11-26 09:03:47,981:INFO:            imblearn: 0.11.0
2023-11-26 09:03:47,981:INFO:   category_encoders: 2.6.3
2023-11-26 09:03:47,981:INFO:            lightgbm: 4.1.0
2023-11-26 09:03:47,981:INFO:               numba: 0.58.1
2023-11-26 09:03:47,981:INFO:            requests: 2.31.0
2023-11-26 09:03:47,981:INFO:          matplotlib: 3.6.0
2023-11-26 09:03:47,981:INFO:          scikitplot: 0.3.7
2023-11-26 09:03:47,981:INFO:         yellowbrick: 1.5
2023-11-26 09:03:47,981:INFO:              plotly: 5.18.0
2023-11-26 09:03:47,981:INFO:    plotly-resampler: Not installed
2023-11-26 09:03:47,982:INFO:             kaleido: 0.2.1
2023-11-26 09:03:47,982:INFO:           schemdraw: 0.15
2023-11-26 09:03:47,982:INFO:         statsmodels: 0.14.0
2023-11-26 09:03:47,982:INFO:              sktime: 0.21.1
2023-11-26 09:03:47,982:INFO:               tbats: 1.1.3
2023-11-26 09:03:47,982:INFO:            pmdarima: 2.0.4
2023-11-26 09:03:47,982:INFO:              psutil: 5.9.6
2023-11-26 09:03:47,982:INFO:          markupsafe: 2.1.3
2023-11-26 09:03:47,982:INFO:             pickle5: Not installed
2023-11-26 09:03:47,983:INFO:         cloudpickle: 3.0.0
2023-11-26 09:03:47,983:INFO:         deprecation: 2.1.0
2023-11-26 09:03:47,983:INFO:              xxhash: 3.4.1
2023-11-26 09:03:47,983:INFO:           wurlitzer: 3.0.3
2023-11-26 09:03:47,983:INFO:PyCaret optional dependencies:
2023-11-26 09:03:47,994:INFO:                shap: Not installed
2023-11-26 09:03:47,994:INFO:           interpret: Not installed
2023-11-26 09:03:47,994:INFO:                umap: Not installed
2023-11-26 09:03:47,994:INFO:     ydata_profiling: Not installed
2023-11-26 09:03:47,994:INFO:  explainerdashboard: Not installed
2023-11-26 09:03:47,994:INFO:             autoviz: Not installed
2023-11-26 09:03:47,994:INFO:           fairlearn: Not installed
2023-11-26 09:03:47,994:INFO:          deepchecks: Not installed
2023-11-26 09:03:47,994:INFO:             xgboost: Not installed
2023-11-26 09:03:47,995:INFO:            catboost: Not installed
2023-11-26 09:03:47,995:INFO:              kmodes: Not installed
2023-11-26 09:03:47,995:INFO:             mlxtend: Not installed
2023-11-26 09:03:47,995:INFO:       statsforecast: Not installed
2023-11-26 09:03:47,995:INFO:        tune_sklearn: Not installed
2023-11-26 09:03:47,995:INFO:                 ray: Not installed
2023-11-26 09:03:47,995:INFO:            hyperopt: Not installed
2023-11-26 09:03:47,995:INFO:              optuna: Not installed
2023-11-26 09:03:47,995:INFO:               skopt: Not installed
2023-11-26 09:03:47,996:INFO:              mlflow: Not installed
2023-11-26 09:03:47,996:INFO:              gradio: Not installed
2023-11-26 09:03:47,996:INFO:             fastapi: Not installed
2023-11-26 09:03:47,996:INFO:             uvicorn: Not installed
2023-11-26 09:03:47,996:INFO:              m2cgen: Not installed
2023-11-26 09:03:47,996:INFO:           evidently: Not installed
2023-11-26 09:03:47,996:INFO:               fugue: Not installed
2023-11-26 09:03:47,996:INFO:           streamlit: Not installed
2023-11-26 09:03:47,996:INFO:             prophet: Not installed
2023-11-26 09:03:47,996:INFO:None
2023-11-26 09:03:47,997:INFO:Set up GPU usage.
2023-11-26 09:03:47,997:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:47,997:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-26 09:03:47,997:INFO:Set up data.
2023-11-26 09:03:48,000:INFO:Set up folding strategy.
2023-11-26 09:03:48,000:INFO:Set up train/test split.
2023-11-26 09:03:48,002:INFO:Set up index.
2023-11-26 09:03:48,002:INFO:Assigning column types.
2023-11-26 09:03:48,003:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-26 09:03:48,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,021:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 09:03:48,021:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,022:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:03:48,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:03:48,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:03:48,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,068:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 09:03:48,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,069:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:03:48,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:03:48,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:03:48,085:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-26 09:03:48,085:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,104:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:03:48,104:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,112:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,114:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:03:48,119:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:03:48,119:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,137:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,137:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,137:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:03:48,137:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,146:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,148:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:03:48,153:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:03:48,153:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-26 09:03:48,153:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,171:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,171:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,171:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,182:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:03:48,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:03:48,187:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,204:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,213:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:03:48,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:03:48,221:INFO:Preparing preprocessing pipeline...
2023-11-26 09:03:48,222:INFO:Set up simple imputation.
2023-11-26 09:03:48,231:INFO:Finished creating preprocessing pipeline.
2023-11-26 09:03:48,233:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-26 09:03:48,233:INFO:Creating final display dataframe.
2023-11-26 09:03:48,255:INFO:Setup _display_container:                     Description             Value
0                    Session id              8051
1                        Target            target
2                   Target type            Binary
3           Original data shape         (210, 13)
4        Transformed data shape         (210, 13)
5   Transformed train set shape         (147, 13)
6    Transformed test set shape          (63, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              f202
2023-11-26 09:03:48,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,275:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,275:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,275:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,285:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:03:48,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:03:48,291:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,309:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,309:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,309:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,318:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:03:48,320:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:03:48,324:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:03:48,325:INFO:setup() successfully completed in 0.36s...............
2023-11-26 09:03:48,325:INFO:Initializing compare_models()
2023-11-26 09:03:48,325:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-26 09:03:48,325:INFO:Checking exceptions
2023-11-26 09:03:48,326:INFO:Preparing display monitor
2023-11-26 09:03:48,328:INFO:Initializing Logistic Regression
2023-11-26 09:03:48,328:INFO:Total runtime is 1.8040339152018229e-06 minutes
2023-11-26 09:03:48,329:INFO:SubProcess create_model() called ==================================
2023-11-26 09:03:48,329:INFO:Initializing create_model()
2023-11-26 09:03:48,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff76a369d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:03:48,329:INFO:Checking exceptions
2023-11-26 09:03:48,329:INFO:Importing libraries
2023-11-26 09:03:48,329:INFO:Copying training dataset
2023-11-26 09:03:48,330:INFO:Defining folds
2023-11-26 09:03:48,331:INFO:Declaring metric variables
2023-11-26 09:03:48,331:INFO:Importing untrained model
2023-11-26 09:03:48,331:INFO:Logistic Regression Imported successfully
2023-11-26 09:03:48,331:INFO:Starting cross validation
2023-11-26 09:03:48,332:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:03:48,390:INFO:Calculating mean and std
2023-11-26 09:03:48,390:INFO:Creating metrics dataframe
2023-11-26 09:03:48,391:INFO:Uploading results into container
2023-11-26 09:03:48,392:INFO:Uploading model into container now
2023-11-26 09:03:48,392:INFO:_master_model_container: 1
2023-11-26 09:03:48,392:INFO:_display_container: 2
2023-11-26 09:03:48,392:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8051, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-26 09:03:48,393:INFO:create_model() successfully completed......................................
2023-11-26 09:03:48,428:INFO:SubProcess create_model() end ==================================
2023-11-26 09:03:48,428:INFO:Creating metrics dataframe
2023-11-26 09:03:48,430:INFO:Initializing K Neighbors Classifier
2023-11-26 09:03:48,430:INFO:Total runtime is 0.0016970475514729818 minutes
2023-11-26 09:03:48,430:INFO:SubProcess create_model() called ==================================
2023-11-26 09:03:48,430:INFO:Initializing create_model()
2023-11-26 09:03:48,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff76a369d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:03:48,431:INFO:Checking exceptions
2023-11-26 09:03:48,431:INFO:Importing libraries
2023-11-26 09:03:48,431:INFO:Copying training dataset
2023-11-26 09:03:48,432:INFO:Defining folds
2023-11-26 09:03:48,432:INFO:Declaring metric variables
2023-11-26 09:03:48,433:INFO:Importing untrained model
2023-11-26 09:03:48,433:INFO:K Neighbors Classifier Imported successfully
2023-11-26 09:03:48,433:INFO:Starting cross validation
2023-11-26 09:03:48,434:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:03:48,610:INFO:Calculating mean and std
2023-11-26 09:03:48,610:INFO:Creating metrics dataframe
2023-11-26 09:03:48,612:INFO:Uploading results into container
2023-11-26 09:03:48,612:INFO:Uploading model into container now
2023-11-26 09:03:48,613:INFO:_master_model_container: 2
2023-11-26 09:03:48,613:INFO:_display_container: 2
2023-11-26 09:03:48,613:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-26 09:03:48,613:INFO:create_model() successfully completed......................................
2023-11-26 09:03:48,643:INFO:SubProcess create_model() end ==================================
2023-11-26 09:03:48,643:INFO:Creating metrics dataframe
2023-11-26 09:03:48,645:INFO:Initializing Naive Bayes
2023-11-26 09:03:48,645:INFO:Total runtime is 0.0052838007609049475 minutes
2023-11-26 09:03:48,645:INFO:SubProcess create_model() called ==================================
2023-11-26 09:03:48,646:INFO:Initializing create_model()
2023-11-26 09:03:48,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff76a369d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:03:48,646:INFO:Checking exceptions
2023-11-26 09:03:48,646:INFO:Importing libraries
2023-11-26 09:03:48,646:INFO:Copying training dataset
2023-11-26 09:03:48,647:INFO:Defining folds
2023-11-26 09:03:48,647:INFO:Declaring metric variables
2023-11-26 09:03:48,648:INFO:Importing untrained model
2023-11-26 09:03:48,648:INFO:Naive Bayes Imported successfully
2023-11-26 09:03:48,648:INFO:Starting cross validation
2023-11-26 09:03:48,648:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:03:48,687:INFO:Calculating mean and std
2023-11-26 09:03:48,688:INFO:Creating metrics dataframe
2023-11-26 09:03:48,689:INFO:Uploading results into container
2023-11-26 09:03:48,690:INFO:Uploading model into container now
2023-11-26 09:03:48,690:INFO:_master_model_container: 3
2023-11-26 09:03:48,690:INFO:_display_container: 2
2023-11-26 09:03:48,690:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-26 09:03:48,690:INFO:create_model() successfully completed......................................
2023-11-26 09:03:48,718:INFO:SubProcess create_model() end ==================================
2023-11-26 09:03:48,718:INFO:Creating metrics dataframe
2023-11-26 09:03:48,721:INFO:Initializing Decision Tree Classifier
2023-11-26 09:03:48,721:INFO:Total runtime is 0.0065413713455200195 minutes
2023-11-26 09:03:48,721:INFO:SubProcess create_model() called ==================================
2023-11-26 09:03:48,721:INFO:Initializing create_model()
2023-11-26 09:03:48,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff76a369d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:03:48,721:INFO:Checking exceptions
2023-11-26 09:03:48,721:INFO:Importing libraries
2023-11-26 09:03:48,722:INFO:Copying training dataset
2023-11-26 09:03:48,723:INFO:Defining folds
2023-11-26 09:03:48,723:INFO:Declaring metric variables
2023-11-26 09:03:48,723:INFO:Importing untrained model
2023-11-26 09:03:48,723:INFO:Decision Tree Classifier Imported successfully
2023-11-26 09:03:48,723:INFO:Starting cross validation
2023-11-26 09:03:48,724:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:03:48,763:INFO:Calculating mean and std
2023-11-26 09:03:48,763:INFO:Creating metrics dataframe
2023-11-26 09:03:48,764:INFO:Uploading results into container
2023-11-26 09:03:48,764:INFO:Uploading model into container now
2023-11-26 09:03:48,765:INFO:_master_model_container: 4
2023-11-26 09:03:48,765:INFO:_display_container: 2
2023-11-26 09:03:48,765:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8051, splitter='best')
2023-11-26 09:03:48,765:INFO:create_model() successfully completed......................................
2023-11-26 09:03:48,793:INFO:SubProcess create_model() end ==================================
2023-11-26 09:03:48,793:INFO:Creating metrics dataframe
2023-11-26 09:03:48,795:INFO:Initializing SVM - Linear Kernel
2023-11-26 09:03:48,795:INFO:Total runtime is 0.007781660556793213 minutes
2023-11-26 09:03:48,795:INFO:SubProcess create_model() called ==================================
2023-11-26 09:03:48,795:INFO:Initializing create_model()
2023-11-26 09:03:48,796:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff76a369d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:03:48,796:INFO:Checking exceptions
2023-11-26 09:03:48,796:INFO:Importing libraries
2023-11-26 09:03:48,796:INFO:Copying training dataset
2023-11-26 09:03:48,797:INFO:Defining folds
2023-11-26 09:03:48,797:INFO:Declaring metric variables
2023-11-26 09:03:48,797:INFO:Importing untrained model
2023-11-26 09:03:48,798:INFO:SVM - Linear Kernel Imported successfully
2023-11-26 09:03:48,798:INFO:Starting cross validation
2023-11-26 09:03:48,798:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:03:48,806:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:03:48,814:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:03:48,822:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:03:48,829:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:03:48,836:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:03:48,838:INFO:Calculating mean and std
2023-11-26 09:03:48,839:INFO:Creating metrics dataframe
2023-11-26 09:03:48,840:INFO:Uploading results into container
2023-11-26 09:03:48,841:INFO:Uploading model into container now
2023-11-26 09:03:48,841:INFO:_master_model_container: 5
2023-11-26 09:03:48,841:INFO:_display_container: 2
2023-11-26 09:03:48,841:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8051, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-26 09:03:48,841:INFO:create_model() successfully completed......................................
2023-11-26 09:03:48,872:INFO:SubProcess create_model() end ==================================
2023-11-26 09:03:48,872:INFO:Creating metrics dataframe
2023-11-26 09:03:48,874:INFO:Initializing Ridge Classifier
2023-11-26 09:03:48,874:INFO:Total runtime is 0.009100178877512615 minutes
2023-11-26 09:03:48,874:INFO:SubProcess create_model() called ==================================
2023-11-26 09:03:48,875:INFO:Initializing create_model()
2023-11-26 09:03:48,875:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff76a369d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:03:48,875:INFO:Checking exceptions
2023-11-26 09:03:48,875:INFO:Importing libraries
2023-11-26 09:03:48,875:INFO:Copying training dataset
2023-11-26 09:03:48,876:INFO:Defining folds
2023-11-26 09:03:48,876:INFO:Declaring metric variables
2023-11-26 09:03:48,877:INFO:Importing untrained model
2023-11-26 09:03:48,877:INFO:Ridge Classifier Imported successfully
2023-11-26 09:03:48,877:INFO:Starting cross validation
2023-11-26 09:03:48,877:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:03:48,884:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:03:48,891:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:03:48,898:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:03:48,905:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:03:48,912:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:03:48,915:INFO:Calculating mean and std
2023-11-26 09:03:48,915:INFO:Creating metrics dataframe
2023-11-26 09:03:48,917:INFO:Uploading results into container
2023-11-26 09:03:48,917:INFO:Uploading model into container now
2023-11-26 09:03:48,917:INFO:_master_model_container: 6
2023-11-26 09:03:48,917:INFO:_display_container: 2
2023-11-26 09:03:48,918:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8051, solver='auto',
                tol=0.0001)
2023-11-26 09:03:48,918:INFO:create_model() successfully completed......................................
2023-11-26 09:03:48,944:INFO:SubProcess create_model() end ==================================
2023-11-26 09:03:48,944:INFO:Creating metrics dataframe
2023-11-26 09:03:48,946:INFO:Initializing Quadratic Discriminant Analysis
2023-11-26 09:03:48,946:INFO:Total runtime is 0.010301554203033449 minutes
2023-11-26 09:03:48,947:INFO:SubProcess create_model() called ==================================
2023-11-26 09:03:48,947:INFO:Initializing create_model()
2023-11-26 09:03:48,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff76a369d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:03:48,947:INFO:Checking exceptions
2023-11-26 09:03:48,947:INFO:Importing libraries
2023-11-26 09:03:48,947:INFO:Copying training dataset
2023-11-26 09:03:48,948:INFO:Defining folds
2023-11-26 09:03:48,948:INFO:Declaring metric variables
2023-11-26 09:03:48,949:INFO:Importing untrained model
2023-11-26 09:03:48,949:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-26 09:03:48,949:INFO:Starting cross validation
2023-11-26 09:03:48,949:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:03:48,987:INFO:Calculating mean and std
2023-11-26 09:03:48,987:INFO:Creating metrics dataframe
2023-11-26 09:03:48,988:INFO:Uploading results into container
2023-11-26 09:03:48,989:INFO:Uploading model into container now
2023-11-26 09:03:48,989:INFO:_master_model_container: 7
2023-11-26 09:03:48,989:INFO:_display_container: 2
2023-11-26 09:03:48,989:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-26 09:03:48,990:INFO:create_model() successfully completed......................................
2023-11-26 09:03:49,016:INFO:SubProcess create_model() end ==================================
2023-11-26 09:03:49,016:INFO:Creating metrics dataframe
2023-11-26 09:03:49,019:INFO:Initializing Ada Boost Classifier
2023-11-26 09:03:49,019:INFO:Total runtime is 0.011508083343505861 minutes
2023-11-26 09:03:49,019:INFO:SubProcess create_model() called ==================================
2023-11-26 09:03:49,019:INFO:Initializing create_model()
2023-11-26 09:03:49,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff76a369d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:03:49,019:INFO:Checking exceptions
2023-11-26 09:03:49,020:INFO:Importing libraries
2023-11-26 09:03:49,020:INFO:Copying training dataset
2023-11-26 09:03:49,021:INFO:Defining folds
2023-11-26 09:03:49,021:INFO:Declaring metric variables
2023-11-26 09:03:49,021:INFO:Importing untrained model
2023-11-26 09:03:49,021:INFO:Ada Boost Classifier Imported successfully
2023-11-26 09:03:49,022:INFO:Starting cross validation
2023-11-26 09:03:49,022:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:03:49,195:INFO:Calculating mean and std
2023-11-26 09:03:49,195:INFO:Creating metrics dataframe
2023-11-26 09:03:49,197:INFO:Uploading results into container
2023-11-26 09:03:49,197:INFO:Uploading model into container now
2023-11-26 09:03:49,197:INFO:_master_model_container: 8
2023-11-26 09:03:49,197:INFO:_display_container: 2
2023-11-26 09:03:49,197:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=8051)
2023-11-26 09:03:49,198:INFO:create_model() successfully completed......................................
2023-11-26 09:03:49,226:INFO:SubProcess create_model() end ==================================
2023-11-26 09:03:49,226:INFO:Creating metrics dataframe
2023-11-26 09:03:49,228:INFO:Initializing Linear Discriminant Analysis
2023-11-26 09:03:49,228:INFO:Total runtime is 0.014997649192810061 minutes
2023-11-26 09:03:49,228:INFO:SubProcess create_model() called ==================================
2023-11-26 09:03:49,229:INFO:Initializing create_model()
2023-11-26 09:03:49,229:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff76a369d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:03:49,229:INFO:Checking exceptions
2023-11-26 09:03:49,229:INFO:Importing libraries
2023-11-26 09:03:49,229:INFO:Copying training dataset
2023-11-26 09:03:49,230:INFO:Defining folds
2023-11-26 09:03:49,230:INFO:Declaring metric variables
2023-11-26 09:03:49,230:INFO:Importing untrained model
2023-11-26 09:03:49,231:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:03:49,231:INFO:Starting cross validation
2023-11-26 09:03:49,231:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:03:49,268:INFO:Calculating mean and std
2023-11-26 09:03:49,268:INFO:Creating metrics dataframe
2023-11-26 09:03:49,270:INFO:Uploading results into container
2023-11-26 09:03:49,270:INFO:Uploading model into container now
2023-11-26 09:03:49,270:INFO:_master_model_container: 9
2023-11-26 09:03:49,271:INFO:_display_container: 2
2023-11-26 09:03:49,271:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:03:49,271:INFO:create_model() successfully completed......................................
2023-11-26 09:03:49,296:INFO:SubProcess create_model() end ==================================
2023-11-26 09:03:49,296:INFO:Creating metrics dataframe
2023-11-26 09:03:49,298:INFO:Initializing Extra Trees Classifier
2023-11-26 09:03:49,298:INFO:Total runtime is 0.01616824865341187 minutes
2023-11-26 09:03:49,299:INFO:SubProcess create_model() called ==================================
2023-11-26 09:03:49,299:INFO:Initializing create_model()
2023-11-26 09:03:49,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff76a369d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:03:49,299:INFO:Checking exceptions
2023-11-26 09:03:49,299:INFO:Importing libraries
2023-11-26 09:03:49,299:INFO:Copying training dataset
2023-11-26 09:03:49,300:INFO:Defining folds
2023-11-26 09:03:49,300:INFO:Declaring metric variables
2023-11-26 09:03:49,301:INFO:Importing untrained model
2023-11-26 09:03:49,301:INFO:Extra Trees Classifier Imported successfully
2023-11-26 09:03:49,301:INFO:Starting cross validation
2023-11-26 09:03:49,301:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:03:50,010:INFO:Calculating mean and std
2023-11-26 09:03:50,010:INFO:Creating metrics dataframe
2023-11-26 09:03:50,012:INFO:Uploading results into container
2023-11-26 09:03:50,012:INFO:Uploading model into container now
2023-11-26 09:03:50,013:INFO:_master_model_container: 10
2023-11-26 09:03:50,013:INFO:_display_container: 2
2023-11-26 09:03:50,013:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=8051, verbose=0, warm_start=False)
2023-11-26 09:03:50,013:INFO:create_model() successfully completed......................................
2023-11-26 09:03:50,042:INFO:SubProcess create_model() end ==================================
2023-11-26 09:03:50,042:INFO:Creating metrics dataframe
2023-11-26 09:03:50,045:INFO:Initializing Light Gradient Boosting Machine
2023-11-26 09:03:50,045:INFO:Total runtime is 0.02860873937606812 minutes
2023-11-26 09:03:50,045:INFO:SubProcess create_model() called ==================================
2023-11-26 09:03:50,045:INFO:Initializing create_model()
2023-11-26 09:03:50,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff76a369d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:03:50,045:INFO:Checking exceptions
2023-11-26 09:03:50,046:INFO:Importing libraries
2023-11-26 09:03:50,046:INFO:Copying training dataset
2023-11-26 09:03:50,047:INFO:Defining folds
2023-11-26 09:03:50,047:INFO:Declaring metric variables
2023-11-26 09:03:50,047:INFO:Importing untrained model
2023-11-26 09:03:50,047:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-26 09:03:50,048:INFO:Starting cross validation
2023-11-26 09:03:50,048:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:03:50,053:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 09:03:50,056:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001808 seconds.
2023-11-26 09:03:50,056:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:03:50,056:INFO:[LightGBM] [Info] Total Bins 488
2023-11-26 09:03:50,056:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 09:03:50,057:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 09:03:50,057:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 09:03:50,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,131:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 09:03:50,131:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.
2023-11-26 09:03:50,131:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:03:50,131:INFO:[LightGBM] [Info] Total Bins 487
2023-11-26 09:03:50,131:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 09:03:50,132:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 09:03:50,132:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 09:03:50,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,215:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 09:03:50,216:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.
2023-11-26 09:03:50,216:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:03:50,216:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 09:03:50,216:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 09:03:50,217:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 09:03:50,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,270:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 09:03:50,270:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000036 seconds.
2023-11-26 09:03:50,271:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:03:50,271:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 09:03:50,271:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 09:03:50,271:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 09:03:50,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,313:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,356:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 60
2023-11-26 09:03:50,356:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000035 seconds.
2023-11-26 09:03:50,356:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:03:50,357:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 09:03:50,357:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 09:03:50,357:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491525 -> initscore=-0.033902
2023-11-26 09:03:50,357:INFO:[LightGBM] [Info] Start training from score -0.033902
2023-11-26 09:03:50,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:03:50,437:INFO:Calculating mean and std
2023-11-26 09:03:50,437:INFO:Creating metrics dataframe
2023-11-26 09:03:50,438:INFO:Uploading results into container
2023-11-26 09:03:50,439:INFO:Uploading model into container now
2023-11-26 09:03:50,439:INFO:_master_model_container: 11
2023-11-26 09:03:50,439:INFO:_display_container: 2
2023-11-26 09:03:50,439:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8051, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-26 09:03:50,439:INFO:create_model() successfully completed......................................
2023-11-26 09:03:50,468:INFO:SubProcess create_model() end ==================================
2023-11-26 09:03:50,468:INFO:Creating metrics dataframe
2023-11-26 09:03:50,470:INFO:Initializing Dummy Classifier
2023-11-26 09:03:50,471:INFO:Total runtime is 0.03570543130238851 minutes
2023-11-26 09:03:50,471:INFO:SubProcess create_model() called ==================================
2023-11-26 09:03:50,471:INFO:Initializing create_model()
2023-11-26 09:03:50,471:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff76a369d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:03:50,471:INFO:Checking exceptions
2023-11-26 09:03:50,471:INFO:Importing libraries
2023-11-26 09:03:50,472:INFO:Copying training dataset
2023-11-26 09:03:50,473:INFO:Defining folds
2023-11-26 09:03:50,473:INFO:Declaring metric variables
2023-11-26 09:03:50,473:INFO:Importing untrained model
2023-11-26 09:03:50,473:INFO:Dummy Classifier Imported successfully
2023-11-26 09:03:50,473:INFO:Starting cross validation
2023-11-26 09:03:50,474:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:03:50,480:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:03:50,487:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:03:50,493:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:03:50,499:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:03:50,506:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:03:50,507:INFO:Calculating mean and std
2023-11-26 09:03:50,507:INFO:Creating metrics dataframe
2023-11-26 09:03:50,509:INFO:Uploading results into container
2023-11-26 09:03:50,509:INFO:Uploading model into container now
2023-11-26 09:03:50,509:INFO:_master_model_container: 12
2023-11-26 09:03:50,509:INFO:_display_container: 2
2023-11-26 09:03:50,510:INFO:DummyClassifier(constant=None, random_state=8051, strategy='prior')
2023-11-26 09:03:50,510:INFO:create_model() successfully completed......................................
2023-11-26 09:03:50,539:INFO:SubProcess create_model() end ==================================
2023-11-26 09:03:50,539:INFO:Creating metrics dataframe
2023-11-26 09:03:50,542:INFO:Initializing create_model()
2023-11-26 09:03:50,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8051, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:03:50,542:INFO:Checking exceptions
2023-11-26 09:03:50,543:INFO:Importing libraries
2023-11-26 09:03:50,543:INFO:Copying training dataset
2023-11-26 09:03:50,544:INFO:Defining folds
2023-11-26 09:03:50,544:INFO:Declaring metric variables
2023-11-26 09:03:50,544:INFO:Importing untrained model
2023-11-26 09:03:50,544:INFO:Declaring custom model
2023-11-26 09:03:50,545:INFO:Ridge Classifier Imported successfully
2023-11-26 09:03:50,545:INFO:Cross validation set to False
2023-11-26 09:03:50,545:INFO:Fitting Model
2023-11-26 09:03:50,549:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8051, solver='auto',
                tol=0.0001)
2023-11-26 09:03:50,549:INFO:create_model() successfully completed......................................
2023-11-26 09:03:50,579:INFO:_master_model_container: 12
2023-11-26 09:03:50,579:INFO:_display_container: 2
2023-11-26 09:03:50,579:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8051, solver='auto',
                tol=0.0001)
2023-11-26 09:03:50,579:INFO:compare_models() successfully completed......................................
2023-11-26 09:03:50,580:INFO:Initializing create_model()
2023-11-26 09:03:50,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:03:50,580:INFO:Checking exceptions
2023-11-26 09:03:50,580:INFO:Importing libraries
2023-11-26 09:03:50,581:INFO:Copying training dataset
2023-11-26 09:03:50,582:INFO:Defining folds
2023-11-26 09:03:50,582:INFO:Declaring metric variables
2023-11-26 09:03:50,582:INFO:Importing untrained model
2023-11-26 09:03:50,582:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:03:50,583:INFO:Starting cross validation
2023-11-26 09:03:50,583:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:03:50,620:INFO:Calculating mean and std
2023-11-26 09:03:50,620:INFO:Creating metrics dataframe
2023-11-26 09:03:50,621:INFO:Finalizing model
2023-11-26 09:03:50,625:INFO:Uploading results into container
2023-11-26 09:03:50,625:INFO:Uploading model into container now
2023-11-26 09:03:50,629:INFO:_master_model_container: 13
2023-11-26 09:03:50,629:INFO:_display_container: 3
2023-11-26 09:03:50,629:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:03:50,629:INFO:create_model() successfully completed......................................
2023-11-26 09:03:50,658:INFO:Initializing tune_model()
2023-11-26 09:03:50,659:INFO:tune_model(estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>)
2023-11-26 09:03:50,659:INFO:Checking exceptions
2023-11-26 09:03:50,660:INFO:Copying training dataset
2023-11-26 09:03:50,661:INFO:Checking base model
2023-11-26 09:03:50,661:INFO:Base model : Linear Discriminant Analysis
2023-11-26 09:03:50,662:INFO:Declaring metric variables
2023-11-26 09:03:50,662:INFO:Defining Hyperparameters
2023-11-26 09:03:50,692:INFO:Tuning with n_jobs=-1
2023-11-26 09:03:50,693:INFO:Initializing RandomizedSearchCV
2023-11-26 09:03:51,916:INFO:best_params: {'actual_estimator__solver': 'eigen', 'actual_estimator__shrinkage': 'auto'}
2023-11-26 09:03:51,916:INFO:Hyperparameter search completed
2023-11-26 09:03:51,916:INFO:SubProcess create_model() called ==================================
2023-11-26 09:03:51,917:INFO:Initializing create_model()
2023-11-26 09:03:51,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff76aa3b20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'eigen', 'shrinkage': 'auto'})
2023-11-26 09:03:51,917:INFO:Checking exceptions
2023-11-26 09:03:51,917:INFO:Importing libraries
2023-11-26 09:03:51,918:INFO:Copying training dataset
2023-11-26 09:03:51,920:INFO:Defining folds
2023-11-26 09:03:51,920:INFO:Declaring metric variables
2023-11-26 09:03:51,920:INFO:Importing untrained model
2023-11-26 09:03:51,920:INFO:Declaring custom model
2023-11-26 09:03:51,921:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:03:51,921:INFO:Starting cross validation
2023-11-26 09:03:51,922:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:03:51,995:INFO:Calculating mean and std
2023-11-26 09:03:51,997:INFO:Creating metrics dataframe
2023-11-26 09:03:52,000:INFO:Finalizing model
2023-11-26 09:03:52,017:INFO:Uploading results into container
2023-11-26 09:03:52,017:INFO:Uploading model into container now
2023-11-26 09:03:52,018:INFO:_master_model_container: 14
2023-11-26 09:03:52,018:INFO:_display_container: 4
2023-11-26 09:03:52,018:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:03:52,018:INFO:create_model() successfully completed......................................
2023-11-26 09:03:52,056:INFO:SubProcess create_model() end ==================================
2023-11-26 09:03:52,056:INFO:choose_better activated
2023-11-26 09:03:52,057:INFO:SubProcess create_model() called ==================================
2023-11-26 09:03:52,057:INFO:Initializing create_model()
2023-11-26 09:03:52,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:03:52,057:INFO:Checking exceptions
2023-11-26 09:03:52,058:INFO:Importing libraries
2023-11-26 09:03:52,058:INFO:Copying training dataset
2023-11-26 09:03:52,059:INFO:Defining folds
2023-11-26 09:03:52,059:INFO:Declaring metric variables
2023-11-26 09:03:52,060:INFO:Importing untrained model
2023-11-26 09:03:52,060:INFO:Declaring custom model
2023-11-26 09:03:52,060:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:03:52,060:INFO:Starting cross validation
2023-11-26 09:03:52,061:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:03:52,100:INFO:Calculating mean and std
2023-11-26 09:03:52,100:INFO:Creating metrics dataframe
2023-11-26 09:03:52,101:INFO:Finalizing model
2023-11-26 09:03:52,105:INFO:Uploading results into container
2023-11-26 09:03:52,105:INFO:Uploading model into container now
2023-11-26 09:03:52,105:INFO:_master_model_container: 15
2023-11-26 09:03:52,105:INFO:_display_container: 5
2023-11-26 09:03:52,105:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:03:52,106:INFO:create_model() successfully completed......................................
2023-11-26 09:03:52,140:INFO:SubProcess create_model() end ==================================
2023-11-26 09:03:52,141:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9971
2023-11-26 09:03:52,141:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9981
2023-11-26 09:03:52,141:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001) is best model
2023-11-26 09:03:52,141:INFO:choose_better completed
2023-11-26 09:03:52,145:INFO:_master_model_container: 15
2023-11-26 09:03:52,145:INFO:_display_container: 4
2023-11-26 09:03:52,146:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:03:52,146:INFO:tune_model() successfully completed......................................
2023-11-26 09:03:52,172:INFO:Initializing evaluate_model()
2023-11-26 09:03:52,172:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-26 09:03:52,175:INFO:Initializing plot_model()
2023-11-26 09:03:52,175:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, system=True)
2023-11-26 09:03:52,175:INFO:Checking exceptions
2023-11-26 09:03:52,176:INFO:Preloading libraries
2023-11-26 09:03:52,176:INFO:Copying training dataset
2023-11-26 09:03:52,176:INFO:Plot type: pipeline
2023-11-26 09:03:52,212:INFO:Visual Rendered Successfully
2023-11-26 09:03:52,260:INFO:plot_model() successfully completed......................................
2023-11-26 09:03:52,262:INFO:Initializing finalize_model()
2023-11-26 09:03:52,263:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-11-26 09:03:52,263:INFO:Finalizing LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:03:52,267:INFO:Initializing create_model()
2023-11-26 09:03:52,270:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage='auto', solver='eigen',
                           store_covariance=False, tol=0.0001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:03:52,271:INFO:Checking exceptions
2023-11-26 09:03:52,272:INFO:Importing libraries
2023-11-26 09:03:52,275:INFO:Copying training dataset
2023-11-26 09:03:52,275:INFO:Defining folds
2023-11-26 09:03:52,275:INFO:Declaring metric variables
2023-11-26 09:03:52,278:INFO:Importing untrained model
2023-11-26 09:03:52,281:INFO:Declaring custom model
2023-11-26 09:03:52,282:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:03:52,283:INFO:Cross validation set to False
2023-11-26 09:03:52,283:INFO:Fitting Model
2023-11-26 09:03:52,304:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage='auto', solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 09:03:52,304:INFO:create_model() successfully completed......................................
2023-11-26 09:03:52,334:INFO:_master_model_container: 15
2023-11-26 09:03:52,334:INFO:_display_container: 4
2023-11-26 09:03:52,336:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage='auto', solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 09:03:52,337:INFO:finalize_model() successfully completed......................................
2023-11-26 09:03:52,849:INFO:Initializing predict_model()
2023-11-26 09:03:52,849:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7a926fa0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage='auto', solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff6c6329d0>)
2023-11-26 09:03:52,850:INFO:Checking exceptions
2023-11-26 09:03:52,850:INFO:Preloading libraries
2023-11-26 09:03:52,850:INFO:Set up data.
2023-11-26 09:03:52,857:INFO:Set up index.
2023-11-26 09:03:52,869:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-11-26 09:03:52,871:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:03:52,873:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:04:35,447:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,449:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,730:INFO:PyCaret ClassificationExperiment
2023-11-26 09:04:35,731:INFO:Logging name: clf-default-name
2023-11-26 09:04:35,731:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-26 09:04:35,731:INFO:version 3.2.0
2023-11-26 09:04:35,731:INFO:Initializing setup()
2023-11-26 09:04:35,731:INFO:self.USI: 7167
2023-11-26 09:04:35,731:INFO:self._variable_keys: {'gpu_n_jobs_param', 'gpu_param', 'is_multiclass', 'html_param', 'exp_name_log', 'exp_id', 'fold_groups_param', '_ml_usecase', 'seed', 'X_test', 'pipeline', 'y', 'USI', 'fold_shuffle_param', 'fold_generator', 'y_test', 'memory', 'X', 'n_jobs_param', 'logging_param', 'idx', 'y_train', 'data', 'target_param', '_available_plots', 'fix_imbalance', 'log_plots_param', 'X_train'}
2023-11-26 09:04:35,731:INFO:Checking environment
2023-11-26 09:04:35,731:INFO:python_version: 3.8.18
2023-11-26 09:04:35,731:INFO:python_build: ('default', 'Nov 21 2023 19:36:55')
2023-11-26 09:04:35,731:INFO:machine: aarch64
2023-11-26 09:04:35,732:INFO:platform: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 09:04:35,732:INFO:Memory: svmem(total=8225304576, available=7057924096, percent=14.2, used=957915136, free=3490521088, active=2020331520, inactive=2086838272, buffers=117403648, cached=3659464704, shared=1888256, slab=445927424)
2023-11-26 09:04:35,733:INFO:Physical Core: 12
2023-11-26 09:04:35,733:INFO:Logical Core: 12
2023-11-26 09:04:35,734:INFO:Checking libraries
2023-11-26 09:04:35,734:INFO:System:
2023-11-26 09:04:35,734:INFO:    python: 3.8.18 (default, Nov 21 2023, 19:36:55)  [GCC 12.2.0]
2023-11-26 09:04:35,734:INFO:executable: /usr/local/bin/python
2023-11-26 09:04:35,734:INFO:   machine: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 09:04:35,734:INFO:PyCaret required dependencies:
2023-11-26 09:04:35,744:INFO:                 pip: 23.3.1
2023-11-26 09:04:35,744:INFO:          setuptools: 57.5.0
2023-11-26 09:04:35,744:INFO:             pycaret: 3.2.0
2023-11-26 09:04:35,744:INFO:             IPython: 8.12.3
2023-11-26 09:04:35,744:INFO:          ipywidgets: 8.1.1
2023-11-26 09:04:35,744:INFO:                tqdm: 4.66.1
2023-11-26 09:04:35,744:INFO:               numpy: 1.24.4
2023-11-26 09:04:35,744:INFO:              pandas: 1.5.3
2023-11-26 09:04:35,744:INFO:              jinja2: 3.1.2
2023-11-26 09:04:35,744:INFO:               scipy: 1.10.1
2023-11-26 09:04:35,745:INFO:              joblib: 1.3.2
2023-11-26 09:04:35,745:INFO:             sklearn: 1.2.2
2023-11-26 09:04:35,745:INFO:                pyod: 1.1.2
2023-11-26 09:04:35,745:INFO:            imblearn: 0.11.0
2023-11-26 09:04:35,745:INFO:   category_encoders: 2.6.3
2023-11-26 09:04:35,745:INFO:            lightgbm: 4.1.0
2023-11-26 09:04:35,745:INFO:               numba: 0.58.1
2023-11-26 09:04:35,745:INFO:            requests: 2.31.0
2023-11-26 09:04:35,745:INFO:          matplotlib: 3.6.0
2023-11-26 09:04:35,745:INFO:          scikitplot: 0.3.7
2023-11-26 09:04:35,746:INFO:         yellowbrick: 1.5
2023-11-26 09:04:35,746:INFO:              plotly: 5.18.0
2023-11-26 09:04:35,746:INFO:    plotly-resampler: Not installed
2023-11-26 09:04:35,746:INFO:             kaleido: 0.2.1
2023-11-26 09:04:35,746:INFO:           schemdraw: 0.15
2023-11-26 09:04:35,746:INFO:         statsmodels: 0.14.0
2023-11-26 09:04:35,746:INFO:              sktime: 0.21.1
2023-11-26 09:04:35,746:INFO:               tbats: 1.1.3
2023-11-26 09:04:35,746:INFO:            pmdarima: 2.0.4
2023-11-26 09:04:35,747:INFO:              psutil: 5.9.6
2023-11-26 09:04:35,747:INFO:          markupsafe: 2.1.3
2023-11-26 09:04:35,747:INFO:             pickle5: Not installed
2023-11-26 09:04:35,747:INFO:         cloudpickle: 3.0.0
2023-11-26 09:04:35,747:INFO:         deprecation: 2.1.0
2023-11-26 09:04:35,747:INFO:              xxhash: 3.4.1
2023-11-26 09:04:35,747:INFO:           wurlitzer: 3.0.3
2023-11-26 09:04:35,747:INFO:PyCaret optional dependencies:
2023-11-26 09:04:35,758:INFO:                shap: Not installed
2023-11-26 09:04:35,758:INFO:           interpret: Not installed
2023-11-26 09:04:35,758:INFO:                umap: Not installed
2023-11-26 09:04:35,758:INFO:     ydata_profiling: Not installed
2023-11-26 09:04:35,758:INFO:  explainerdashboard: Not installed
2023-11-26 09:04:35,758:INFO:             autoviz: Not installed
2023-11-26 09:04:35,759:INFO:           fairlearn: Not installed
2023-11-26 09:04:35,759:INFO:          deepchecks: Not installed
2023-11-26 09:04:35,759:INFO:             xgboost: Not installed
2023-11-26 09:04:35,759:INFO:            catboost: Not installed
2023-11-26 09:04:35,759:INFO:              kmodes: Not installed
2023-11-26 09:04:35,759:INFO:             mlxtend: Not installed
2023-11-26 09:04:35,759:INFO:       statsforecast: Not installed
2023-11-26 09:04:35,759:INFO:        tune_sklearn: Not installed
2023-11-26 09:04:35,759:INFO:                 ray: Not installed
2023-11-26 09:04:35,760:INFO:            hyperopt: Not installed
2023-11-26 09:04:35,760:INFO:              optuna: Not installed
2023-11-26 09:04:35,760:INFO:               skopt: Not installed
2023-11-26 09:04:35,760:INFO:              mlflow: Not installed
2023-11-26 09:04:35,760:INFO:              gradio: Not installed
2023-11-26 09:04:35,760:INFO:             fastapi: Not installed
2023-11-26 09:04:35,760:INFO:             uvicorn: Not installed
2023-11-26 09:04:35,760:INFO:              m2cgen: Not installed
2023-11-26 09:04:35,760:INFO:           evidently: Not installed
2023-11-26 09:04:35,761:INFO:               fugue: Not installed
2023-11-26 09:04:35,761:INFO:           streamlit: Not installed
2023-11-26 09:04:35,761:INFO:             prophet: Not installed
2023-11-26 09:04:35,761:INFO:None
2023-11-26 09:04:35,761:INFO:Set up GPU usage.
2023-11-26 09:04:35,761:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,761:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-26 09:04:35,761:INFO:Set up data.
2023-11-26 09:04:35,764:INFO:Set up folding strategy.
2023-11-26 09:04:35,765:INFO:Set up train/test split.
2023-11-26 09:04:35,766:INFO:Set up index.
2023-11-26 09:04:35,766:INFO:Assigning column types.
2023-11-26 09:04:35,768:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-26 09:04:35,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,785:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 09:04:35,785:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,786:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:04:35,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,796:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,799:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:04:35,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:04:35,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,843:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 09:04:35,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,843:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,844:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:04:35,844:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,853:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,855:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:04:35,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:04:35,861:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-26 09:04:35,861:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,879:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,879:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,879:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:04:35,880:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,888:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,890:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:04:35,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:04:35,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,913:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,913:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,914:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:04:35,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,922:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,924:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,924:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:04:35,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:04:35,929:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-26 09:04:35,929:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,947:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,947:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,947:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,956:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,958:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,958:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:04:35,962:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:04:35,963:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,980:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,980:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,981:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,990:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,992:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:35,992:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:04:35,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:04:35,997:INFO:Preparing preprocessing pipeline...
2023-11-26 09:04:35,999:INFO:Set up simple imputation.
2023-11-26 09:04:36,008:INFO:Finished creating preprocessing pipeline.
2023-11-26 09:04:36,010:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-26 09:04:36,010:INFO:Creating final display dataframe.
2023-11-26 09:04:36,034:INFO:Setup _display_container:                     Description             Value
0                    Session id              4200
1                        Target            target
2                   Target type            Binary
3           Original data shape         (210, 13)
4        Transformed data shape         (210, 13)
5   Transformed train set shape         (147, 13)
6    Transformed test set shape          (63, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              7167
2023-11-26 09:04:36,036:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:36,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:36,054:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:36,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:36,065:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:36,067:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:36,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:04:36,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:04:36,072:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:36,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:36,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:36,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:36,099:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:36,101:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:04:36,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:04:36,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:04:36,107:INFO:setup() successfully completed in 0.38s...............
2023-11-26 09:04:36,107:INFO:Initializing compare_models()
2023-11-26 09:04:36,107:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-26 09:04:36,107:INFO:Checking exceptions
2023-11-26 09:04:36,109:INFO:Preparing display monitor
2023-11-26 09:04:36,111:INFO:Initializing Logistic Regression
2023-11-26 09:04:36,111:INFO:Total runtime is 2.5431315104166665e-06 minutes
2023-11-26 09:04:36,111:INFO:SubProcess create_model() called ==================================
2023-11-26 09:04:36,111:INFO:Initializing create_model()
2023-11-26 09:04:36,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff79c069d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:04:36,112:INFO:Checking exceptions
2023-11-26 09:04:36,112:INFO:Importing libraries
2023-11-26 09:04:36,112:INFO:Copying training dataset
2023-11-26 09:04:36,113:INFO:Defining folds
2023-11-26 09:04:36,113:INFO:Declaring metric variables
2023-11-26 09:04:36,113:INFO:Importing untrained model
2023-11-26 09:04:36,113:INFO:Logistic Regression Imported successfully
2023-11-26 09:04:36,114:INFO:Starting cross validation
2023-11-26 09:04:36,114:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:04:36,173:INFO:Calculating mean and std
2023-11-26 09:04:36,173:INFO:Creating metrics dataframe
2023-11-26 09:04:36,175:INFO:Uploading results into container
2023-11-26 09:04:36,175:INFO:Uploading model into container now
2023-11-26 09:04:36,175:INFO:_master_model_container: 1
2023-11-26 09:04:36,176:INFO:_display_container: 2
2023-11-26 09:04:36,176:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4200, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-26 09:04:36,176:INFO:create_model() successfully completed......................................
2023-11-26 09:04:36,213:INFO:SubProcess create_model() end ==================================
2023-11-26 09:04:36,213:INFO:Creating metrics dataframe
2023-11-26 09:04:36,215:INFO:Initializing K Neighbors Classifier
2023-11-26 09:04:36,216:INFO:Total runtime is 0.0017459273338317873 minutes
2023-11-26 09:04:36,216:INFO:SubProcess create_model() called ==================================
2023-11-26 09:04:36,216:INFO:Initializing create_model()
2023-11-26 09:04:36,216:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff79c069d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:04:36,216:INFO:Checking exceptions
2023-11-26 09:04:36,216:INFO:Importing libraries
2023-11-26 09:04:36,216:INFO:Copying training dataset
2023-11-26 09:04:36,218:INFO:Defining folds
2023-11-26 09:04:36,218:INFO:Declaring metric variables
2023-11-26 09:04:36,218:INFO:Importing untrained model
2023-11-26 09:04:36,218:INFO:K Neighbors Classifier Imported successfully
2023-11-26 09:04:36,219:INFO:Starting cross validation
2023-11-26 09:04:36,219:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:04:36,397:INFO:Calculating mean and std
2023-11-26 09:04:36,398:INFO:Creating metrics dataframe
2023-11-26 09:04:36,399:INFO:Uploading results into container
2023-11-26 09:04:36,399:INFO:Uploading model into container now
2023-11-26 09:04:36,400:INFO:_master_model_container: 2
2023-11-26 09:04:36,400:INFO:_display_container: 2
2023-11-26 09:04:36,400:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-26 09:04:36,400:INFO:create_model() successfully completed......................................
2023-11-26 09:04:36,429:INFO:SubProcess create_model() end ==================================
2023-11-26 09:04:36,430:INFO:Creating metrics dataframe
2023-11-26 09:04:36,432:INFO:Initializing Naive Bayes
2023-11-26 09:04:36,432:INFO:Total runtime is 0.005353581905364991 minutes
2023-11-26 09:04:36,432:INFO:SubProcess create_model() called ==================================
2023-11-26 09:04:36,432:INFO:Initializing create_model()
2023-11-26 09:04:36,433:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff79c069d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:04:36,433:INFO:Checking exceptions
2023-11-26 09:04:36,433:INFO:Importing libraries
2023-11-26 09:04:36,433:INFO:Copying training dataset
2023-11-26 09:04:36,434:INFO:Defining folds
2023-11-26 09:04:36,434:INFO:Declaring metric variables
2023-11-26 09:04:36,434:INFO:Importing untrained model
2023-11-26 09:04:36,435:INFO:Naive Bayes Imported successfully
2023-11-26 09:04:36,435:INFO:Starting cross validation
2023-11-26 09:04:36,435:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:04:36,473:INFO:Calculating mean and std
2023-11-26 09:04:36,473:INFO:Creating metrics dataframe
2023-11-26 09:04:36,475:INFO:Uploading results into container
2023-11-26 09:04:36,475:INFO:Uploading model into container now
2023-11-26 09:04:36,475:INFO:_master_model_container: 3
2023-11-26 09:04:36,475:INFO:_display_container: 2
2023-11-26 09:04:36,475:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-26 09:04:36,476:INFO:create_model() successfully completed......................................
2023-11-26 09:04:36,501:INFO:SubProcess create_model() end ==================================
2023-11-26 09:04:36,501:INFO:Creating metrics dataframe
2023-11-26 09:04:36,503:INFO:Initializing Decision Tree Classifier
2023-11-26 09:04:36,503:INFO:Total runtime is 0.006537314256032309 minutes
2023-11-26 09:04:36,503:INFO:SubProcess create_model() called ==================================
2023-11-26 09:04:36,504:INFO:Initializing create_model()
2023-11-26 09:04:36,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff79c069d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:04:36,504:INFO:Checking exceptions
2023-11-26 09:04:36,504:INFO:Importing libraries
2023-11-26 09:04:36,504:INFO:Copying training dataset
2023-11-26 09:04:36,505:INFO:Defining folds
2023-11-26 09:04:36,505:INFO:Declaring metric variables
2023-11-26 09:04:36,505:INFO:Importing untrained model
2023-11-26 09:04:36,506:INFO:Decision Tree Classifier Imported successfully
2023-11-26 09:04:36,506:INFO:Starting cross validation
2023-11-26 09:04:36,506:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:04:36,545:INFO:Calculating mean and std
2023-11-26 09:04:36,546:INFO:Creating metrics dataframe
2023-11-26 09:04:36,547:INFO:Uploading results into container
2023-11-26 09:04:36,547:INFO:Uploading model into container now
2023-11-26 09:04:36,548:INFO:_master_model_container: 4
2023-11-26 09:04:36,548:INFO:_display_container: 2
2023-11-26 09:04:36,548:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=4200, splitter='best')
2023-11-26 09:04:36,548:INFO:create_model() successfully completed......................................
2023-11-26 09:04:36,577:INFO:SubProcess create_model() end ==================================
2023-11-26 09:04:36,577:INFO:Creating metrics dataframe
2023-11-26 09:04:36,580:INFO:Initializing SVM - Linear Kernel
2023-11-26 09:04:36,580:INFO:Total runtime is 0.007815714677174887 minutes
2023-11-26 09:04:36,580:INFO:SubProcess create_model() called ==================================
2023-11-26 09:04:36,580:INFO:Initializing create_model()
2023-11-26 09:04:36,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff79c069d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:04:36,580:INFO:Checking exceptions
2023-11-26 09:04:36,581:INFO:Importing libraries
2023-11-26 09:04:36,581:INFO:Copying training dataset
2023-11-26 09:04:36,582:INFO:Defining folds
2023-11-26 09:04:36,582:INFO:Declaring metric variables
2023-11-26 09:04:36,582:INFO:Importing untrained model
2023-11-26 09:04:36,583:INFO:SVM - Linear Kernel Imported successfully
2023-11-26 09:04:36,583:INFO:Starting cross validation
2023-11-26 09:04:36,583:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:04:36,590:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:04:36,598:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:04:36,604:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:04:36,611:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:04:36,618:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:04:36,621:INFO:Calculating mean and std
2023-11-26 09:04:36,621:INFO:Creating metrics dataframe
2023-11-26 09:04:36,622:INFO:Uploading results into container
2023-11-26 09:04:36,623:INFO:Uploading model into container now
2023-11-26 09:04:36,623:INFO:_master_model_container: 5
2023-11-26 09:04:36,623:INFO:_display_container: 2
2023-11-26 09:04:36,623:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4200, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-26 09:04:36,623:INFO:create_model() successfully completed......................................
2023-11-26 09:04:36,654:INFO:SubProcess create_model() end ==================================
2023-11-26 09:04:36,655:INFO:Creating metrics dataframe
2023-11-26 09:04:36,657:INFO:Initializing Ridge Classifier
2023-11-26 09:04:36,657:INFO:Total runtime is 0.009103953838348389 minutes
2023-11-26 09:04:36,657:INFO:SubProcess create_model() called ==================================
2023-11-26 09:04:36,657:INFO:Initializing create_model()
2023-11-26 09:04:36,658:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff79c069d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:04:36,658:INFO:Checking exceptions
2023-11-26 09:04:36,658:INFO:Importing libraries
2023-11-26 09:04:36,658:INFO:Copying training dataset
2023-11-26 09:04:36,659:INFO:Defining folds
2023-11-26 09:04:36,659:INFO:Declaring metric variables
2023-11-26 09:04:36,659:INFO:Importing untrained model
2023-11-26 09:04:36,660:INFO:Ridge Classifier Imported successfully
2023-11-26 09:04:36,660:INFO:Starting cross validation
2023-11-26 09:04:36,660:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:04:36,667:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:04:36,674:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:04:36,681:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:04:36,688:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:04:36,695:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:04:36,698:INFO:Calculating mean and std
2023-11-26 09:04:36,698:INFO:Creating metrics dataframe
2023-11-26 09:04:36,700:INFO:Uploading results into container
2023-11-26 09:04:36,700:INFO:Uploading model into container now
2023-11-26 09:04:36,700:INFO:_master_model_container: 6
2023-11-26 09:04:36,701:INFO:_display_container: 2
2023-11-26 09:04:36,701:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4200, solver='auto',
                tol=0.0001)
2023-11-26 09:04:36,701:INFO:create_model() successfully completed......................................
2023-11-26 09:04:36,728:INFO:SubProcess create_model() end ==================================
2023-11-26 09:04:36,728:INFO:Creating metrics dataframe
2023-11-26 09:04:36,730:INFO:Initializing Quadratic Discriminant Analysis
2023-11-26 09:04:36,730:INFO:Total runtime is 0.010323007901509603 minutes
2023-11-26 09:04:36,730:INFO:SubProcess create_model() called ==================================
2023-11-26 09:04:36,731:INFO:Initializing create_model()
2023-11-26 09:04:36,731:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff79c069d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:04:36,731:INFO:Checking exceptions
2023-11-26 09:04:36,731:INFO:Importing libraries
2023-11-26 09:04:36,731:INFO:Copying training dataset
2023-11-26 09:04:36,732:INFO:Defining folds
2023-11-26 09:04:36,732:INFO:Declaring metric variables
2023-11-26 09:04:36,733:INFO:Importing untrained model
2023-11-26 09:04:36,733:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-26 09:04:36,733:INFO:Starting cross validation
2023-11-26 09:04:36,733:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:04:36,771:INFO:Calculating mean and std
2023-11-26 09:04:36,771:INFO:Creating metrics dataframe
2023-11-26 09:04:36,773:INFO:Uploading results into container
2023-11-26 09:04:36,773:INFO:Uploading model into container now
2023-11-26 09:04:36,773:INFO:_master_model_container: 7
2023-11-26 09:04:36,773:INFO:_display_container: 2
2023-11-26 09:04:36,774:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-26 09:04:36,774:INFO:create_model() successfully completed......................................
2023-11-26 09:04:36,801:INFO:SubProcess create_model() end ==================================
2023-11-26 09:04:36,802:INFO:Creating metrics dataframe
2023-11-26 09:04:36,805:INFO:Initializing Ada Boost Classifier
2023-11-26 09:04:36,806:INFO:Total runtime is 0.01157889763514201 minutes
2023-11-26 09:04:36,806:INFO:SubProcess create_model() called ==================================
2023-11-26 09:04:36,806:INFO:Initializing create_model()
2023-11-26 09:04:36,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff79c069d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:04:36,807:INFO:Checking exceptions
2023-11-26 09:04:36,807:INFO:Importing libraries
2023-11-26 09:04:36,807:INFO:Copying training dataset
2023-11-26 09:04:36,808:INFO:Defining folds
2023-11-26 09:04:36,809:INFO:Declaring metric variables
2023-11-26 09:04:36,809:INFO:Importing untrained model
2023-11-26 09:04:36,809:INFO:Ada Boost Classifier Imported successfully
2023-11-26 09:04:36,809:INFO:Starting cross validation
2023-11-26 09:04:36,810:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:04:36,988:INFO:Calculating mean and std
2023-11-26 09:04:36,989:INFO:Creating metrics dataframe
2023-11-26 09:04:36,990:INFO:Uploading results into container
2023-11-26 09:04:36,990:INFO:Uploading model into container now
2023-11-26 09:04:36,991:INFO:_master_model_container: 8
2023-11-26 09:04:36,991:INFO:_display_container: 2
2023-11-26 09:04:36,991:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=4200)
2023-11-26 09:04:36,991:INFO:create_model() successfully completed......................................
2023-11-26 09:04:37,020:INFO:SubProcess create_model() end ==================================
2023-11-26 09:04:37,021:INFO:Creating metrics dataframe
2023-11-26 09:04:37,023:INFO:Initializing Linear Discriminant Analysis
2023-11-26 09:04:37,023:INFO:Total runtime is 0.015203428268432618 minutes
2023-11-26 09:04:37,023:INFO:SubProcess create_model() called ==================================
2023-11-26 09:04:37,023:INFO:Initializing create_model()
2023-11-26 09:04:37,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff79c069d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:04:37,024:INFO:Checking exceptions
2023-11-26 09:04:37,024:INFO:Importing libraries
2023-11-26 09:04:37,024:INFO:Copying training dataset
2023-11-26 09:04:37,025:INFO:Defining folds
2023-11-26 09:04:37,025:INFO:Declaring metric variables
2023-11-26 09:04:37,025:INFO:Importing untrained model
2023-11-26 09:04:37,026:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:04:37,026:INFO:Starting cross validation
2023-11-26 09:04:37,026:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:04:37,064:INFO:Calculating mean and std
2023-11-26 09:04:37,064:INFO:Creating metrics dataframe
2023-11-26 09:04:37,066:INFO:Uploading results into container
2023-11-26 09:04:37,066:INFO:Uploading model into container now
2023-11-26 09:04:37,066:INFO:_master_model_container: 9
2023-11-26 09:04:37,066:INFO:_display_container: 2
2023-11-26 09:04:37,066:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:04:37,066:INFO:create_model() successfully completed......................................
2023-11-26 09:04:37,095:INFO:SubProcess create_model() end ==================================
2023-11-26 09:04:37,095:INFO:Creating metrics dataframe
2023-11-26 09:04:37,097:INFO:Initializing Extra Trees Classifier
2023-11-26 09:04:37,097:INFO:Total runtime is 0.01643775701522827 minutes
2023-11-26 09:04:37,097:INFO:SubProcess create_model() called ==================================
2023-11-26 09:04:37,098:INFO:Initializing create_model()
2023-11-26 09:04:37,098:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff79c069d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:04:37,098:INFO:Checking exceptions
2023-11-26 09:04:37,098:INFO:Importing libraries
2023-11-26 09:04:37,098:INFO:Copying training dataset
2023-11-26 09:04:37,099:INFO:Defining folds
2023-11-26 09:04:37,099:INFO:Declaring metric variables
2023-11-26 09:04:37,099:INFO:Importing untrained model
2023-11-26 09:04:37,100:INFO:Extra Trees Classifier Imported successfully
2023-11-26 09:04:37,100:INFO:Starting cross validation
2023-11-26 09:04:37,100:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:04:37,793:INFO:Calculating mean and std
2023-11-26 09:04:37,793:INFO:Creating metrics dataframe
2023-11-26 09:04:37,795:INFO:Uploading results into container
2023-11-26 09:04:37,795:INFO:Uploading model into container now
2023-11-26 09:04:37,796:INFO:_master_model_container: 10
2023-11-26 09:04:37,796:INFO:_display_container: 2
2023-11-26 09:04:37,796:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=4200, verbose=0, warm_start=False)
2023-11-26 09:04:37,796:INFO:create_model() successfully completed......................................
2023-11-26 09:04:37,829:INFO:SubProcess create_model() end ==================================
2023-11-26 09:04:37,830:INFO:Creating metrics dataframe
2023-11-26 09:04:37,832:INFO:Initializing Light Gradient Boosting Machine
2023-11-26 09:04:37,832:INFO:Total runtime is 0.028690111637115476 minutes
2023-11-26 09:04:37,832:INFO:SubProcess create_model() called ==================================
2023-11-26 09:04:37,833:INFO:Initializing create_model()
2023-11-26 09:04:37,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff79c069d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:04:37,833:INFO:Checking exceptions
2023-11-26 09:04:37,833:INFO:Importing libraries
2023-11-26 09:04:37,833:INFO:Copying training dataset
2023-11-26 09:04:37,834:INFO:Defining folds
2023-11-26 09:04:37,834:INFO:Declaring metric variables
2023-11-26 09:04:37,835:INFO:Importing untrained model
2023-11-26 09:04:37,835:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-26 09:04:37,835:INFO:Starting cross validation
2023-11-26 09:04:37,836:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:04:37,841:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 09:04:37,841:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000119 seconds.
2023-11-26 09:04:37,841:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-26 09:04:37,842:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-26 09:04:37,842:INFO:[LightGBM] [Info] Total Bins 488
2023-11-26 09:04:37,842:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 09:04:37,842:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 09:04:37,843:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 09:04:37,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,897:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 09:04:37,898:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000271 seconds.
2023-11-26 09:04:37,898:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:04:37,899:INFO:[LightGBM] [Info] Total Bins 487
2023-11-26 09:04:37,899:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 09:04:37,899:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 09:04:37,900:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 09:04:37,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,983:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 60
2023-11-26 09:04:37,983:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000042 seconds.
2023-11-26 09:04:37,983:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:04:37,983:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 09:04:37,984:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 09:04:37,984:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491525 -> initscore=-0.033902
2023-11-26 09:04:37,984:INFO:[LightGBM] [Info] Start training from score -0.033902
2023-11-26 09:04:37,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:37,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,077:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 09:04:38,078:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.
2023-11-26 09:04:38,078:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:04:38,078:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 09:04:38,078:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 09:04:38,078:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 09:04:38,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,137:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 09:04:38,138:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.
2023-11-26 09:04:38,138:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:04:38,138:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 09:04:38,138:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 09:04:38,139:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 09:04:38,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:04:38,202:INFO:Calculating mean and std
2023-11-26 09:04:38,202:INFO:Creating metrics dataframe
2023-11-26 09:04:38,203:INFO:Uploading results into container
2023-11-26 09:04:38,204:INFO:Uploading model into container now
2023-11-26 09:04:38,204:INFO:_master_model_container: 11
2023-11-26 09:04:38,204:INFO:_display_container: 2
2023-11-26 09:04:38,204:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4200, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-26 09:04:38,205:INFO:create_model() successfully completed......................................
2023-11-26 09:04:38,234:INFO:SubProcess create_model() end ==================================
2023-11-26 09:04:38,234:INFO:Creating metrics dataframe
2023-11-26 09:04:38,236:INFO:Initializing Dummy Classifier
2023-11-26 09:04:38,236:INFO:Total runtime is 0.03542284965515136 minutes
2023-11-26 09:04:38,236:INFO:SubProcess create_model() called ==================================
2023-11-26 09:04:38,237:INFO:Initializing create_model()
2023-11-26 09:04:38,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff79c069d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:04:38,237:INFO:Checking exceptions
2023-11-26 09:04:38,237:INFO:Importing libraries
2023-11-26 09:04:38,237:INFO:Copying training dataset
2023-11-26 09:04:38,238:INFO:Defining folds
2023-11-26 09:04:38,238:INFO:Declaring metric variables
2023-11-26 09:04:38,239:INFO:Importing untrained model
2023-11-26 09:04:38,239:INFO:Dummy Classifier Imported successfully
2023-11-26 09:04:38,239:INFO:Starting cross validation
2023-11-26 09:04:38,239:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:04:38,246:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:04:38,253:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:04:38,259:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:04:38,266:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:04:38,272:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:04:38,274:INFO:Calculating mean and std
2023-11-26 09:04:38,274:INFO:Creating metrics dataframe
2023-11-26 09:04:38,276:INFO:Uploading results into container
2023-11-26 09:04:38,276:INFO:Uploading model into container now
2023-11-26 09:04:38,276:INFO:_master_model_container: 12
2023-11-26 09:04:38,276:INFO:_display_container: 2
2023-11-26 09:04:38,276:INFO:DummyClassifier(constant=None, random_state=4200, strategy='prior')
2023-11-26 09:04:38,276:INFO:create_model() successfully completed......................................
2023-11-26 09:04:38,303:INFO:SubProcess create_model() end ==================================
2023-11-26 09:04:38,303:INFO:Creating metrics dataframe
2023-11-26 09:04:38,306:INFO:Initializing create_model()
2023-11-26 09:04:38,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4200, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:04:38,306:INFO:Checking exceptions
2023-11-26 09:04:38,307:INFO:Importing libraries
2023-11-26 09:04:38,307:INFO:Copying training dataset
2023-11-26 09:04:38,308:INFO:Defining folds
2023-11-26 09:04:38,308:INFO:Declaring metric variables
2023-11-26 09:04:38,309:INFO:Importing untrained model
2023-11-26 09:04:38,309:INFO:Declaring custom model
2023-11-26 09:04:38,309:INFO:Ridge Classifier Imported successfully
2023-11-26 09:04:38,309:INFO:Cross validation set to False
2023-11-26 09:04:38,310:INFO:Fitting Model
2023-11-26 09:04:38,313:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4200, solver='auto',
                tol=0.0001)
2023-11-26 09:04:38,314:INFO:create_model() successfully completed......................................
2023-11-26 09:04:38,344:INFO:_master_model_container: 12
2023-11-26 09:04:38,344:INFO:_display_container: 2
2023-11-26 09:04:38,344:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4200, solver='auto',
                tol=0.0001)
2023-11-26 09:04:38,344:INFO:compare_models() successfully completed......................................
2023-11-26 09:04:38,344:INFO:Initializing create_model()
2023-11-26 09:04:38,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:04:38,345:INFO:Checking exceptions
2023-11-26 09:04:38,345:INFO:Importing libraries
2023-11-26 09:04:38,345:INFO:Copying training dataset
2023-11-26 09:04:38,347:INFO:Defining folds
2023-11-26 09:04:38,347:INFO:Declaring metric variables
2023-11-26 09:04:38,347:INFO:Importing untrained model
2023-11-26 09:04:38,347:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:04:38,347:INFO:Starting cross validation
2023-11-26 09:04:38,348:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:04:38,386:INFO:Calculating mean and std
2023-11-26 09:04:38,386:INFO:Creating metrics dataframe
2023-11-26 09:04:38,387:INFO:Finalizing model
2023-11-26 09:04:38,391:INFO:Uploading results into container
2023-11-26 09:04:38,391:INFO:Uploading model into container now
2023-11-26 09:04:38,395:INFO:_master_model_container: 13
2023-11-26 09:04:38,395:INFO:_display_container: 3
2023-11-26 09:04:38,395:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:04:38,395:INFO:create_model() successfully completed......................................
2023-11-26 09:04:38,424:INFO:Initializing tune_model()
2023-11-26 09:04:38,424:INFO:tune_model(estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>)
2023-11-26 09:04:38,424:INFO:Checking exceptions
2023-11-26 09:04:38,426:INFO:Copying training dataset
2023-11-26 09:04:38,427:INFO:Checking base model
2023-11-26 09:04:38,427:INFO:Base model : Linear Discriminant Analysis
2023-11-26 09:04:38,427:INFO:Declaring metric variables
2023-11-26 09:04:38,427:INFO:Defining Hyperparameters
2023-11-26 09:04:38,457:INFO:Tuning with n_jobs=-1
2023-11-26 09:04:38,457:INFO:Initializing RandomizedSearchCV
2023-11-26 09:04:39,716:INFO:best_params: {'actual_estimator__solver': 'eigen', 'actual_estimator__shrinkage': 0.2}
2023-11-26 09:04:39,717:INFO:Hyperparameter search completed
2023-11-26 09:04:39,717:INFO:SubProcess create_model() called ==================================
2023-11-26 09:04:39,718:INFO:Initializing create_model()
2023-11-26 09:04:39,718:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff718995e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'eigen', 'shrinkage': 0.2})
2023-11-26 09:04:39,718:INFO:Checking exceptions
2023-11-26 09:04:39,718:INFO:Importing libraries
2023-11-26 09:04:39,718:INFO:Copying training dataset
2023-11-26 09:04:39,720:INFO:Defining folds
2023-11-26 09:04:39,721:INFO:Declaring metric variables
2023-11-26 09:04:39,721:INFO:Importing untrained model
2023-11-26 09:04:39,721:INFO:Declaring custom model
2023-11-26 09:04:39,721:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:04:39,722:INFO:Starting cross validation
2023-11-26 09:04:39,722:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:04:39,788:INFO:Calculating mean and std
2023-11-26 09:04:39,789:INFO:Creating metrics dataframe
2023-11-26 09:04:39,791:INFO:Finalizing model
2023-11-26 09:04:39,797:INFO:Uploading results into container
2023-11-26 09:04:39,800:INFO:Uploading model into container now
2023-11-26 09:04:39,806:INFO:_master_model_container: 14
2023-11-26 09:04:39,806:INFO:_display_container: 4
2023-11-26 09:04:39,807:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.2, solver='eigen',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:04:39,813:INFO:create_model() successfully completed......................................
2023-11-26 09:04:39,853:INFO:SubProcess create_model() end ==================================
2023-11-26 09:04:39,853:INFO:choose_better activated
2023-11-26 09:04:39,854:INFO:SubProcess create_model() called ==================================
2023-11-26 09:04:39,854:INFO:Initializing create_model()
2023-11-26 09:04:39,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:04:39,854:INFO:Checking exceptions
2023-11-26 09:04:39,855:INFO:Importing libraries
2023-11-26 09:04:39,855:INFO:Copying training dataset
2023-11-26 09:04:39,856:INFO:Defining folds
2023-11-26 09:04:39,856:INFO:Declaring metric variables
2023-11-26 09:04:39,856:INFO:Importing untrained model
2023-11-26 09:04:39,857:INFO:Declaring custom model
2023-11-26 09:04:39,857:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:04:39,857:INFO:Starting cross validation
2023-11-26 09:04:39,857:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:04:39,902:INFO:Calculating mean and std
2023-11-26 09:04:39,902:INFO:Creating metrics dataframe
2023-11-26 09:04:39,903:INFO:Finalizing model
2023-11-26 09:04:39,907:INFO:Uploading results into container
2023-11-26 09:04:39,907:INFO:Uploading model into container now
2023-11-26 09:04:39,908:INFO:_master_model_container: 15
2023-11-26 09:04:39,908:INFO:_display_container: 5
2023-11-26 09:04:39,908:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:04:39,908:INFO:create_model() successfully completed......................................
2023-11-26 09:04:39,937:INFO:SubProcess create_model() end ==================================
2023-11-26 09:04:39,938:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9982
2023-11-26 09:04:39,938:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.2, solver='eigen',
                           store_covariance=False, tol=0.0001) result for AUC is 1.0
2023-11-26 09:04:39,938:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.2, solver='eigen',
                           store_covariance=False, tol=0.0001) is best model
2023-11-26 09:04:39,938:INFO:choose_better completed
2023-11-26 09:04:39,942:INFO:_master_model_container: 15
2023-11-26 09:04:39,942:INFO:_display_container: 4
2023-11-26 09:04:39,942:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.2, solver='eigen',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:04:39,942:INFO:tune_model() successfully completed......................................
2023-11-26 09:04:39,971:INFO:Initializing evaluate_model()
2023-11-26 09:04:39,972:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.2, solver='eigen',
                           store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-26 09:04:39,974:INFO:Initializing plot_model()
2023-11-26 09:04:39,975:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.2, solver='eigen',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, system=True)
2023-11-26 09:04:39,975:INFO:Checking exceptions
2023-11-26 09:04:39,975:INFO:Preloading libraries
2023-11-26 09:04:39,976:INFO:Copying training dataset
2023-11-26 09:04:39,976:INFO:Plot type: pipeline
2023-11-26 09:04:40,011:INFO:Visual Rendered Successfully
2023-11-26 09:04:40,046:INFO:plot_model() successfully completed......................................
2023-11-26 09:04:40,048:INFO:Initializing finalize_model()
2023-11-26 09:04:40,050:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.2, solver='eigen',
                           store_covariance=False, tol=0.0001), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-11-26 09:04:40,050:INFO:Finalizing LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.2, solver='eigen',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:04:40,053:INFO:Initializing create_model()
2023-11-26 09:04:40,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.2, solver='eigen',
                           store_covariance=False, tol=0.0001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:04:40,054:INFO:Checking exceptions
2023-11-26 09:04:40,055:INFO:Importing libraries
2023-11-26 09:04:40,055:INFO:Copying training dataset
2023-11-26 09:04:40,055:INFO:Defining folds
2023-11-26 09:04:40,055:INFO:Declaring metric variables
2023-11-26 09:04:40,056:INFO:Importing untrained model
2023-11-26 09:04:40,056:INFO:Declaring custom model
2023-11-26 09:04:40,056:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:04:40,057:INFO:Cross validation set to False
2023-11-26 09:04:40,057:INFO:Fitting Model
2023-11-26 09:04:40,066:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.2, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 09:04:40,069:INFO:create_model() successfully completed......................................
2023-11-26 09:04:40,122:INFO:_master_model_container: 15
2023-11-26 09:04:40,122:INFO:_display_container: 4
2023-11-26 09:04:40,124:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.2, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 09:04:40,124:INFO:finalize_model() successfully completed......................................
2023-11-26 09:04:40,636:INFO:Initializing predict_model()
2023-11-26 09:04:40,636:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff7daf6fa0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.2, solver='eigen',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff4efd39d0>)
2023-11-26 09:04:40,636:INFO:Checking exceptions
2023-11-26 09:04:40,637:INFO:Preloading libraries
2023-11-26 09:04:40,637:INFO:Set up data.
2023-11-26 09:04:40,640:INFO:Set up index.
2023-11-26 09:04:40,646:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-11-26 09:04:40,661:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:04:40,664:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:05:09,672:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:09,672:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:09,672:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:09,673:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:09,960:INFO:PyCaret ClassificationExperiment
2023-11-26 09:05:09,960:INFO:Logging name: clf-default-name
2023-11-26 09:05:09,960:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-26 09:05:09,960:INFO:version 3.2.0
2023-11-26 09:05:09,960:INFO:Initializing setup()
2023-11-26 09:05:09,960:INFO:self.USI: 3aaa
2023-11-26 09:05:09,961:INFO:self._variable_keys: {'fold_shuffle_param', 'y_train', 'X_test', 'fold_groups_param', 'html_param', 'pipeline', 'target_param', 'memory', 'fold_generator', 'X_train', '_available_plots', 'USI', 'seed', 'gpu_n_jobs_param', 'exp_name_log', 'data', 'logging_param', 'exp_id', '_ml_usecase', 'log_plots_param', 'y', 'n_jobs_param', 'is_multiclass', 'y_test', 'idx', 'gpu_param', 'X', 'fix_imbalance'}
2023-11-26 09:05:09,961:INFO:Checking environment
2023-11-26 09:05:09,961:INFO:python_version: 3.8.18
2023-11-26 09:05:09,961:INFO:python_build: ('default', 'Nov 21 2023 19:36:55')
2023-11-26 09:05:09,961:INFO:machine: aarch64
2023-11-26 09:05:09,962:INFO:platform: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 09:05:09,962:INFO:Memory: svmem(total=8225304576, available=7060619264, percent=14.2, used=955215872, free=3493068800, active=2020335616, inactive=2085998592, buffers=117411840, cached=3659608064, shared=1892352, slab=446189568)
2023-11-26 09:05:09,963:INFO:Physical Core: 12
2023-11-26 09:05:09,963:INFO:Logical Core: 12
2023-11-26 09:05:09,963:INFO:Checking libraries
2023-11-26 09:05:09,963:INFO:System:
2023-11-26 09:05:09,963:INFO:    python: 3.8.18 (default, Nov 21 2023, 19:36:55)  [GCC 12.2.0]
2023-11-26 09:05:09,963:INFO:executable: /usr/local/bin/python
2023-11-26 09:05:09,963:INFO:   machine: Linux-6.4.16-linuxkit-aarch64-with-glibc2.34
2023-11-26 09:05:09,963:INFO:PyCaret required dependencies:
2023-11-26 09:05:09,974:INFO:                 pip: 23.3.1
2023-11-26 09:05:09,974:INFO:          setuptools: 57.5.0
2023-11-26 09:05:09,974:INFO:             pycaret: 3.2.0
2023-11-26 09:05:09,974:INFO:             IPython: 8.12.3
2023-11-26 09:05:09,974:INFO:          ipywidgets: 8.1.1
2023-11-26 09:05:09,974:INFO:                tqdm: 4.66.1
2023-11-26 09:05:09,974:INFO:               numpy: 1.24.4
2023-11-26 09:05:09,974:INFO:              pandas: 1.5.3
2023-11-26 09:05:09,975:INFO:              jinja2: 3.1.2
2023-11-26 09:05:09,975:INFO:               scipy: 1.10.1
2023-11-26 09:05:09,975:INFO:              joblib: 1.3.2
2023-11-26 09:05:09,975:INFO:             sklearn: 1.2.2
2023-11-26 09:05:09,975:INFO:                pyod: 1.1.2
2023-11-26 09:05:09,975:INFO:            imblearn: 0.11.0
2023-11-26 09:05:09,975:INFO:   category_encoders: 2.6.3
2023-11-26 09:05:09,975:INFO:            lightgbm: 4.1.0
2023-11-26 09:05:09,976:INFO:               numba: 0.58.1
2023-11-26 09:05:09,976:INFO:            requests: 2.31.0
2023-11-26 09:05:09,976:INFO:          matplotlib: 3.6.0
2023-11-26 09:05:09,976:INFO:          scikitplot: 0.3.7
2023-11-26 09:05:09,976:INFO:         yellowbrick: 1.5
2023-11-26 09:05:09,976:INFO:              plotly: 5.18.0
2023-11-26 09:05:09,976:INFO:    plotly-resampler: Not installed
2023-11-26 09:05:09,976:INFO:             kaleido: 0.2.1
2023-11-26 09:05:09,976:INFO:           schemdraw: 0.15
2023-11-26 09:05:09,977:INFO:         statsmodels: 0.14.0
2023-11-26 09:05:09,977:INFO:              sktime: 0.21.1
2023-11-26 09:05:09,977:INFO:               tbats: 1.1.3
2023-11-26 09:05:09,977:INFO:            pmdarima: 2.0.4
2023-11-26 09:05:09,977:INFO:              psutil: 5.9.6
2023-11-26 09:05:09,977:INFO:          markupsafe: 2.1.3
2023-11-26 09:05:09,977:INFO:             pickle5: Not installed
2023-11-26 09:05:09,977:INFO:         cloudpickle: 3.0.0
2023-11-26 09:05:09,977:INFO:         deprecation: 2.1.0
2023-11-26 09:05:09,978:INFO:              xxhash: 3.4.1
2023-11-26 09:05:09,978:INFO:           wurlitzer: 3.0.3
2023-11-26 09:05:09,978:INFO:PyCaret optional dependencies:
2023-11-26 09:05:09,993:INFO:                shap: Not installed
2023-11-26 09:05:09,993:INFO:           interpret: Not installed
2023-11-26 09:05:09,993:INFO:                umap: Not installed
2023-11-26 09:05:09,993:INFO:     ydata_profiling: Not installed
2023-11-26 09:05:09,993:INFO:  explainerdashboard: Not installed
2023-11-26 09:05:09,993:INFO:             autoviz: Not installed
2023-11-26 09:05:09,994:INFO:           fairlearn: Not installed
2023-11-26 09:05:09,994:INFO:          deepchecks: Not installed
2023-11-26 09:05:09,994:INFO:             xgboost: Not installed
2023-11-26 09:05:09,994:INFO:            catboost: Not installed
2023-11-26 09:05:09,994:INFO:              kmodes: Not installed
2023-11-26 09:05:09,994:INFO:             mlxtend: Not installed
2023-11-26 09:05:09,994:INFO:       statsforecast: Not installed
2023-11-26 09:05:09,995:INFO:        tune_sklearn: Not installed
2023-11-26 09:05:09,995:INFO:                 ray: Not installed
2023-11-26 09:05:09,995:INFO:            hyperopt: Not installed
2023-11-26 09:05:09,995:INFO:              optuna: Not installed
2023-11-26 09:05:09,995:INFO:               skopt: Not installed
2023-11-26 09:05:09,995:INFO:              mlflow: Not installed
2023-11-26 09:05:09,996:INFO:              gradio: Not installed
2023-11-26 09:05:09,996:INFO:             fastapi: Not installed
2023-11-26 09:05:09,996:INFO:             uvicorn: Not installed
2023-11-26 09:05:09,996:INFO:              m2cgen: Not installed
2023-11-26 09:05:09,996:INFO:           evidently: Not installed
2023-11-26 09:05:09,996:INFO:               fugue: Not installed
2023-11-26 09:05:09,996:INFO:           streamlit: Not installed
2023-11-26 09:05:09,996:INFO:             prophet: Not installed
2023-11-26 09:05:09,997:INFO:None
2023-11-26 09:05:09,997:INFO:Set up GPU usage.
2023-11-26 09:05:09,997:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:09,997:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2023-11-26 09:05:09,997:INFO:Set up data.
2023-11-26 09:05:10,000:INFO:Set up folding strategy.
2023-11-26 09:05:10,000:INFO:Set up train/test split.
2023-11-26 09:05:10,002:INFO:Set up index.
2023-11-26 09:05:10,002:INFO:Assigning column types.
2023-11-26 09:05:10,003:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-26 09:05:10,003:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,021:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 09:05:10,021:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,022:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:05:10,022:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,032:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:05:10,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:05:10,053:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,070:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-26 09:05:10,071:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,071:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,071:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:05:10,071:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,082:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,082:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:05:10,087:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:05:10,087:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-26 09:05:10,087:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,106:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:05:10,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,117:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:05:10,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:05:10,122:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,141:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-26 09:05:10,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,152:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,152:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:05:10,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:05:10,156:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-26 09:05:10,157:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,175:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,175:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,183:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:05:10,190:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:05:10,190:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,208:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,208:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,209:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,217:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,219:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:05:10,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:05:10,225:INFO:Preparing preprocessing pipeline...
2023-11-26 09:05:10,226:INFO:Set up simple imputation.
2023-11-26 09:05:10,235:INFO:Finished creating preprocessing pipeline.
2023-11-26 09:05:10,237:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-26 09:05:10,237:INFO:Creating final display dataframe.
2023-11-26 09:05:10,260:INFO:Setup _display_container:                     Description             Value
0                    Session id              5257
1                        Target            target
2                   Target type            Binary
3           Original data shape         (210, 13)
4        Transformed data shape         (210, 13)
5   Transformed train set shape         (147, 13)
6    Transformed test set shape          (63, 13)
7              Numeric features                12
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 5
14                     CPU Jobs                -1
15                      Use GPU              True
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3aaa
2023-11-26 09:05:10,262:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,281:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,291:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,293:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,293:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:05:10,298:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:05:10,298:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,316:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,316:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,316:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-26 09:05:10,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:05:10,331:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-26 09:05:10,332:INFO:setup() successfully completed in 0.37s...............
2023-11-26 09:05:10,332:INFO:Initializing compare_models()
2023-11-26 09:05:10,332:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, 'include': None, 'exclude': ['catboost', 'xgboost', 'gbc', 'rf'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost', 'xgboost', 'gbc', 'rf'])
2023-11-26 09:05:10,332:INFO:Checking exceptions
2023-11-26 09:05:10,333:INFO:Preparing display monitor
2023-11-26 09:05:10,336:INFO:Initializing Logistic Regression
2023-11-26 09:05:10,336:INFO:Total runtime is 3.723303476969401e-06 minutes
2023-11-26 09:05:10,336:INFO:SubProcess create_model() called ==================================
2023-11-26 09:05:10,337:INFO:Initializing create_model()
2023-11-26 09:05:10,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff746469d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:05:10,337:INFO:Checking exceptions
2023-11-26 09:05:10,337:INFO:Importing libraries
2023-11-26 09:05:10,337:INFO:Copying training dataset
2023-11-26 09:05:10,338:INFO:Defining folds
2023-11-26 09:05:10,338:INFO:Declaring metric variables
2023-11-26 09:05:10,339:INFO:Importing untrained model
2023-11-26 09:05:10,339:INFO:Logistic Regression Imported successfully
2023-11-26 09:05:10,339:INFO:Starting cross validation
2023-11-26 09:05:10,339:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:05:10,397:INFO:Calculating mean and std
2023-11-26 09:05:10,397:INFO:Creating metrics dataframe
2023-11-26 09:05:10,399:INFO:Uploading results into container
2023-11-26 09:05:10,399:INFO:Uploading model into container now
2023-11-26 09:05:10,399:INFO:_master_model_container: 1
2023-11-26 09:05:10,399:INFO:_display_container: 2
2023-11-26 09:05:10,400:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5257, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-26 09:05:10,400:INFO:create_model() successfully completed......................................
2023-11-26 09:05:10,437:INFO:SubProcess create_model() end ==================================
2023-11-26 09:05:10,437:INFO:Creating metrics dataframe
2023-11-26 09:05:10,439:INFO:Initializing K Neighbors Classifier
2023-11-26 09:05:10,439:INFO:Total runtime is 0.0017159740130106608 minutes
2023-11-26 09:05:10,439:INFO:SubProcess create_model() called ==================================
2023-11-26 09:05:10,439:INFO:Initializing create_model()
2023-11-26 09:05:10,440:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff746469d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:05:10,440:INFO:Checking exceptions
2023-11-26 09:05:10,440:INFO:Importing libraries
2023-11-26 09:05:10,440:INFO:Copying training dataset
2023-11-26 09:05:10,441:INFO:Defining folds
2023-11-26 09:05:10,441:INFO:Declaring metric variables
2023-11-26 09:05:10,442:INFO:Importing untrained model
2023-11-26 09:05:10,442:INFO:K Neighbors Classifier Imported successfully
2023-11-26 09:05:10,442:INFO:Starting cross validation
2023-11-26 09:05:10,442:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:05:10,623:INFO:Calculating mean and std
2023-11-26 09:05:10,623:INFO:Creating metrics dataframe
2023-11-26 09:05:10,625:INFO:Uploading results into container
2023-11-26 09:05:10,626:INFO:Uploading model into container now
2023-11-26 09:05:10,628:INFO:_master_model_container: 2
2023-11-26 09:05:10,628:INFO:_display_container: 2
2023-11-26 09:05:10,628:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-26 09:05:10,628:INFO:create_model() successfully completed......................................
2023-11-26 09:05:10,664:INFO:SubProcess create_model() end ==================================
2023-11-26 09:05:10,665:INFO:Creating metrics dataframe
2023-11-26 09:05:10,667:INFO:Initializing Naive Bayes
2023-11-26 09:05:10,667:INFO:Total runtime is 0.005516715844472249 minutes
2023-11-26 09:05:10,667:INFO:SubProcess create_model() called ==================================
2023-11-26 09:05:10,667:INFO:Initializing create_model()
2023-11-26 09:05:10,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff746469d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:05:10,668:INFO:Checking exceptions
2023-11-26 09:05:10,668:INFO:Importing libraries
2023-11-26 09:05:10,668:INFO:Copying training dataset
2023-11-26 09:05:10,669:INFO:Defining folds
2023-11-26 09:05:10,669:INFO:Declaring metric variables
2023-11-26 09:05:10,670:INFO:Importing untrained model
2023-11-26 09:05:10,670:INFO:Naive Bayes Imported successfully
2023-11-26 09:05:10,670:INFO:Starting cross validation
2023-11-26 09:05:10,670:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:05:10,707:INFO:Calculating mean and std
2023-11-26 09:05:10,708:INFO:Creating metrics dataframe
2023-11-26 09:05:10,709:INFO:Uploading results into container
2023-11-26 09:05:10,710:INFO:Uploading model into container now
2023-11-26 09:05:10,710:INFO:_master_model_container: 3
2023-11-26 09:05:10,710:INFO:_display_container: 2
2023-11-26 09:05:10,710:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-26 09:05:10,711:INFO:create_model() successfully completed......................................
2023-11-26 09:05:10,738:INFO:SubProcess create_model() end ==================================
2023-11-26 09:05:10,739:INFO:Creating metrics dataframe
2023-11-26 09:05:10,741:INFO:Initializing Decision Tree Classifier
2023-11-26 09:05:10,741:INFO:Total runtime is 0.006749979654947917 minutes
2023-11-26 09:05:10,741:INFO:SubProcess create_model() called ==================================
2023-11-26 09:05:10,741:INFO:Initializing create_model()
2023-11-26 09:05:10,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff746469d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:05:10,742:INFO:Checking exceptions
2023-11-26 09:05:10,742:INFO:Importing libraries
2023-11-26 09:05:10,742:INFO:Copying training dataset
2023-11-26 09:05:10,743:INFO:Defining folds
2023-11-26 09:05:10,743:INFO:Declaring metric variables
2023-11-26 09:05:10,743:INFO:Importing untrained model
2023-11-26 09:05:10,744:INFO:Decision Tree Classifier Imported successfully
2023-11-26 09:05:10,744:INFO:Starting cross validation
2023-11-26 09:05:10,744:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:05:10,782:INFO:Calculating mean and std
2023-11-26 09:05:10,782:INFO:Creating metrics dataframe
2023-11-26 09:05:10,783:INFO:Uploading results into container
2023-11-26 09:05:10,784:INFO:Uploading model into container now
2023-11-26 09:05:10,784:INFO:_master_model_container: 4
2023-11-26 09:05:10,784:INFO:_display_container: 2
2023-11-26 09:05:10,784:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5257, splitter='best')
2023-11-26 09:05:10,784:INFO:create_model() successfully completed......................................
2023-11-26 09:05:10,814:INFO:SubProcess create_model() end ==================================
2023-11-26 09:05:10,814:INFO:Creating metrics dataframe
2023-11-26 09:05:10,816:INFO:Initializing SVM - Linear Kernel
2023-11-26 09:05:10,816:INFO:Total runtime is 0.008003763357798259 minutes
2023-11-26 09:05:10,816:INFO:SubProcess create_model() called ==================================
2023-11-26 09:05:10,817:INFO:Initializing create_model()
2023-11-26 09:05:10,817:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff746469d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:05:10,817:INFO:Checking exceptions
2023-11-26 09:05:10,817:INFO:Importing libraries
2023-11-26 09:05:10,817:INFO:Copying training dataset
2023-11-26 09:05:10,818:INFO:Defining folds
2023-11-26 09:05:10,819:INFO:Declaring metric variables
2023-11-26 09:05:10,819:INFO:Importing untrained model
2023-11-26 09:05:10,819:INFO:SVM - Linear Kernel Imported successfully
2023-11-26 09:05:10,819:INFO:Starting cross validation
2023-11-26 09:05:10,820:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:05:10,826:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:05:10,833:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:05:10,840:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:05:10,846:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:05:10,853:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-26 09:05:10,855:INFO:Calculating mean and std
2023-11-26 09:05:10,856:INFO:Creating metrics dataframe
2023-11-26 09:05:10,857:INFO:Uploading results into container
2023-11-26 09:05:10,857:INFO:Uploading model into container now
2023-11-26 09:05:10,858:INFO:_master_model_container: 5
2023-11-26 09:05:10,858:INFO:_display_container: 2
2023-11-26 09:05:10,858:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5257, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-26 09:05:10,858:INFO:create_model() successfully completed......................................
2023-11-26 09:05:10,887:INFO:SubProcess create_model() end ==================================
2023-11-26 09:05:10,887:INFO:Creating metrics dataframe
2023-11-26 09:05:10,889:INFO:Initializing Ridge Classifier
2023-11-26 09:05:10,889:INFO:Total runtime is 0.009219996134440104 minutes
2023-11-26 09:05:10,889:INFO:SubProcess create_model() called ==================================
2023-11-26 09:05:10,890:INFO:Initializing create_model()
2023-11-26 09:05:10,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff746469d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:05:10,890:INFO:Checking exceptions
2023-11-26 09:05:10,890:INFO:Importing libraries
2023-11-26 09:05:10,890:INFO:Copying training dataset
2023-11-26 09:05:10,891:INFO:Defining folds
2023-11-26 09:05:10,891:INFO:Declaring metric variables
2023-11-26 09:05:10,892:INFO:Importing untrained model
2023-11-26 09:05:10,892:INFO:Ridge Classifier Imported successfully
2023-11-26 09:05:10,892:INFO:Starting cross validation
2023-11-26 09:05:10,892:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:05:10,899:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:05:10,906:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:05:10,912:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:05:10,919:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:05:10,926:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 182, in _score
    return super()._score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 127, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-26 09:05:10,929:INFO:Calculating mean and std
2023-11-26 09:05:10,929:INFO:Creating metrics dataframe
2023-11-26 09:05:10,931:INFO:Uploading results into container
2023-11-26 09:05:10,931:INFO:Uploading model into container now
2023-11-26 09:05:10,931:INFO:_master_model_container: 6
2023-11-26 09:05:10,931:INFO:_display_container: 2
2023-11-26 09:05:10,931:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5257, solver='auto',
                tol=0.0001)
2023-11-26 09:05:10,932:INFO:create_model() successfully completed......................................
2023-11-26 09:05:10,958:INFO:SubProcess create_model() end ==================================
2023-11-26 09:05:10,958:INFO:Creating metrics dataframe
2023-11-26 09:05:10,960:INFO:Initializing Quadratic Discriminant Analysis
2023-11-26 09:05:10,960:INFO:Total runtime is 0.010406839847564697 minutes
2023-11-26 09:05:10,961:INFO:SubProcess create_model() called ==================================
2023-11-26 09:05:10,961:INFO:Initializing create_model()
2023-11-26 09:05:10,961:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff746469d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:05:10,961:INFO:Checking exceptions
2023-11-26 09:05:10,961:INFO:Importing libraries
2023-11-26 09:05:10,961:INFO:Copying training dataset
2023-11-26 09:05:10,963:INFO:Defining folds
2023-11-26 09:05:10,963:INFO:Declaring metric variables
2023-11-26 09:05:10,963:INFO:Importing untrained model
2023-11-26 09:05:10,963:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-26 09:05:10,963:INFO:Starting cross validation
2023-11-26 09:05:10,964:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:05:11,000:INFO:Calculating mean and std
2023-11-26 09:05:11,000:INFO:Creating metrics dataframe
2023-11-26 09:05:11,002:INFO:Uploading results into container
2023-11-26 09:05:11,002:INFO:Uploading model into container now
2023-11-26 09:05:11,002:INFO:_master_model_container: 7
2023-11-26 09:05:11,002:INFO:_display_container: 2
2023-11-26 09:05:11,002:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-26 09:05:11,003:INFO:create_model() successfully completed......................................
2023-11-26 09:05:11,029:INFO:SubProcess create_model() end ==================================
2023-11-26 09:05:11,029:INFO:Creating metrics dataframe
2023-11-26 09:05:11,031:INFO:Initializing Ada Boost Classifier
2023-11-26 09:05:11,031:INFO:Total runtime is 0.01158913771311442 minutes
2023-11-26 09:05:11,032:INFO:SubProcess create_model() called ==================================
2023-11-26 09:05:11,032:INFO:Initializing create_model()
2023-11-26 09:05:11,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff746469d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:05:11,032:INFO:Checking exceptions
2023-11-26 09:05:11,032:INFO:Importing libraries
2023-11-26 09:05:11,032:INFO:Copying training dataset
2023-11-26 09:05:11,034:INFO:Defining folds
2023-11-26 09:05:11,034:INFO:Declaring metric variables
2023-11-26 09:05:11,034:INFO:Importing untrained model
2023-11-26 09:05:11,034:INFO:Ada Boost Classifier Imported successfully
2023-11-26 09:05:11,035:INFO:Starting cross validation
2023-11-26 09:05:11,035:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:05:11,212:INFO:Calculating mean and std
2023-11-26 09:05:11,213:INFO:Creating metrics dataframe
2023-11-26 09:05:11,214:INFO:Uploading results into container
2023-11-26 09:05:11,214:INFO:Uploading model into container now
2023-11-26 09:05:11,215:INFO:_master_model_container: 8
2023-11-26 09:05:11,215:INFO:_display_container: 2
2023-11-26 09:05:11,215:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=5257)
2023-11-26 09:05:11,215:INFO:create_model() successfully completed......................................
2023-11-26 09:05:11,244:INFO:SubProcess create_model() end ==================================
2023-11-26 09:05:11,244:INFO:Creating metrics dataframe
2023-11-26 09:05:11,246:INFO:Initializing Linear Discriminant Analysis
2023-11-26 09:05:11,246:INFO:Total runtime is 0.015171329180399575 minutes
2023-11-26 09:05:11,247:INFO:SubProcess create_model() called ==================================
2023-11-26 09:05:11,247:INFO:Initializing create_model()
2023-11-26 09:05:11,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff746469d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:05:11,247:INFO:Checking exceptions
2023-11-26 09:05:11,247:INFO:Importing libraries
2023-11-26 09:05:11,247:INFO:Copying training dataset
2023-11-26 09:05:11,248:INFO:Defining folds
2023-11-26 09:05:11,249:INFO:Declaring metric variables
2023-11-26 09:05:11,249:INFO:Importing untrained model
2023-11-26 09:05:11,249:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:05:11,249:INFO:Starting cross validation
2023-11-26 09:05:11,250:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:05:11,288:INFO:Calculating mean and std
2023-11-26 09:05:11,288:INFO:Creating metrics dataframe
2023-11-26 09:05:11,290:INFO:Uploading results into container
2023-11-26 09:05:11,290:INFO:Uploading model into container now
2023-11-26 09:05:11,291:INFO:_master_model_container: 9
2023-11-26 09:05:11,291:INFO:_display_container: 2
2023-11-26 09:05:11,291:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:05:11,291:INFO:create_model() successfully completed......................................
2023-11-26 09:05:11,318:INFO:SubProcess create_model() end ==================================
2023-11-26 09:05:11,319:INFO:Creating metrics dataframe
2023-11-26 09:05:11,321:INFO:Initializing Extra Trees Classifier
2023-11-26 09:05:11,321:INFO:Total runtime is 0.01641740004221598 minutes
2023-11-26 09:05:11,321:INFO:SubProcess create_model() called ==================================
2023-11-26 09:05:11,321:INFO:Initializing create_model()
2023-11-26 09:05:11,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff746469d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:05:11,322:INFO:Checking exceptions
2023-11-26 09:05:11,322:INFO:Importing libraries
2023-11-26 09:05:11,322:INFO:Copying training dataset
2023-11-26 09:05:11,323:INFO:Defining folds
2023-11-26 09:05:11,323:INFO:Declaring metric variables
2023-11-26 09:05:11,323:INFO:Importing untrained model
2023-11-26 09:05:11,324:INFO:Extra Trees Classifier Imported successfully
2023-11-26 09:05:11,324:INFO:Starting cross validation
2023-11-26 09:05:11,324:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:05:12,009:INFO:Calculating mean and std
2023-11-26 09:05:12,010:INFO:Creating metrics dataframe
2023-11-26 09:05:12,011:INFO:Uploading results into container
2023-11-26 09:05:12,012:INFO:Uploading model into container now
2023-11-26 09:05:12,012:INFO:_master_model_container: 10
2023-11-26 09:05:12,012:INFO:_display_container: 2
2023-11-26 09:05:12,012:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5257, verbose=0, warm_start=False)
2023-11-26 09:05:12,012:INFO:create_model() successfully completed......................................
2023-11-26 09:05:12,041:INFO:SubProcess create_model() end ==================================
2023-11-26 09:05:12,041:INFO:Creating metrics dataframe
2023-11-26 09:05:12,043:INFO:Initializing Light Gradient Boosting Machine
2023-11-26 09:05:12,043:INFO:Total runtime is 0.02845544417699178 minutes
2023-11-26 09:05:12,044:INFO:SubProcess create_model() called ==================================
2023-11-26 09:05:12,044:INFO:Initializing create_model()
2023-11-26 09:05:12,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff746469d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:05:12,044:INFO:Checking exceptions
2023-11-26 09:05:12,044:INFO:Importing libraries
2023-11-26 09:05:12,044:INFO:Copying training dataset
2023-11-26 09:05:12,045:INFO:Defining folds
2023-11-26 09:05:12,046:INFO:Declaring metric variables
2023-11-26 09:05:12,046:INFO:Importing untrained model
2023-11-26 09:05:12,046:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-26 09:05:12,046:INFO:Starting cross validation
2023-11-26 09:05:12,047:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:05:12,052:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 09:05:12,054:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001802 seconds.
2023-11-26 09:05:12,055:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:05:12,055:INFO:[LightGBM] [Info] Total Bins 488
2023-11-26 09:05:12,055:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 09:05:12,056:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 09:05:12,056:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 09:05:12,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,104:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 59
2023-11-26 09:05:12,106:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001685 seconds.
2023-11-26 09:05:12,106:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:05:12,106:INFO:[LightGBM] [Info] Total Bins 486
2023-11-26 09:05:12,107:INFO:[LightGBM] [Info] Number of data points in the train set: 117, number of used features: 12
2023-11-26 09:05:12,107:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495726 -> initscore=-0.017094
2023-11-26 09:05:12,107:INFO:[LightGBM] [Info] Start training from score -0.017094
2023-11-26 09:05:12,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,164:INFO:[LightGBM] [Info] Number of positive: 58, number of negative: 60
2023-11-26 09:05:12,166:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001876 seconds.
2023-11-26 09:05:12,167:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:05:12,167:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 09:05:12,167:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 09:05:12,168:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491525 -> initscore=-0.033902
2023-11-26 09:05:12,168:INFO:[LightGBM] [Info] Start training from score -0.033902
2023-11-26 09:05:12,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf

2023-11-26 09:05:12,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,276:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 09:05:12,277:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000036 seconds.
2023-11-26 09:05:12,277:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-26 09:05:12,277:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 09:05:12,277:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 09:05:12,277:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 09:05:12,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,355:INFO:[LightGBM] [Info] Number of positive: 59, number of negative: 59
2023-11-26 09:05:12,355:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000028 seconds.
2023-11-26 09:05:12,356:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-26 09:05:12,356:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-26 09:05:12,356:INFO:[LightGBM] [Info] Total Bins 492
2023-11-26 09:05:12,356:INFO:[LightGBM] [Info] Number of data points in the train set: 118, number of used features: 12
2023-11-26 09:05:12,356:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2023-11-26 09:05:12,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-11-26 09:05:12,408:INFO:Calculating mean and std
2023-11-26 09:05:12,408:INFO:Creating metrics dataframe
2023-11-26 09:05:12,410:INFO:Uploading results into container
2023-11-26 09:05:12,410:INFO:Uploading model into container now
2023-11-26 09:05:12,410:INFO:_master_model_container: 11
2023-11-26 09:05:12,410:INFO:_display_container: 2
2023-11-26 09:05:12,411:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5257, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-26 09:05:12,411:INFO:create_model() successfully completed......................................
2023-11-26 09:05:12,439:INFO:SubProcess create_model() end ==================================
2023-11-26 09:05:12,440:INFO:Creating metrics dataframe
2023-11-26 09:05:12,442:INFO:Initializing Dummy Classifier
2023-11-26 09:05:12,442:INFO:Total runtime is 0.03510013024012248 minutes
2023-11-26 09:05:12,442:INFO:SubProcess create_model() called ==================================
2023-11-26 09:05:12,442:INFO:Initializing create_model()
2023-11-26 09:05:12,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffff746469d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:05:12,443:INFO:Checking exceptions
2023-11-26 09:05:12,443:INFO:Importing libraries
2023-11-26 09:05:12,443:INFO:Copying training dataset
2023-11-26 09:05:12,444:INFO:Defining folds
2023-11-26 09:05:12,444:INFO:Declaring metric variables
2023-11-26 09:05:12,445:INFO:Importing untrained model
2023-11-26 09:05:12,445:INFO:Dummy Classifier Imported successfully
2023-11-26 09:05:12,445:INFO:Starting cross validation
2023-11-26 09:05:12,445:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:05:12,452:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:05:12,459:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:05:12,466:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:05:12,473:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:05:12,479:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-26 09:05:12,481:INFO:Calculating mean and std
2023-11-26 09:05:12,481:INFO:Creating metrics dataframe
2023-11-26 09:05:12,482:INFO:Uploading results into container
2023-11-26 09:05:12,483:INFO:Uploading model into container now
2023-11-26 09:05:12,483:INFO:_master_model_container: 12
2023-11-26 09:05:12,483:INFO:_display_container: 2
2023-11-26 09:05:12,483:INFO:DummyClassifier(constant=None, random_state=5257, strategy='prior')
2023-11-26 09:05:12,483:INFO:create_model() successfully completed......................................
2023-11-26 09:05:12,511:INFO:SubProcess create_model() end ==================================
2023-11-26 09:05:12,511:INFO:Creating metrics dataframe
2023-11-26 09:05:12,514:INFO:Initializing create_model()
2023-11-26 09:05:12,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:05:12,514:INFO:Checking exceptions
2023-11-26 09:05:12,515:INFO:Importing libraries
2023-11-26 09:05:12,515:INFO:Copying training dataset
2023-11-26 09:05:12,516:INFO:Defining folds
2023-11-26 09:05:12,516:INFO:Declaring metric variables
2023-11-26 09:05:12,516:INFO:Importing untrained model
2023-11-26 09:05:12,516:INFO:Declaring custom model
2023-11-26 09:05:12,517:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-26 09:05:12,517:INFO:Cross validation set to False
2023-11-26 09:05:12,517:INFO:Fitting Model
2023-11-26 09:05:12,521:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-26 09:05:12,521:INFO:create_model() successfully completed......................................
2023-11-26 09:05:12,550:INFO:_master_model_container: 12
2023-11-26 09:05:12,550:INFO:_display_container: 2
2023-11-26 09:05:12,551:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-26 09:05:12,551:INFO:compare_models() successfully completed......................................
2023-11-26 09:05:12,551:INFO:Initializing create_model()
2023-11-26 09:05:12,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=lda, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:05:12,551:INFO:Checking exceptions
2023-11-26 09:05:12,552:INFO:Importing libraries
2023-11-26 09:05:12,552:INFO:Copying training dataset
2023-11-26 09:05:12,553:INFO:Defining folds
2023-11-26 09:05:12,553:INFO:Declaring metric variables
2023-11-26 09:05:12,554:INFO:Importing untrained model
2023-11-26 09:05:12,554:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:05:12,554:INFO:Starting cross validation
2023-11-26 09:05:12,555:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:05:12,593:INFO:Calculating mean and std
2023-11-26 09:05:12,594:INFO:Creating metrics dataframe
2023-11-26 09:05:12,595:INFO:Finalizing model
2023-11-26 09:05:12,599:INFO:Uploading results into container
2023-11-26 09:05:12,599:INFO:Uploading model into container now
2023-11-26 09:05:12,603:INFO:_master_model_container: 13
2023-11-26 09:05:12,603:INFO:_display_container: 3
2023-11-26 09:05:12,603:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:05:12,603:INFO:create_model() successfully completed......................................
2023-11-26 09:05:12,632:INFO:Initializing tune_model()
2023-11-26 09:05:12,632:INFO:tune_model(estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=AUC, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>)
2023-11-26 09:05:12,632:INFO:Checking exceptions
2023-11-26 09:05:12,633:INFO:Copying training dataset
2023-11-26 09:05:12,634:INFO:Checking base model
2023-11-26 09:05:12,634:INFO:Base model : Linear Discriminant Analysis
2023-11-26 09:05:12,635:INFO:Declaring metric variables
2023-11-26 09:05:12,635:INFO:Defining Hyperparameters
2023-11-26 09:05:12,663:INFO:Tuning with n_jobs=-1
2023-11-26 09:05:12,663:INFO:Initializing RandomizedSearchCV
2023-11-26 09:05:13,899:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
10 fits failed out of a total of 50.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 275, in fit
    fitted_estimator = self._memory_fit(
  File "/usr/local/lib/python3.8/site-packages/joblib/memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/pipeline.py", line 68, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/usr/local/lib/python3.8/site-packages/sklearn/discriminant_analysis.py", line 571, in fit
    self._validate_params()
  File "/usr/local/lib/python3.8/site-packages/sklearn/base.py", line 600, in _validate_params
    validate_parameter_constraints(
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py", line 97, in validate_parameter_constraints
    raise InvalidParameterError(
sklearn.utils._param_validation.InvalidParameterError: The 'shrinkage' parameter of LinearDiscriminantAnalysis must be a str among {'auto'}, a float in the range [0, 1] or None. Got 'empirical' instead.

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-11-26 09:05:13,902:WARNING:/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.99549206        nan 0.98698413        nan 0.99720635 0.99815873
 0.99815873 0.99815873 0.99815873 0.99815873]
  warnings.warn(

2023-11-26 09:05:13,903:INFO:best_params: {'actual_estimator__solver': 'lsqr', 'actual_estimator__shrinkage': 0.1}
2023-11-26 09:05:13,903:INFO:Hyperparameter search completed
2023-11-26 09:05:13,903:INFO:SubProcess create_model() called ==================================
2023-11-26 09:05:13,904:INFO:Initializing create_model()
2023-11-26 09:05:13,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0xffffb3bd8520>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'solver': 'lsqr', 'shrinkage': 0.1})
2023-11-26 09:05:13,904:INFO:Checking exceptions
2023-11-26 09:05:13,904:INFO:Importing libraries
2023-11-26 09:05:13,905:INFO:Copying training dataset
2023-11-26 09:05:13,907:INFO:Defining folds
2023-11-26 09:05:13,907:INFO:Declaring metric variables
2023-11-26 09:05:13,907:INFO:Importing untrained model
2023-11-26 09:05:13,907:INFO:Declaring custom model
2023-11-26 09:05:13,907:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:05:13,908:INFO:Starting cross validation
2023-11-26 09:05:13,908:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:05:13,951:INFO:Calculating mean and std
2023-11-26 09:05:13,952:INFO:Creating metrics dataframe
2023-11-26 09:05:13,953:INFO:Finalizing model
2023-11-26 09:05:13,957:INFO:Uploading results into container
2023-11-26 09:05:13,958:INFO:Uploading model into container now
2023-11-26 09:05:13,958:INFO:_master_model_container: 14
2023-11-26 09:05:13,958:INFO:_display_container: 4
2023-11-26 09:05:13,959:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='lsqr',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:05:13,959:INFO:create_model() successfully completed......................................
2023-11-26 09:05:14,004:INFO:SubProcess create_model() end ==================================
2023-11-26 09:05:14,004:INFO:choose_better activated
2023-11-26 09:05:14,005:INFO:SubProcess create_model() called ==================================
2023-11-26 09:05:14,005:INFO:Initializing create_model()
2023-11-26 09:05:14,005:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:05:14,005:INFO:Checking exceptions
2023-11-26 09:05:14,006:INFO:Importing libraries
2023-11-26 09:05:14,006:INFO:Copying training dataset
2023-11-26 09:05:14,008:INFO:Defining folds
2023-11-26 09:05:14,008:INFO:Declaring metric variables
2023-11-26 09:05:14,008:INFO:Importing untrained model
2023-11-26 09:05:14,008:INFO:Declaring custom model
2023-11-26 09:05:14,009:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:05:14,009:INFO:Starting cross validation
2023-11-26 09:05:14,009:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2023-11-26 09:05:14,050:INFO:Calculating mean and std
2023-11-26 09:05:14,051:INFO:Creating metrics dataframe
2023-11-26 09:05:14,052:INFO:Finalizing model
2023-11-26 09:05:14,056:INFO:Uploading results into container
2023-11-26 09:05:14,057:INFO:Uploading model into container now
2023-11-26 09:05:14,057:INFO:_master_model_container: 15
2023-11-26 09:05:14,057:INFO:_display_container: 5
2023-11-26 09:05:14,057:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:05:14,057:INFO:create_model() successfully completed......................................
2023-11-26 09:05:14,087:INFO:SubProcess create_model() end ==================================
2023-11-26 09:05:14,087:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9972
2023-11-26 09:05:14,088:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='lsqr',
                           store_covariance=False, tol=0.0001) result for AUC is 0.9982
2023-11-26 09:05:14,088:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='lsqr',
                           store_covariance=False, tol=0.0001) is best model
2023-11-26 09:05:14,088:INFO:choose_better completed
2023-11-26 09:05:14,092:INFO:_master_model_container: 15
2023-11-26 09:05:14,092:INFO:_display_container: 4
2023-11-26 09:05:14,092:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='lsqr',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:05:14,092:INFO:tune_model() successfully completed......................................
2023-11-26 09:05:14,118:INFO:Initializing evaluate_model()
2023-11-26 09:05:14,118:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='lsqr',
                           store_covariance=False, tol=0.0001), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-26 09:05:14,121:INFO:Initializing plot_model()
2023-11-26 09:05:14,121:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='lsqr',
                           store_covariance=False, tol=0.0001), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, system=True)
2023-11-26 09:05:14,121:INFO:Checking exceptions
2023-11-26 09:05:14,122:INFO:Preloading libraries
2023-11-26 09:05:14,122:INFO:Copying training dataset
2023-11-26 09:05:14,122:INFO:Plot type: pipeline
2023-11-26 09:05:14,157:INFO:Visual Rendered Successfully
2023-11-26 09:05:14,204:INFO:plot_model() successfully completed......................................
2023-11-26 09:05:14,208:INFO:Initializing finalize_model()
2023-11-26 09:05:14,212:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='lsqr',
                           store_covariance=False, tol=0.0001), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-11-26 09:05:14,214:INFO:Finalizing LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='lsqr',
                           store_covariance=False, tol=0.0001)
2023-11-26 09:05:14,219:INFO:Initializing create_model()
2023-11-26 09:05:14,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=0.1, solver='lsqr',
                           store_covariance=False, tol=0.0001), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2023-11-26 09:05:14,226:INFO:Checking exceptions
2023-11-26 09:05:14,237:INFO:Importing libraries
2023-11-26 09:05:14,244:INFO:Copying training dataset
2023-11-26 09:05:14,244:INFO:Defining folds
2023-11-26 09:05:14,244:INFO:Declaring metric variables
2023-11-26 09:05:14,244:INFO:Importing untrained model
2023-11-26 09:05:14,244:INFO:Declaring custom model
2023-11-26 09:05:14,245:INFO:Linear Discriminant Analysis Imported successfully
2023-11-26 09:05:14,245:INFO:Cross validation set to False
2023-11-26 09:05:14,246:INFO:Fitting Model
2023-11-26 09:05:14,252:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='lsqr',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 09:05:14,252:INFO:create_model() successfully completed......................................
2023-11-26 09:05:14,285:INFO:_master_model_container: 15
2023-11-26 09:05:14,285:INFO:_display_container: 4
2023-11-26 09:05:14,287:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='lsqr',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False)
2023-11-26 09:05:14,288:INFO:finalize_model() successfully completed......................................
2023-11-26 09:05:14,825:INFO:Initializing predict_model()
2023-11-26 09:05:14,826:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0xffff78536f70>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['mfcc_1', 'mfcc_2', 'mfcc_3',
                                             'mfcc_4', 'mfcc_5', 'mfcc_6',
                                             'mfcc_7', 'mfcc_8', 'mfcc_9',
                                             'mfcc_10', 'mfcc_11', 'mfcc_12'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('actual_estimator',
                 LinearDiscriminantAnalysis(covariance_estimator=None,
                                            n_components=None, priors=None,
                                            shrinkage=0.1, solver='lsqr',
                                            store_covariance=False,
                                            tol=0.0001))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0xffff499103a0>)
2023-11-26 09:05:14,826:INFO:Checking exceptions
2023-11-26 09:05:14,826:INFO:Preloading libraries
2023-11-26 09:05:14,827:INFO:Set up data.
2023-11-26 09:05:14,834:INFO:Set up index.
2023-11-26 09:05:14,845:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 200, in union1d
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 200, in unique
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'int' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[''] and y_pred=[0]. Make sure that the predictions provided by the classifier coincides with the true labels.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 200, in union1d
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 200, in unique
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'int' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py", line 192, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 221, in accuracy_score
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[''] and y_pred=[0]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(traceback.format_exc())

2023-11-26 09:05:14,848:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 572, in roc_auc_score
    return _average_binary_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_ranking.py", line 339, in _binary_roc_auc_score
    raise ValueError(
ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.

  warnings.warn(traceback.format_exc())

2023-11-26 09:05:14,850:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 200, in union1d
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 200, in unique
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'int' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[''] and y_pred=[0]. Make sure that the predictions provided by the classifier coincides with the true labels.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 200, in union1d
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 200, in unique
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'int' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 2098, in recall_score
    _, r, _, _ = precision_recall_fscore_support(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[''] and y_pred=[0]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(traceback.format_exc())

2023-11-26 09:05:14,856:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 200, in union1d
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 200, in unique
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'int' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[''] and y_pred=[0]. Make sure that the predictions provided by the classifier coincides with the true labels.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 200, in union1d
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 200, in unique
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'int' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1954, in precision_score
    p, _, _, _ = precision_recall_fscore_support(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[''] and y_pred=[0]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(traceback.format_exc())

2023-11-26 09:05:14,858:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 200, in union1d
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 200, in unique
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'int' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[''] and y_pred=[0]. Make sure that the predictions provided by the classifier coincides with the true labels.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 200, in union1d
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 200, in unique
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'int' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/pycaret/internal/metrics.py", line 44, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1146, in f1_score
    return fbeta_score(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1287, in fbeta_score
    _, _, f, _ = precision_recall_fscore_support(
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1573, in precision_recall_fscore_support
    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 1374, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[''] and y_pred=[0]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(traceback.format_exc())

2023-11-26 09:05:14,860:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 200, in union1d
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 200, in unique
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'int' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[''] and y_pred=[0]. Make sure that the predictions provided by the classifier coincides with the true labels.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 200, in union1d
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 200, in unique
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'int' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 654, in cohen_kappa_score
    confusion = confusion_matrix(y1, y2, labels=labels, sample_weight=sample_weight)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 317, in confusion_matrix
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[''] and y_pred=[0]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(traceback.format_exc())

2023-11-26 09:05:14,863:WARNING:/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py:586: UserWarning: Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 200, in union1d
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 200, in unique
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'int' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 580, in _calculate_metric
    calculated_metric = score_func(y_test, target, sample_weight=weights, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[''] and y_pred=[0]. Make sure that the predictions provided by the classifier coincides with the true labels.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 113, in _check_targets
    unique_values = np.union1d(y_true, y_pred)
  File "<__array_function__ internals>", line 200, in union1d
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 932, in union1d
    return unique(np.concatenate((ar1, ar2), axis=None))
  File "<__array_function__ internals>", line 200, in unique
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 274, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts,
  File "/usr/local/lib/python3.8/site-packages/numpy/lib/arraysetops.py", line 336, in _unique1d
    ar.sort()
TypeError: '<' not supported between instances of 'int' and 'str'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/site-packages/pycaret/utils/generic.py", line 584, in _calculate_metric
    calculated_metric = score_func(y_test, target, **kwargs)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 911, in matthews_corrcoef
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/usr/local/lib/python3.8/site-packages/sklearn/metrics/_classification.py", line 119, in _check_targets
    raise TypeError(
TypeError: Labels in y_true and y_pred should be of the same type. Got y_true=[''] and y_pred=[0]. Make sure that the predictions provided by the classifier coincides with the true labels.

  warnings.warn(traceback.format_exc())

